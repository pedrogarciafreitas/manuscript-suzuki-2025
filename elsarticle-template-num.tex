% !BIB TS-program = biber


%% 
%% Copyright 2007-2024 Elsevier Ltd
%% 
%% This file is part of the 'Elsarticle Bundle'.
%% ---------------------------------------------
%% 
%% It may be distributed under the conditions of the LaTeX Project Public
%% License, either version 1.3 of this license or (at your option) any
%% later version.  The latest version of this license is in
%%    http://www.latex-project.org/lppl.txt
%% and version 1.3 or later is part of all distributions of LaTeX
%% version 1999/12/01 or later.
%% 
%% The list of all files belonging to the 'Elsarticle Bundle' is
%% given in the file `manifest.txt'.
%% 
%% Template article for Elsevier's document class `elsarticle'
%% with numbered style bibliographic references
%% SP 2008/03/01
%% $Id: elsarticle-template-num.tex 249 2024-04-06 10:51:24Z rishi $
%%



%\documentclass[preprint,12pt,twocolumn]{elsarticle}

%% Use the option review to obtain double line spacing
%\documentclass[authoryear,preprint,review,12pt]{elsarticle}

%% Use the options 1p,twocolumn; 3p; 3p,twocolumn; 5p; or 5p,twocolumn
%% for a journal layout:
%% \documentclass[final,1p,times]{elsarticle}
\documentclass[final,3p,times,twocolumn]{elsarticle}
%% \documentclass[final,3p,times]{elsarticle}
%% \documentclass[final,3p,times,twocolumn]{elsarticle}
%% \documentclass[final,5p,times]{elsarticle}
%% \documentclass[final,5p,times,twocolumn]{elsarticle}

%% For including figures, graphicx.sty has been loaded in
%% elsarticle.cls. If you prefer to use the old commands
%% please give \usepackage{epsfig}


\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}

\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{booktabs}

\usepackage{diagbox}
\usepackage{adjustbox}
\usepackage{graphicx}
\usepackage{subfigure}

\usepackage[hidelinks, draft]{hyperref}
\usepackage{url}

\usepackage{multicol}
\usepackage{multirow}

\usepackage{dsfont}
\newcommand\dsone{\mathds{1}}

\usepackage{xcolor}

\newcommand{\red}[1]{\textcolor{red}{#1}}
\newcommand{\blue}[1]{\textcolor{blue}{#1}}
\newcommand{\purpole}[1]{\textcolor[rgb]{0.7,0.2,0.7}{#1}}


\usepackage[nomain, acronym, symbols]{glossaries}
\usepackage{glossaries-extra}
\glsdisablehyper
\setabbreviationstyle[acronym]{long-short}


\newacronym{AI}{AI}{Artificial Intelligence}
\newacronym{AAL}{AAL}{Additive Attention Layer}
\newacronym{BERT}{BERT}{Bidirectional Encoder Representations from Transformers}
\newacronym{DPAL}{DPAL}{Dot Product Attention Layer}
\newacronym{NSDPAL}{NSDPAL}{Non-Scaled Dot Product Attention Layer}

\newacronym{PoC}{PoC}{Proof-of-Concept}
\newacronym{GPL}{GPL}{Global Pooling Layer}
\newacronym{GPT}{GPT}{Generative Pre-training Transformer}

\newacronym[longplural={Convolutional Neural Networks}, plural=CNNs]{CNN}{CNN}{Convolutional Neural Network}
\newacronym[longplural={Interbeat Intervals}, plural=IBIs]{IBI}{IBI}{Inter-Beat Interval}
\newacronym{PPG}{PPG}{Photoplethysmography}
\newacronym{PD}{PD}{Peak Detection}
\newacronym[longplural={Multilayer Perceptrons}, plural=MLPs]{MLP}{MLP}{Multilayer Perceptron}
\newacronym{HRV}{HRV}{Heart Rate Variability}
\newacronym{ML}{ML}{Machine Learning}
\newacronym{DL}{DL}{Deep Learning}
\newacronym{NAS}{NAS}{Neural Architecture Search}
\newacronym[longplural={Electrocardiogram}, plural=ECGs]{ECG}{ECG}{Electrocardiogram}
\newacronym{SQA}{SQA}{Signal Quality Assessment}
\newacronym{SOTA}{SOTA}{state-of-the-art}
\newacronym{LSTM}{LSTM}{Long Short-Term Memory}
\newacronym{TP}{TP}{True Positive}
\newacronym{TN}{TN}{True Negative}
\newacronym{FP}{FP}{False Positive}
\newacronym{FN}{FN}{False Negative}
\newacronym{MPER}{MPER}{Metric-Parameters Efficiency Ratio}
\newacronym{RRI}{RRI}{RR Interval}
\newacronym{PPI}{PPI}{Peak-to-Peak Interval}
\newacronym{HMA}{HMA}{Health Monitoring Applications}
\newacronym[longplural={Cardiovascular Diseases}, plural=CVDs]{CVD}{CVD}{Cardiovascular Disease}
\newacronym{WHO}{WHO}{World Health Organization}
\newacronym{HR}{HR}{Heart Rate}
\newacronym{LMS}{LMS}{Least-Mean-Square}
\newacronym{SQC}{SQC}{Signal Quality Classifier}
\newacronym{SpO2}{SpO2}{Peripheral Oxygen Saturation}
\newacronym{NLP}{NLP}{Natural Language Processing}
\newacronym{AF}{AF}{Atrial Fibrillation}
\newacronym{NSR}{NSR}{Normal Sinus Rhythm}
\newacronym{DFPAL}{DFPAL}{Differential Dot-Product Attention Layer}
\newacronym{DINTAL}{DINTAL}{Differential-Integral Dot-Product Attention Layer}

\newacronym{ABP}{ABP}{arterial blood pressure}
\newacronym{ACC}{ACC}{accuracy}
\newacronym{BACC}{BACC}{balanced accuracy}
\newacronym{BPM}{BPM}{beats per minute}
\newacronym{BUTPPG}{BUTPPG}{Brno University of Technology smartphone Photoplethysmography database}
\newacronym{CA}{CA}{cardiac arrhythmia}
\newacronym{GAF}{GAF}{Gramian Angular Field}
\newacronym{GADF}{GADF}{Gramian Angular Difference Field}
\newacronym{GASF}{GASF}{Gramian Angular Summation Field}

\newacronym{LOSO}{LOSO}{Leave One Subject Out}

\newacronym{GPU}{GPU}{Graphics Processing Unit}


\newacronym{MTF}{MTF}{Markov Transition Field}
\newacronym{RP}{RP}{Recurrence Plot}
\newacronym{PMix}{PMix}{Projection Mix}
\newacronym{CV}{CV}{Computer Vision}
\newacronym{IoT}{IoT}{Internet of Things}
\newacronym{LED}{LED}{light-emitting diode}
\newacronym{SESS}{SESS}{slow ejection slope sum}
\newacronym{EDSS}{EDSS}{end diastole slope sum}
\newacronym{SQI}{SQI}{signal quality index}
\newacronym{SVM}{SVM}{support vector machine}
\newacronym{FFNN}{FFNN}{feed-forward neural network}
\newacronym{DTW}{DTW}{dynamic time warping}
\newacronym{KNN}{KNN}{k-nearest neighbors}
\newacronym{ROC AUC}{ROC AUC}{area under receiver operating characteristics curve}
\newacronym{MCC}{MCC}{Matthew's correlation coefficient}


\newacronym{ViT}{ViT}{Vision Transformer}
\newacronym{MaxViT}{MaxViT}{Multi-axis Vision Transformer}
\newacronym{SwinT}{SwinT}{Shifted Windows Transformer}
\newacronym{SwinTV2}{SwinTV2}{Shifted Windows Transformer Version~2}
\newacronym{RISEC}{RISEC}{Random Interval Spectral Ensemble Classifier}
\newacronym{TDE}{TDE}{Temporal Dictionary Ensemble}
\newacronym{WiResNet}{WiResNet}{Wide ResNet}


%% Activation functions
\newacronym{ReLU}{ReLU}{Rectified Linear Unit}
\newacronym{LeakyReLU}{LeakyReLU}{Leaky version of a Rectified Linear Unit}
\newacronym{Tanh}{Tanh}{Hyperbolic Tangent}

\newacronym{LBP}{LBP}{Local Binary Pattern}
\newacronym{FLOP}{FLOP}{Floating-Point Operations}


\usepackage{lineno}



% PARAMETERS
\newcommand{\SubjectTreeSize}{0.8\textwidth}
\newcommand{\RPThreshold}{0.05}
\newcommand{\RPDelay}{10}
\newcommand{\MemoryTableWidth}{\textwidth}
\newcommand{\MemoryTableReduction}{0.7}
\newcommand{\timePlotsWidth}{0.95\textwidth}
\newcommand{\NumberOfMemoryTableColumns}{2}

\newcommand{\averagesTableWidth}{\columnwidth}

\newcommand{\MemoryTabularsInclusion}[2]{
    \foreach \index in {1, ..., #1} {
        \input{tex/tabelas/resultados/memory/#2/memory_table_\index.tex}
    }
}

\newcommand{\AveragesTableDescription}[1]{\caption{Averages and standard deviations of the folds evaluation for the #1 variants.}}
\newcommand{\MemoryTableDescription}[1]{Memory size in Mega Bytes of each #1 family model variant.}
\newcommand{\TimePlotsDescription}[1]{Inference time in milliseconds of each #1 family model variant.}

\newcommand{\AveragesTable}[2]{
    \begin{table}[h!]
        \AveragesTableDescription{#1}
        \adjustbox{width=\averagesTableWidth,center}{#2}
        \label{tab:Averages_of_#2}
    \end{table}
}

\newcommand{\IncludeMemoryTable}[2]{
    \begin{table}[h!]
    \centering
    \caption{\MemoryTableDescription{#2}}
    \scalebox{\MemoryTableReduction}{
        \MemoryTabularsInclusion{\NumberOfMemoryTableColumns}{#1}
    }
    \label{tab:Memory_of_#1}
\end{table}
}





\journal{Information Sciences}

\begin{document}

\begin{frontmatter}

\title{VisionPPG: Photoplethysmography Signal Quality Assessment Through Computer Vision Techniques}

\author[1]{Guilherme Chagas Suzuki}
\ead{guilherme.suzuki.198@gmail.com}
\ead[URL]{http://lattes.cnpq.br/6308081045104473}


% Second author
\author[1]{Pedro Garcia Freitas\corref{cor1}}
\cortext[cor1]{Corresponding author}
\ead{pedro.freitas@unb.br}
\ead[URL]{https://pedrogarcia.gitlab.io/}



%% Author affiliation
\affiliation[1]{organization={Department of Computer Science, University of Brasília},
            addressline={CIC/EST Building, Campus Darcy Ribeiro, Asa Norte}, 
            city={Brasilia},
%          citysep={}, % Uncomment if no comma needed between city and postcode
            postcode={70910-900}, 
            state={DF},
            country={Brazil}}



%% Abstract
\begin{abstract}


\gls{PPG} is a fundamental component to enable a myriad of continuous \gls{HMA}. 
These applications commonly utilize wearable devices to record signals that are useful in the individual's health condition diagnostic.
%\gls{PPG} is widely adopted in wearable sensors due to its small form factor, non-invasive nature, and cost-effectiveness. 
However, despite these benefits, \gls{PPG} is highly susceptible to noise caused by motion and environmental interferences.
%Such noise can greatly impair the quality of the signal, which compromises the performance and reliability of health monitoring. 
For that reason, \gls{SQA} is essential for enabling reliable \gls{HMA}.
Most \gls{SQA} strategies rely either on \gls{ML} models, achieving high performance levels despite the associated increases in resource demand and power consumption, or rule-based strategies that can assess signal quality in an energy-efficient way with reduced accuracy. 
In this work, we present VisionPPG, a method for assessing the quality of \gls{PPG} signals through a fusion of signal projections and \gls{CV} techniques.
%Specifically, the one-dimensional \gls{PPG} signal is projected onto a set of bidimensional representations based on \gls{GAF}, \gls{MTF} and \gls{RP}.
These projections are then aggregated to form a tensor referred as \gls{PMix}.
%The \gls{PMix} is combined with several \gls{CV} to model a signal quality classifier.
To validate \gls{PMix}, different \glspl{CV} models are trained and tested using the \gls{BUTPPG} database. 
Results indicate that VisionPPG outperforms state-of-the-art time series classifiers, achieving a K-Fold mean Cohen Kappa score of 0.955$\pm$0.101\%, F1 Score of 0.967$\pm$0.078, and Precision of 0.944$\pm$0.130 when the \gls{PMix} is combined with a Wide ResNet.
%The source code is available at \url{https://gitlab.com/lisa-unb/projection-based-biological-signal-processing}.
\end{abstract}

%%Graphical abstract
% \begin{graphicalabstract}
% \includegraphics{grabs}
% \end{graphicalabstract}

%%Research highlights
\begin{highlights}
\item Novel VisionPPG method combines signal projections with computer vision for PPG SQA.
\item Proposed Projection Mix (PMix) fuses GAF, MTF, and RP for better signal assessment.
\item VisionPPG with Wide ResNet outperforms state-of-the-art time series classifiers.
\item Achieved a high Cohen Kappa score of 0.955 using deep learning and signal imagery.
\end{highlights}

%% Keywords
\begin{keyword}
Intelligent Systems \sep Biomedical Engineering \sep Computer Vision \sep Photoplethysmography \sep Quality Assessment
\end{keyword}

\end{frontmatter}

%% Add \usepackage{lineno} before \begin{document} and uncomment 
%% following line to enable line numbers
\linenumbers

\section{Introduction} \label{sec_intro}


The pursuit of enhanced clinical longevity and patient quality of life has driven significant research in medical monitoring technologies. 
One of the main research areas in that regard is medicine, which provides means of preventing and remedying accidents and diseases. 
Asymptomatic cardiovascular pathologies, such as atheroma formation, present significant clinical risks, including acute ischemic events and strokes~\cite{atheromas}.
For that reason, it is vital to seek regular medical consultation to detect diseases in their early stages. The treatability of certain conditions, such as cardiac amyloidosis, is often contingent upon early diagnosis~\cite{cardiac-amyloidosis}.
However, personalized professional care can be expensive and often lacks the real-time responsiveness required to manage acute events when a patient is outside of a hospital setting.
As a result, there is a growing demand for autonomous and continuous health monitoring systems.


In this context, a promising solution for that demand is to use wearable devices for enabling affordable continuous health monitoring applications.
Examples of wearable devices include quotidian objects, with the shape of belts, bracelets, rings, shoe soles, clothing, etc~\cite{van2024smart}.
Smartwatches are a common category of wearables capable of running multiple health-monitoring applications.
These applications are facilitated by the advent of the \gls{IoT}, which is defined as a scalable network of interconnected devices that exchange data captured by various sensors~\cite{aouedi2024survey}.
These sensors capture vital physiological indicators, including thermal fluctuations, hemodynamic parameters, and neuroelectrical activity.
These sensors are significant to capture environmental and physiological data that are valuable for healthcare, since they provide indicators of the patient's physiological state~\cite{ECG-diagnosis}. 
%For instance, certain \gls{ECG} patterns can signal a post-ischemic state~\cite{ECG-diagnosis}.



Despite the advantages of continuous health monitoring using wearables, the extraction of physiological signals are often vulnerable to signal artifacts and environmental noise. 
\gls{PPG} signals, one of the most versatile sensed data in wearables, are influenced by various factors, including ambient light, hardware limitations, and dermal characteristics. These artifacts can impair signal integrity to the point that its use becomes unfeasible for diagnostic use.
Moreover, \gls{PPG} signals are highly susceptible to artifacts generated by motion or noise sources. For instance, wrist movements can disrupt the signal in a smartwatch \gls{PPG} sensor~\cite{ppg-1}, though the degree of distortion varies with the signal power and wavelength. These variation can cause high-amplitude distortions that not only can destroy the core information, but can also produce misleading events. 
Such distortions are unacceptable in healthcare contexts since noisy signals can lead the monitoring system to misdiagnosis, exposing healthy patient to unnecessary risk, while may leave an at-risk patient without essential care.
For these reasons, ensuring signal integrity is crucial before proceeding with further health status estimation.
This process, termed \glsfirst{SQA}, is responsible for classifying which segments of the incoming \gls{PPG} signal are of sufficient quality to ensure reliable measurements for the health applications.
\gls{SQA} is the focus of this paper, which proposes an objective method for evaluating \gls{PPG} signals.



\subsection{Problem description}
\label{sec:problem}

Historically, \gls{ECG} and \gls{PPG} are the two most prevalent methods for evaluating the cardiac activity and heart rate monitoring.
The \gls{ECG} has long been considered the clinical gold standard for monitoring heart rate and diagnosing cardiovascular conditions. 
It monitors the electrical impulses responsible for myocardial contractions through electrodes attached to the skin, usually positioned on the chest and limbs.
While \gls{ECG} is the clinical standard, its requirement for surface electrodes and stable skin contact makes it less suitable for continuous monitoring in unconstrained environments.
Conversely, \gls{PPG} offers a more convenient approach for monitoring cardiorespiratory status under these unconstrained scenarios.
\gls{PPG} employs compact optical sensors and a light source to detect variations in skin color caused by blood flow following each heartbeat. The \gls{PPG} measures the blood flow rate in tissues (e.g. wrist), influenced by the heart's pumping action, making it particularly effective for peripheral circulation monitoring, especially with wrist-worn or finger-mounted devices. Since both \gls{ECG} and \gls{PPG} gauge cardiovascular and circulatory parameters, they are interconnected, as depicted in Figure~\ref{fig:ecg_and_ppg}. The similarity in the signal periods of both methods suggests that either can be used to analyze metrics such as the \gls{IBI}. Additionally, Figure~\ref{fig:ecg_and_ppg} emphasizes the reference points often utilized to assess health indicators related to blood pressure, oxygen saturation, and more.
Consequently, \gls{PPG} emerges as a viable alternative to \gls{ECG}, particularly in unconstrained scenarios.
\begin{figure}[t!]
    \centering
    \includegraphics[width=\columnwidth]{ecg_ppg_signals.pdf}
    \caption{Inter-beat interval estimation using RR interval from \gls{ECG} and the corresponding peak-to-peak (PP) interval from \gls{PPG}.}
    \label{fig:ecg_and_ppg}
\end{figure} 
\begin{figure}[t!]
    \centering
    \adjustbox{width=1\columnwidth}{%
    \def\arraystretch{0}
    \setlength{\tabcolsep}{0pt}
    \begin{tabular}{cc}
        Reliable (suitable) & Unreliable (distorted) \\
        \includegraphics[width=0.48\textwidth, trim={5.02em 0 0em 0}, clip]{butppg_111001.png} 
        & \includegraphics[width=0.48\textwidth, trim={4.12em 0 0em 0}, clip]{butppg_111003.png} \\
        \includegraphics[width=0.48\textwidth, trim={5.02em 0 0em 0}, clip]{butppg_111002.png} 
        & \includegraphics[width=0.48\textwidth, trim={4.12em 0 0em 0}, clip]{butppg_111004.png} \\
    \end{tabular}
    }
    \caption{Example of reliable (blue) and distorted (red) \gls{PPG} signals from the \gls{BUTPPG} database~\protect\cite{butppg}.}
    \label{fig:butppg_samples}
\end{figure}

Typically, \gls{PPG} signals are prone to degradation due to various factors, with motion artifacts being among the most significant~\cite{ppg-1}.
Excessive movement of the \gls{PPG} sensor can cause significant waveform distortion, introducing motion artifacts that compromise the accuracy of feature extraction.
Such artifacts mask important information by distorting signal morphology, thereby compromising the integrity of the physiological measurement.
Figure~\ref{fig:butppg_samples} illustrates examples of both reliable and distorted \gls{PPG} signals.
As shown in Figure~\ref{fig:butppg_samples}, the reliable signals exhibit symmetrical, well-defined, and more consistent patterns. Conversely, the distorted segments are irregular and asymmetrical, demonstrating lower consistency and increased variability between cardiac cycles.
These distorted signals may cause algorithmic misclassifications, which is unacceptable in health monitoring.
Therefore, methods for assessing \gls{PPG} signal quality are essential to prevent misinterpretation by differentiating between reliable and noisy data.


\subsection{Related Work}
\label{sec:related}


\gls{SQA} involves a wide range of problems in signal processing technologies, and it is not exclusive to the medical domain.
Its origins are rooted in early communication systems, specifically the information theory developments of the 1920s and 1930s.
Foundational studies, such as the work by Rice~\cite{origins-1}, analyzed the statistical properties of noise in communication devices, while Shannon~\cite{origins-2} established the fundamental principles of communication systems.
By the late 20th century, the concept of \gls{SQA} was well-established~\cite{origins-3, origins-4}.
For instance, Stehle~\cite{origins-3} proposed an algorithm in the 1980s to objectively measure human perception regarding the intelligibility of shortwave broadcast signals.
Several conclusions from that era remain relevant to contemporary clinical \gls{SQA}, particularly the inherent subjectivity of human quality assessment.
This subjectivity underscores the critical importance of rigorous dataset labeling to ensure that \gls{SQA} algorithms are evaluated against a consistent and representative ground truth.

Following the 20th century, \gls{SQA} for physiological signals gained significant traction, with a proliferation of studies emerging in the early 2000s. 
For example, Wang et al. \cite{2000s-1} proposed an \gls{ECG} \gls{SQA} method based on the area differences between distinct QRS complexes, utilizing cumulative histogram comparisons across various \gls{ECG} leads.
Subsequently, Li et al. \cite{2000s-2} introduced a combination of multiple quality indices and \gls{HR} for \gls{ECG} evaluation.
In a different approach, Deshmane et al. \cite{2000s-3} utilized thresholding based on Hjorth parameters~\cite{hjorth-parameters} to assess \gls{PPG} signal quality. Furthermore, Zhang et al. \cite{2000s-4} developed an \gls{ABP} quality metric based on \gls{EDSS} and \gls{SESS} features.
Collectively, these studies moved toward quantifying \gls{SQA} through a single representative metric \cite{2000s-2, 2000s-3, 2000s-4}, frequently referred to in the literature as the \gls{SQI} \cite{2000s-2, 2000s-3}.


Among the variety of physiological signals, the \gls{ECG} remains the most prominent in the literature due to its diverse applications, including disease classification, arrhythmia detection, biometric identification, and emotion recognition \cite{ecg-1}.
Consequently, \gls{SQA} methodologies for \gls{ECG} signals are extensively documented.
For instance, Naseri et al. \cite{ecg-2} proposed two distinct features to estimate a classification-based \gls{SQI} for multi-channel \gls{ECG} data.
The first feature evaluates whether two energy-based indices, measured in decibels, fall within a predefined admissible range.
The second feature utilizes a \gls{FFNN} to reconstruct a randomly selected target lead from the derivatives of all available leads and the reconstructed signal is then compared to the original via correlation analysis to assess signal integrity.


Beyond foundational studies, various specialized features have been developed for \gls{ECG} \gls{SQA}.
For instance, Orphanidou et al. \cite{ecg-3} proposed extracting the \gls{HRV} signal and decomposing it into wavelet coefficients across multiple frequency ranges.
The entropy of these coefficients forms a feature vector utilized by a \gls{SVM} for binary quality classification.
Alternatively, Shahriari et al. \cite{ecg-4} introduced an image-based approach that calculates the structural similarity between a Cartesian plot of the signal and clustered templates from the training set.
Other signal transformation techniques include the use of the autocorrelation function for feature extraction \cite{ecg-5} and the generation of discretized phase space plots—such as Poincaré plots—where cell values represent the logarithm of point density \cite{ecg-6}.
Collectively, these methodologies demonstrate the technical diversity of \gls{ECG} quality assessment within the existing literature.


In addition to the established relevance of the \gls{ECG}, the use of \gls{PPG} as a diagnostic alternative has gained significant traction, with related publications increasing by 176\% between 2013 and 2023 \cite{ppg-1}.
However, the susceptibility of \gls{PPG} to noise necessitates robust \gls{SQA} methodologies.
For instance, Li et al. \cite{ppg-2} utilized \gls{DTW} to quantify signal disparity relative to an established template.
This \gls{SQI}, alongside auxiliary metrics, was processed through both an \gls{MLP} and a heuristic rule-based function to determine a final quality score, achieving a peak accuracy of 95.2\% using the MIMIC II dataset as benchmark.
Similarly, Papini et al. \cite{ppg-3} demonstrated that comparing individual heartbeats to a \gls{DTW} barycenter template yields predictive values exceeding 95\% across two public datasets. These findings suggest that high predictive accuracy is attainable for \gls{PPG} \gls{SQA} tasks using template-based comparisons.


According to Such~\cite{such2007motion}, \gls{SQA} methods in biomedical signals generally fall into two categories: single-parameter and multiparameter approaches.
Unlike single-parameter methods, multiparameter techniques utilize additional sensors that provide information related to the motion or the \gls{PPG} itself.
Examples of these additional sensors include accelerometers~\cite{nabavi2020robust, tuauctan2015characterization} and optical source-detector pairs with peak responses beyond the red-infrared wavelength spectrum~\cite{zhang2019motion}.
Some studies generate reference noise signals internally from the impaired \gls{PPG} segments, reducing the need for extra hardware~\cite{ram2011novel, raghuram2016use}.
dditional sensor channels can also transmit data about the same or a similar physiological indicator that reacts differently to artifacts.
Nevertheless, using measured or synthetic reference signals for detecting contaminated \gls{PPG} segments often relies on adaptive filtering.
Beyond its high computational and mathematical complexity, this approach may require extended convergence times to reach an optimal solution.


In contrast to the aforementioned techniques, \gls{SQA} methods that do not rely on measured or synthetic reference signals (i.e. referenceless methods) may be better suited for wearable, real-time applications, since they eliminate the need for additional data collection and processing.
In this context, \gls{ML} has made significant strides in this area by enabling the classification of \gls{PPG} signals into ``reliable'' or ``unreliable'' based on the extraction of distinguishing information and the recognition of complex patterns, either automatically or with minimal human involvement~\cite{janiesch2021machine}. 


The \gls{PPG} \gls{SQA} literature encompasses both supervised and unsupervised learning paradigms.
Supervised approaches leverage labeled data to capture discriminative features, often yielding higher predictive performance at the expense of increased computational training costs.
For instance, Mohagheghian et al. \cite{ppg-sqa-1} improved feature selection by ensembling subsets through a majority voting scheme, where the threshold was determined by classifiers such as AdaBoost, \gls{SVM}, and \gls{KNN}.
Among these, AdaBoost achieved peak performance with accuracies of 91.55\%, 92.29\%, and 95.86\% on the DeepBeat, UMMC Simband, and MIMIC III datasets, respectively. Similarly, Tiwari et al. \cite{ppg-sqa-2} utilized modulation spectrogram representations to extract features for logistic regression.
Their method outperformed traditional \glspl{SQI} across green, red, and infrared wavelengths, improving \gls{BACC} by up to 21.6\%.
Furthermore, Miranda et al. \cite{ppg-sqa-3} applied an interval type-2 fuzzy logic system to a private dataset, achieving an \gls{MCC} of 77\% and an \gls{ACC} of 93.72\%.
Notably, the reliance of many such studies on private or non-publicly available datasets limits the reproducibility of their results and underscores the need for standardized benchmarking.


On the other hand, unsupervised learning paradigms omit ground-truth labels during the training process.
While this provides the model with less explicit information, it ensures independence from specialist guidance and inherent human biases. 
Although supervised methods predominate in \gls{SQA} research, several unsupervised approaches have demonstrated significant efficacy.
For instance, Singha et al. \cite{ppg-sqa-4} proposed a self-organizing map that utilizes entropy and statistical features, achieving 92.01\% accuracy in ternary classification on a private dataset.
Similarly, Mahmoudzadeh et al. \cite{ppg-sqa-5} employed an elliptical envelope algorithm to process time and frequency domain features, attaining F1-scores of 97\% and 93\% for intra- and inter-subject testing, respectively.
Furthermore, hybrid architectures can facilitate semi-supervised learning.
Feli et al. \cite{ppg-sqa-6} utilized a one-class \gls{SVM} trained exclusively on ``reliable'' samples.
This semi-supervised approach outperformed rule-based, unsupervised, and deep learning methods, reaching a 99\% F1-score on a private dataset.
However, as with the supervised literature, the reliance on non-public datasets and private labeling protocols remains a significant barrier to cross-study validation.



The \gls{PPG} \gls{SQA} literature also addresses the challenge of identifying \glspl{CA}, which involve anomalous cardiac rates or rhythms without an underlying physiological cause \cite{arrhythmia-1}.
These conditions present a significant challenge for \gls{SQI} design because many traditional features assume signal periodicity.
Consequently, arrhythmic signals may be erroneously rejected as unreliable, potentially leading to misdiagnosis in patients with \glspl{CA}.
To address this, Pereira et al. \cite{arrhythmia-2} utilized a private dataset containing \gls{AF} cases to evaluate 40 features previously established in the literature. By employing these features within an \gls{SVM} framework, they achieved an average accuracy exceeding 94\%, significantly outperforming existing methodologies.
These results demonstrate that incorporating diverse feature sets and training models on datasets inclusive of arrhythmic cases significantly improves the detection of these specific signal types.

In sequence, two studies adopted a similar approach to the one mentioned in the past paragraph to attack the arrhythmia problem.
In the first study, Pereira et al. \cite{arrhythmia-3} fed several features to three classifiers: \gls{SVM}, \gls{KNN} and decision trees.
Similarly to their previous study, experiments on a private dataset demonstrated that the \gls{SVM} was the best of all classifiers and it obtained above 95\% surpassing the methods of other studies.
A following study by Pereira et al. \cite{arrhythmia-4} expanded this comparison by incorporating \gls{DL} models alongside the \gls{SVM} framework.
This research contemplated both one-dimensional (1D) and bidimensional (2D) \gls{DL} models, , where the 1D models processed raw signals and the 2D models utilized Cartesian plot images.
Experiments on private data containing \gls{AF} instances revealed that the ResNet18 model achieved a peak accuracy of 98.5\%.
These results underscore the potential of deep learning architectures to surpass conventional methods even in the presence of arrhythmic events.
The following section provides a more comprehensive review of deep learning applications in the \gls{SQA} literature.


{
\newcommand{\projectionsWidth}{0.125\textwidth}
\begin{figure*}[ht!]
    \centering
%    \bgroup
%    \setlength{\tabcolsep}{1mm}
%    \def\arraystretch{2}
%    \adjustbox{max width=0.92\textwidth}{%
%    \begin{tabular}{cccc}
%    \multicolumn{4}{c}{\includegraphics[width=0.95\textwidth, trim={2cm 0cm 2cm 0cm}]{signal.png}} \\
%        \fbox{\includegraphics[width=\projectionsWidth]{GramianAngularFieldDifference.png}}
%         & \fbox{\includegraphics[width=\projectionsWidth]{GramianAngularFieldSummation.png}}
%         & \fbox{\includegraphics[width=\projectionsWidth]{MarkovTransitionField.png}}
%         & \fbox{\includegraphics[width=\projectionsWidth]{RecurrencePlot.png}}\\
%        \fbox{\includegraphics[width=\projectionsWidth]{PoincatePlotLogarithmGrid.png}}
%        & \fbox{\includegraphics[width=\projectionsWidth]{MultiscaleMarkovTransitionField.png}}
%        & \fbox{\includegraphics[width=\projectionsWidth, height=\projectionsWidth]{ShortTimeFFT.png}}
%        & ~ \\
%    \end{tabular}
%    }
%    \egroup
%     \caption[A signal and its various projection obtained by several methods.]{A signal and its various projection obtained by several methods. In the first line, from the left to the right, the methods are: Gramian Angular Diference Field~\cite{gaf-mtf-1}, Gramian Angular Summation Field~\cite{gaf-mtf-1}, Markov Transition Field~\cite{gaf-mtf-1} and Recurrence Plot~\cite{rp-1}. The methods of the second line are, from the left to the right: Poincaré Plot Density Map~\cite{ecg-6}, Multiscale Markov Transition Field~\cite{imaging-6} and Short Time Fourier Transform Spectogram~\cite{STFT, imaging-1}.}
    \subfigure[]{
        \includegraphics[width=0.8\textwidth]{signal.png}
        \label{fig:projections:signal}
    }\\
    \subfigure[]{
        \includegraphics[width=\projectionsWidth]{GramianAngularFieldDifference.png}
        \label{fig:projections:GramianAngularFieldDifference}
    }
    \subfigure[]{
        \includegraphics[width=\projectionsWidth]{GramianAngularFieldSummation.png}
        \label{fig:projections:GramianAngularFieldSummation}
    }
    \subfigure[]{
        \includegraphics[width=\projectionsWidth]{MarkovTransitionField.png}
        \label{fig:projections:MarkovTransitionField}
    }
    \subfigure[]{
        \includegraphics[width=\projectionsWidth]{RecurrencePlot.png}
        \label{fig:projections:RecurrencePlot}
    }
    \subfigure[]{
        \includegraphics[width=\projectionsWidth]{PoincatePlotLogarithmGrid.png}
        \label{fig:projections:PoincatePlotLogarithmGrid}
    }
    \subfigure[]{
        \includegraphics[width=\projectionsWidth]{MultiscaleMarkovTransitionField.png}
        \label{fig:projections:MultiscaleMarkovTransitionField}
    }
    \subfigure[]{
        \includegraphics[width=\projectionsWidth]{ShortTimeFFT.png}
        \label{fig:projections:ShortTimeFFT}
    }\\

       \caption[A signal and its various projection obtained by several methods.]{
           A signal~\subref{fig:projections:signal} and its various projection obtained by several methods. They are: 
           \subref{fig:projections:GramianAngularFieldDifference}~Gramian Angular Diference Field~\cite{gaf-mtf-1}, 
           \subref{fig:projections:GramianAngularFieldSummation}~Gramian Angular Summation Field~\cite{gaf-mtf-1}, 
           \subref{fig:projections:MarkovTransitionField}~Markov Transition Field~\cite{gaf-mtf-1} and 
           \subref{fig:projections:RecurrencePlot}~Recurrence Plot~\cite{rp-1}, 
           \subref{fig:projections:PoincatePlotLogarithmGrid}~Poincaré Plot Density Map~\cite{ecg-6}, 
           \subref{fig:projections:MultiscaleMarkovTransitionField}~Multiscale Markov Transition Field~\cite{imaging-6} and 
           \subref{fig:projections:ShortTimeFFT}~Short Time Fourier Transform Spectogram~\cite{STFT, imaging-1}.
       }
        \label{fig:literature_projections}
\end{figure*}
}


\subsubsection{Signal quality assessment using deep learning}
\label{sec:deep_learning}

\gls{DL} methods have demonstrated the capacity to achieve superior accuracy compared to feature-based models even when arrhythmic conditions are present \cite{arrhythmia-3}.
In contrast to hand-crafted features, \gls{DL} architectures automatically extract hierarchical representations from the input signal to create models that adapt to diverse training contexts.
Furthermore, high-quality datasets provide the necessary resources for these models to develop robustness against variations in signal conditions.
Despite these advantages, \gls{DL} models function as black boxes that lack interpretability regarding the specific reasons for a given quality score.
These architectures also necessitate large volumes of data for optimal parameter optimization.
Nevertheless, the potential for \gls{DL} to provide the accuracy and robustness required for clinical applications justifies its investigation in the \gls{SQA} domain.



In this context, several studies have proposed 1D \gls{CNN} architectures that process raw input signals directly.
For instance, Naeini et al. \cite{deep-learning-1} designed a 1D \gls{CNN} to extract a binary \gls{SQI} and achieved an 85\% F1-score for the ``reliable'' class using a private dataset comprising data from three different devices.
Similarly, Zanelli et al. \cite{deep-learning-2} utilized a custom 1D \gls{CNN} to evaluate the impact of transfer learning.
Their methodology involved initially training the model on a primary dataset where it reached 99.8\% accuracy followed by fine-tuning on two additional private databases. 
This procedure yielded accuracies of 93\% and 81\% on the subsequent datasets respectively.
Notably, the model trained exclusively on the second database achieved a lower accuracy of 86\% compared to the transfer learning approach.
These results indicate that 1D \glspl{CNN} can achieve high accuracy in \gls{SQA} while demonstrating the feasibility of transferring learned features across disparate databases to enhance performance.


Alternatively, some research explores hybrid architectures that extend beyond the standard application of \glspl{CNN}.
For instance, Lucafo et al. \cite{deep-learning-3} introduced a hybrid model for quality assessment that integrates a 1D \gls{CNN} with a rule-based component.
This rule-based mechanism bypasses the \gls{CNN} if the min-to-max signal distance falls below a predefined threshold.
The researchers determined this threshold using methods such as Last Value Thresholding and Nearest Value Thresholding.
This approach was implemented to reduce the computational overhead and power consumption associated with \gls{DL} models.
The hybrid method proved effective as it bypassed the \gls{CNN} for 3.27\% of the input samples while maintaining predictive performance comparable to the standalone \gls{CNN}.
Consequently, integrating 1D \glspl{CNN} with heuristic rules can provide specific advantages in terms of computational efficiency.


Beyond the aforementioned 1D \glspl{CNN}, various alternative \gls{DL} architectures have been explored for \gls{PPG} \gls{SQA}.
For instance, Gao et al. \cite{deep-learning-4} proposed a \gls{LSTM} \gls{SQA} that generates a quality index for each individual signal point.
Their experiments involved labeling private dataset by applying blind source separation to derive high- and low-quality components from raw \gls{PPG} signals.
This model achieved competitive accuracy relative to baseline \glspl{SQI} while remaining computationally efficient for real-time inference.
Another approach combines a stacked denoising autoencoder with an \gls{MLP} as demonstrated by Singha et al. \cite{deep-learning-5}.
This architecture achieved 95\% accuracy on a private dataset outperforming several baseline classifiers.
Additionally, Naeini et al. \cite{deep-learning-6} evaluated 2D \glspl{CNN} by transforming signals into images using \glspl{GAF}. Although three different 2D \gls{CNN} models achieved scores exceeding 90\% for accuracy and F1-score, a proposed 1D \gls{CNN} outperformed all 2D variants.
Consequently, while multiple architectures yield competitive results, the application of 2D \glspl{CNN} has garnered significant interest within the last decade.





\subsubsection{Methods based on time series imaging}
\label{sec:imaging}

Several studies in the literature propose transforming input signals into two-dimensional images for processing via \gls{CV} models.
Figure \ref{fig:literature_projections} illustrates representative examples of these transformations.
For instance, Chen et al. \cite{imaging-1} utilized 2D \glspl{CNN} to classify \glspl{SQI} based on short-time Fourier transform spectrograms.
By annotating the VitalDB database \cite{vitaldb-dataset}, they achieved a peak accuracy of 98.3\% which outperformed four selected baseline models.
Alternatively, Chatterjee et al. \cite{imaging-2} transformed \gls{PPG} signals into quantum pattern recognition images for quality assessment.
This methodology achieved an accuracy of 98.3\% on the University of Queensland vital signs dataset \cite{queensland-dataset} using custom labels.
While this approach outperformed both baseline and standard \gls{DL} methods, the lack of publicly available quality labels presents significant reproducibility challenges.
Similarly, Roh et al. \cite{imaging-3} embedded signals into \glspl{RP} to capture nonlinear dynamics.
Their method achieved 97.5\% accuracy on a private dataset.
Collectively, these results indicate that transforming time series into image-based representations is a promising approach for \gls{SQA} within \gls{SOTA}.


One particular method present in the \gls{SQA} literature is the time series matrix embedding, which encodes time relationships of the original signal into a square matrix.
For instance, Freitas et al.~\cite{imaging-4} fed a \gls{ViT} with a \gls{RP} or a \gls{MTF}, achieving, respectively, 89.9\% and 90.3\% accuracy on a private dataset. Freitas et al. \cite{imaging-5} also fed images with a \gls{ViT}, but used \glspl{GAF}, reaching 92.2\% accuracy on a private dataset.
Liu et al. \cite{imaging-6} proposed to input multiscale \gls{MTF}, a \gls{MTF} version which concatenates the signal first and second derivatives, to a self-made \gls{CV} model, resulting in a binary classification accuracy of 99.1\% in a non-public dataset.
These findings demonstrate that combining generic \gls{CV} models with projection methods can improve predictive performance.

Accurate identification of \gls{PPG} sequences contaminated with artifacts is crucial for enabling reliable smart health applications.
In this regard, \gls{ML} techniques have facilitated significant advancements.
Although labeled datasets remain scarce, supervised learning models are more frequently adopted than their unsupervised counterparts, with \gls{SVM} and \gls{CNN} being the most widely employed.
While feature-engineered and deep learning methods demonstrate similar performance in some scenarios, deep learning may be more advantageous for overcoming the limitations of manual feature engineering.
In the current literature, there is a clear need for a standardized experimental framework to validate 2D \gls{DL} approaches against 1D \gls{ML} methods.
This work addresses that gap by evaluating various time-series methods to provide a comprehensive study of the field.



\subsection{Contributions of this work}
\label{sec:my_work}

This paper introduces a quality assessment framework for \gls{PPG} signals and offers several key contributions to the field.
First, it presents a novel method for encoding time series into 2D images by aggregating various projections into a composite hyperspectral tensor.
This approach is based on the premise that such aggregation yields a richer feature representation than any single projection alone.
Second, this work evaluates the methodology across a diverse range of \gls{CV} models to identify which architectures best complement time-series matrix embeddings, addressing a scope that is rarely explored in existing literature.
Third, the study investigates the application of transfer learning using the ImageNet dataset within the \gls{SQA} domain.
Finally, to address the lack of transparency in the field, all experiments utilize the publicly available \gls{BUTPPG} dataset~\cite{butppg}.
This favors reproducibility and establishes a better benchmark for future comparative studies.



\section{Proposed Method}
\label{sec_proposed_method}

%Section~\ref{sec:related} established that time series imaging enables the application of \gls{CV} models to \gls{SQI} estimation.
Figure~\ref{fig:projections:projection-based-approach} illustrates a general ``projection-based'' framework of the projection-based methods discussed in Section~\ref{sec:related}.
While this framework accommodates various projection algorithms independently, our study focuses on four specific time series embedding methods including \gls{GASF} and \gls{GADF} variants of the \gls{GAF}, the \gls{MTF}, and the \gls{RP}.
The aggregation of these distinct projections is defined here as \gls{PMix}.






\subsection{Recurrence Plot}

The \gls{RP} method was introduced by Eckmann et al.~\cite{rp-1} to visualize the fundamental properties and recurrence behaviors of time series data.
Since its inception, the application of \gls{RP} has expanded across various domains including earth sciences, finance, engineering, and physics~\cite{rp-2}.
Within the life sciences, researchers have utilized \gls{RP} to identify pathological states such as Parkinson's disease~\cite{rp-3}, epileptic seizures~\cite{rp-4}, fetal hypoxia~\cite{rp-5}, and Alzheimer's disease~\cite{rp-6}.
Given its demonstrated efficacy in cardiological signal processing, \gls{RP} represents a robust tool for assessing the quality of physiological signals in the context of \gls{SQA}.


The \gls{RP} represents the occurrence of recurrences between the phase space values of time instant pairs. For this end, the first step is to embed the time series $X=\{x_1,x_2,...,x_n\}$, with $ x_i \in \mathbb{R}$ and $n \in \mathbb{N}$ samples, into a phase space, creating a new time series $S=\{\vec{s_1},\vec{s_2},...,\vec{s_m}\}$, with $ \vec{s_i} \in \mathbb{R}^d$ and $m \in \mathbb{N}$ elements. We can employ the time delays method to represent each element $\vec{s_i}$ of this new sequence $S$ as follows:
\begin{equation}
    \vec{s_i} = (x_i, x_{i + \tau}, x_{i + 2\cdot \tau} ..., x_{i + (d-1) \cdot \tau}),
\end{equation}   
where $d \in \mathbb{N}$ is the dimension and $\tau \in \mathbb{N}$ is the time delay of the phase space. Notice that the length $m$ of the sequence $S$ depends on both $d$ and $\tau$ by the equation $m = n - (d-1) \cdot \tau$. Also notice that this embedding is optional, since the choice of the dimension $d=1$ results in $S=X$, the original time series. Figure~\ref{fig:phase_space} depicts the phase space of the example signal of Figure~\ref{fig:projections:signal}.

\begin{figure}[t!]
    \centering
    \adjustbox{width=\columnwidth}{
    \includegraphics{projection-based-approach.png}
    }
    \label{fig:projections:projection-based-approach}
    \caption{Projection-based time series imaging approach.}
\end{figure}

\begin{figure}[t!]
    \centering

    \subfigure[Signal formed from function $f(t)=\sin(\frac{15 \pi t}{500}) + \frac{t}{500}$.]{
        \includegraphics[width=0.9\columnwidth]{signal_1.png}
        \label{fig:methodology:signal}
    }

    \subfigure[]{
        \includegraphics[width=0.45\columnwidth, trim={0.5em 1em 2em 2em}, clip]{delay_phase_space.pdf}
        \label{fig:phase_space_A}
    }
    \subfigure[]{
        \includegraphics[width=0.45\columnwidth, trim={0.5em 1em 2em 2em}, clip]{delay_phase_space_recurrences.pdf}
        \label{fig:phase_space_B}
    }

    \subfigure[Thresholded RP]{
        \frame{\includegraphics[width=0.4\columnwidth]{RecurrencePlot.png}}
        \label{fig:method:rp:thresholded}
    }
    \subfigure[Unthresholded RP]{
        \frame{\includegraphics[width=0.4\columnwidth]{RecurrencePlotUnthresholded.png}}
        \label{fig:method:rp:unthresholded}
    }

    \caption{\subref{fig:methodology:signal} Example of artificial signal, where the variable $t$ represents the time instant and $f(t)$ denotes the signal magnitude. 
    \subref{fig:phase_space_A} encodes the illustrated signal in the time delay phase space without temporal information. Its parameters are dimension $d=2$ and delay $\tau=\RPDelay$. \subref{fig:phase_space_B} is almost the same but with the recurrences represented by red lines $\vec{s_i} - \vec{s_j}$ that links the pair of near points that have a distance below $\varepsilon=\RPThreshold$.
    \subref{fig:method:rp:thresholded} displays the thresholded recurrence plot where binary values indicate proximal points, whereas \subref{fig:method:rp:unthresholded} presents the unthresholded version representing the continuous distance matrix.
    }
    \label{fig:phase_space}
\end{figure}



Subsequently, a recurrence matrix $RP_{m \times m}$ is constructed where each element $RP_{i,j} \in \{0,1\}$ the occurrence of a recurrence between a pair of pointss $\left(\vec{s_i},\vec{s_j}\right)$ within the phase space $S$. We can represent this concept by measuring the distance $||\vec{s_i} - \vec{s_j}||$ between the points of the pair and verifying if it is smaller than a threshold $\varepsilon \in \mathbb{R}$, as the following equation:
%\begin{equation}
$
    RP_{i,j} = \mathcal{H}(\varepsilon - ||\vec{s_i} - \vec{s_j}||),
$
%\end{equation}
where $\mathcal{H}: \mathbb{R} \mapsto \{0,1\}$ is the Heaviside function. Alternativelly, we can produce an unthresholded version $RP'_{m \times m}$ by attributing to each cell $RP'_{i,j} \in \mathbb{R}$ the points distance:
%\begin{equation}
$
RP'_{i,j} = ||\vec{s_i} - \vec{s_j}||.
$
%\end{equation}  
$RP$ and $RP'$ are illustrated in Figures~\ref{fig:method:rp:thresholded} and \ref{fig:method:rp:unthresholded}, respectively.


\begin{figure}[t!]
    \centering

    \subfigure[Example of a signal represented in polar coordinate.]{
        \includegraphics[width=0.9\columnwidth, trim={4cm 4cm 4cm 4cm}, clip]{polar.png}
        \label{fig:methodology:polar}
    }

    \subfigure[\gls{GADF}]{
        \frame{\includegraphics[width=0.47\columnwidth]{GramianAngularDifferenceField.png}}
        \label{fig:method:gaf:gadf}
    }
    \subfigure[\gls{GASF}]{
        \frame{\includegraphics[width=0.47\columnwidth]{GramianAngularSummationField.png}}
        \label{fig:method:gaf:gasf}
    } 
    \caption{The example signal corresponding \acrlong{GADF} \subref{fig:method:gaf:gadf} and \acrlong{GASF} \subref{fig:method:gaf:gasf}.}
    \label{fig:method:gaf}
\end{figure}






\subsection{Gramian Angular Field}

The work of Oates et al.~\cite{gaf-mtf-1} introduced the \gls{GAF} method. This method, in summary, encodes the signal into angular relationships between pair of points. The first step to do this is to convert the signal $X=\{x_1,x_2,\cdots,x_n\}$, with $x_i \in \mathbb{R}$, $n \in \mathbb{N}$ samples, and time instants $\{t_1,t_2,...,t_n\}$, into a polar coordinate series $P=\{p_1,p_2,\cdots,p_n\}$ with $p_i \in \mathbb{R}$. One manner to do that is to associate the time $i \in \mathbb{N}$ to the radius $r_i \in \mathbb{R}$ and the value $x_i \in \mathbb{R}$ to the angle by the inverse of the cosine as follows:
\begin{align}
\begin{split}
    p_i(r_i, \phi_i) & = f_{\sphericalangle}(t_i, x_i) \\
        & = 
        \begin{cases} 
            \phi_i = \arccos(x_i), & -1 \leq x_i \leq 1\\
            r_i = \frac{t_i}{N},     & N \in \mathbb{R}
        \end{cases},
\end{split}
\end{align}
where $N$ is a rescaling factor. Notice that it might be necessary to rescale the signal to fit each $x_i$ in the range $[-1,1]$. Figure~\ref{fig:methodology:polar} shows the application of the function $f_{\sphericalangle}$ over the example signal. The polar coordinate system has one property of interest: the $f_{\sphericalangle}: \mathbb{N} \times \{x \in \mathbb{R}| -1 \leq x \leq 1\} \mapsto \mathbb{R} \times \{\phi \in \mathbb{R}| 0 \leq \phi \leq \pi \}$ is bijective, since it has the inverse function 
\begin{equation}
f_{\sphericalangle}^{-1}(r_i, \phi_i)=(r_i \cdot N, \cos(\phi_i))=(t_i,x_i).
\end{equation}
This indicates that the application of the function $f_{\sphericalangle}$ does not result in loss of information.




The second step is to construct the temporal relationship matrix. We can achieve that by two methods that exploit trigonometric properties. One of them is calculating the cosine of the summation of the pairs of angles, constructing the matrix $\text{GASF}_{n \times n}$:
\begin{align}
\begin{split}
    \text{GASF}_{i,j}     & = \cos(\phi_i + \phi_j) \\
            & = \cos(\phi_i) \cdot \cos(\phi_j) - \sin(\phi_i) \cdot \sin(\phi_j) \\
            & = x_i \cdot x_j - \sqrt{1 - x_i^2} \cdot \sqrt{1 - x_j^2}, \label{eq:gasf:algebraic}
\end{split}
\end{align}
where \gls{GASF} is the final matrix. Due to the inversibility of the $arccos$ function, it is possible to express that calculation without trigonometric operations, as expressed by the equality \ref{eq:gasf:algebraic}. Thus, we can calculate \gls{GASF} using matrix operations, as follows:  
\begin{equation}
    \text{GASF} = X^T \cdot X - \sqrt[\circ 2]{\mathds{1}-X^{\circ 2}}^T \cdot \sqrt[\circ 2]{\mathds{1}-X^{\circ 2}},
\end{equation}
where $M^{\circ 2}$ and $\sqrt[\circ 2]{M}$ represents the element-wise square power and square root of the matrix $M$, respectively, and $\mathds{1}$ is a matrix in which all elements are $1$. The other method is analogous, but uses the sine of the difference of the pairs of angles, constructing the following matrix $\text{GADF}_{n \times n}$:
\begin{align}
\begin{split}
    \text{GADF}_{i,j} & = \sin(\phi_i - \phi_j) \\
        & = \sin(\phi_i) \cdot \cos{\phi_j} - \cos(\phi_i) \cdot \sin(\phi_j) \\
        & = \sqrt{1 - x_i^2} \cdot x_j - x_i \cdot \sqrt{1 - x_j^2},  \label{eq:gadf:algebraic}
\end{split}
\end{align}
Also similarly, by the equality \ref{eq:gadf:algebraic}, we can express \gls{GADF} by matrix operations:
\begin{equation}
    \text{GADF} = \sqrt[\circ 2]{\mathds{1} - X^{\circ 2}}^T \cdot X - X^T \cdot \sqrt[\circ 2]{\mathds{1} - X^{\circ 2}}.
\end{equation}
Figure~\ref{fig:method:gaf} illustrates the \gls{GASF} and \gls{GADF} representations of the example signal depicted in Figure~\ref{fig:methodology:signal}.






\begin{figure*}[t!]
    \centering

    \subfigure[Signal segment.]{
        \includegraphics[width=0.46\textwidth, trim={2em 3em 2em 4em}, clip]{QuantileBins.png} 
        \label{fig:method:mtf_signals}
    }
    \subfigure[MTF transitions Markov chain.]{
        \includegraphics[width=0.28\textwidth, trim={1em 1em 1em 1em}, clip]{MarkovChain.pdf}
        \label{fig:method:markov_chain}
    }
    \subfigure[MTF projection]{
        \frame{\includegraphics[width=0.205\textwidth]{MarkovTransitionField.png}}
        \label{fig:method:mtf}
    } 
    
    \caption{Original signal segmented into quantile bins \subref{fig:method:mtf_signals}, the Markov chain representing the transitions of the signal depicted in Figure~\ref{fig:method:mtf_signals} \subref{fig:method:markov_chain}, and the \gls{MTF} of the example signal with the number of quantile bins $m=8$ \subref{fig:method:mtf}.}
    \label{fig:method:mtf_method}
\end{figure*}


\subsection{Markov Transition Field}

Oates et al.~\cite{gaf-mtf-1} proposed the \gls{MTF} as well, based on a signal to graph mapping of Campanharo et al.~\cite{mtf-1}. In fact, that mapping is the first step of this method. We map the signal $X=\{x_1,x_2,...,x_n\}$, with $x_i \in \mathbb{R}$, to a graph $G=(N,W)$, with nodes set $N$ and edges weights adjacency matrix $W$. Its nodes $N$ corresponds to $m \in \mathbb{N}$ quantile bins $Q_i \subseteq \{x_i | i \in \{1,2,...,n\}\}$, that is, $|Q_1|=|Q_2|=...=|Q_n|$ and, $\forall q_1 \in Q_1, \forall q_2 \in Q_2, ..., \forall q_n \in Q_n$, we have that $q_1 \leq q_2 \leq ... \leq q_n$. In other words, those quantiles bins separate the signal $X$ into bands $Q_i$ with equal amount of samples $x_i$. Figure~\ref{fig:method:mtf_signals} pictures this concept for the example signal. The other graph component, its edges, are directed and corresponds to the probability of a sample $x_{k+1}$, consecutive to a uniformly randomly chosen sample of a certain quantile $x_k \in Q_i$ (must have a consecutive), belonging to a certain quantile $Q_j$. Those edges are akin to transitions of first-order Markov chains, since the probabilities summation of the transitions that sources from a state is always equal to $100\%$.

The adjacency matrix $W_{m \times m}$ can be expressed as:  
\begin{equation}
    W_{i,j} = \frac{
    \sum\limits_{k=1}^{n-1} \mathbb{I}(x_k \in Q_i \text{ and } x_{k+1} \in Q_j)
    }{
    \sum\limits_{k=1}^{n-1} \mathbb{I}(x_k \in Q_i)
    }
\end{equation}
where the indicator function
\begin{equation}
    \mathbb{I}_Q(x) = \begin{cases}
        0, & x \not\in Q \\
        1, & x \in Q
    \end{cases}
\end{equation}
ensures that for every coordinate $(i, j)$ in the resulting matrix, the specific transition probability $W_{u,v}$ is selected according to the bins where the $i$-th and $j$-th samples reside. This mathematical formulation establishes a rigorous mapping from the 1D signal domain to the 2D image domain.
This shows that the value at coordinates $(i, j)$ in the \gls{MTF} is the transition probability $W_{u,v}$ between the quantiles that contain samples $x_i$ and $x_j$.
Figure~\ref{fig:method:markov_chain} depicts the graph of the example signal. This graph $G$ enables a representation  $X' = \{ x'_1,x'_2,\cdots,x'_n \}$  of the input signal $X$ by iteratively selecting a sample from the current quantile node and transitioning to the subsequent node based on the transition probabilities.

Algorithm~\ref{alg:mtf_reconstruction} details this representation, while Figure~\ref{fig:method:mtf_signals} illustrates its application to the example signal. Consequently, the signal conversion to this graph representation is probabilistically reversible. This characteristic ensures that the statistical information of the signal is preserved, even though an exact recovery of the original values is not guaranteed.
Since that graph does not retain temporal relationships, the second step of the \gls{MTF} method is to build the matrix $\text{MTF}_{n \times n}$ by explicitly mapping the signal indices to the quantile bins:
\begin{equation}
    %\text{MTF}_{i,j} = W_{u,v} | x_i \in Q_u, x_j \in Q_v,
    \text{MTF}_{i,j} = W_{u,v} \quad \text{where} \quad x_i \in Q_u, x_j \in Q_v,
\end{equation}
where each cell $\text{MTF}_{i,j}$ contains the transition probability between the quantiles $(Q_u,Q_v)$ to which the samples $(x_i,x_j)$ belong.
Figure~\ref{fig:method:mtf} pictures the final result of the method applied to the example signal. 



\begin{algorithm}[t!]
    \begin{algorithmic}
        \Require Graph $G=(N=\{Q_1, Q_2, ..., Q_m\},W)$
        \Ensure Reconstructed Signal $X'=x'_1,x'_2,...,x'_n$
        \State $Q_{current} \gets Q \in_R N$ 
        \For {$k \in 1,2,...,n$}
            \State $x'_k \gets x \in_R Q_{current}$
            \State $Q_{current} \gets Q_{next}$, with probability $W_{current,next}$
        \EndFor
    \end{algorithmic}
    \caption{The probabilistic signal representation algorithm. }
    \label{alg:mtf_reconstruction}
\end{algorithm}


\subsection{VisionPPG: Computer vision using projection mix}

The fundamental objective of signal projection methods is to map the morphological properties and temporal dynamics of a signal into distinct visual patterns.
This concept is highly applicable to the assessment of signal quality.
Figure~\ref{fig:method:noises} illustrates the influence of various noise types on the visual characteristics of these projections.
Notably, the presence of low-frequency or high-frequency interference tends to produce macro-scale or micro-scale structures, respectively.
For instance, baseline wander manifests as a limited number of large-scale structures while high-frequency noise generates fine, granular patterns.
Furthermore, localized noise often creates cross-like artifacts in the projection space as shown in the local noise column of Figure~\ref{fig:method:noises}.
The sensitivity of these projections is also evident in the presence of Gaussian or impulsive noise. Gaussian noise tends to preserve high-level structural features while obscuring finer details, whereas impulsive noise generates distinct vertical and horizontal lines.
Consequently, these projections are suitable for \gls{SQI} estimation using computer vision models because they represent noise characteristics as discernible visual features that these architectures are designed to identify.



{
\newcommand{\NoisesImageWidth}{0.2\textwidth}
\begin{figure*}[t!]
    \centering
    {
    \def\arraystretch{1}
    \setlength{\tabcolsep}{2pt}
    \adjustbox{max width=\textwidth}{
        \begin{tabular}{ccccccc}
            ~
            & Base signal
            & Gaussian Noise
            & Salt-and-Pepper
            & Baseline Wander 
            & HFN
            & Local Noise \\
            
            \rotatebox{90}{\hspace{1em} Signal}
            & \includegraphics[width=\NoisesImageWidth, trim={5.55em 2.5em 4.45em 2.7em}, clip]{signal(base).png}
            & \includegraphics[width=\NoisesImageWidth, trim={5.55em 2.5em 4.45em 2.7em}, clip]{signal(gaussian).png}
            & \includegraphics[width=\NoisesImageWidth, trim={5.55em 2.5em 4.45em 2.7em}, clip]{signal(salt_and_pepper).png} 
            & \includegraphics[width=\NoisesImageWidth, trim={5.55em 2.5em 4.45em 2.7em}, clip]{signal(baseline_wander).png} 
            & \includegraphics[width=\NoisesImageWidth, trim={5.55em 2.5em 4.45em 2.7em}, clip]{signal(low_frequency_noise).png} 
            & \includegraphics[width=\NoisesImageWidth, trim={5.55em 2.5em 4.45em 2.7em}, clip]{signal(local_noise).png} \\
            
            \rotatebox{90}{\hspace{3em} GADF}
            & \frame{\includegraphics[width=\NoisesImageWidth]{GramianAngularDifferenceField(base).png}}
            & \frame{\includegraphics[width=\NoisesImageWidth]{GramianAngularDifferenceField(gaussian).png}} 
            & \frame{\includegraphics[width=\NoisesImageWidth]{GramianAngularDifferenceField(salt_and_pepper).png}} 
            & \frame{\includegraphics[width=\NoisesImageWidth]{GramianAngularDifferenceField(baseline_wander).png}} 
            & \frame{\includegraphics[width=\NoisesImageWidth]{GramianAngularDifferenceField(low_frequency_noise).png}} 
            & \frame{\includegraphics[width=\NoisesImageWidth]{GramianAngularDifferenceField(local_noise).png}} \\
            
            \rotatebox{90}{\hspace{3em} GASF}
            & \frame{\includegraphics[width=\NoisesImageWidth]{GramianAngularSummationField(base).png}}
            & \frame{\includegraphics[width=\NoisesImageWidth]{GramianAngularSummationField(gaussian).png}} 
            & \frame{\includegraphics[width=\NoisesImageWidth]{GramianAngularSummationField(salt_and_pepper).png}} 
            & \frame{\includegraphics[width=\NoisesImageWidth]{GramianAngularSummationField(baseline_wander).png}} 
            & \frame{\includegraphics[width=\NoisesImageWidth]{GramianAngularSummationField(low_frequency_noise).png}} 
            & \frame{\includegraphics[width=\NoisesImageWidth]{GramianAngularSummationField(local_noise).png}} \\
            
            \rotatebox{90}{\hspace{4em} RP}
            & \frame{\includegraphics[width=\NoisesImageWidth]{RecurrencePlotUnthresholded(base).png}}
            & \frame{\includegraphics[width=\NoisesImageWidth]{RecurrencePlotUnthresholded(gaussian).png}} 
            & \frame{\includegraphics[width=\NoisesImageWidth]{RecurrencePlotUnthresholded(salt_and_pepper).png}} 
            & \frame{\includegraphics[width=\NoisesImageWidth]{RecurrencePlotUnthresholded(baseline_wander).png}} 
            & \frame{\includegraphics[width=\NoisesImageWidth]{RecurrencePlotUnthresholded(low_frequency_noise).png}} 
            & \frame{\includegraphics[width=\NoisesImageWidth]{RecurrencePlotUnthresholded(local_noise).png}} \\
            
            \rotatebox{90}{\hspace{3em} MTF}
            & \frame{\includegraphics[width=\NoisesImageWidth]{MarkovTransitionField(base).png}}
            & \frame{\includegraphics[width=\NoisesImageWidth]{MarkovTransitionField(gaussian).png}} 
            & \frame{\includegraphics[width=\NoisesImageWidth]{MarkovTransitionField(salt_and_pepper).png}} 
            & \frame{\includegraphics[width=\NoisesImageWidth]{MarkovTransitionField(baseline_wander).png}} 
            & \frame{\includegraphics[width=\NoisesImageWidth]{MarkovTransitionField(low_frequency_noise).png}} 
            & \frame{\includegraphics[width=\NoisesImageWidth]{MarkovTransitionField(local_noise).png}} 
        \end{tabular}
    }
    }
    \caption[The signal, its impaired versions, and their corresponding 2D projections.]{The signal, its impaired versions, and their corresponding 2D projections. From top to bottom: \acrlong{GADF}, \acrlong{GASF}, \acrlong{RP}, and \acrlong{MTF}.}
    \label{fig:method:noises}
\end{figure*}
}




\begin{figure}[t!]
    \centering

    \subfigure[Proposed \gls{PPG} \gls{SQA} framework.]{
        \includegraphics[width=0.96\columnwidth]{method.png}
        \label{fig:method}
    } 
    \subfigure[Channel adaptations.]{
        \includegraphics[width=0.96\columnwidth]{input_layer.png}
        \label{fig:input_layer}
    }

    \caption{Components of VisionPPG. The whole pipeline is illustrated in \subref{fig:method}, while \subref{fig:input_layer} depicts the four-channel of projection mix is convolved with a $1 \times 1$ convolution filter to produce the three-channel input layer used in the \gls{CV} classifier.}
    \label{fig:visionppg}
\end{figure}

Each projection captures distinct signal features and are consequently integrated into a unified ensemble by fusing them into an aggregated tensor. This structure, termed \gls{PMix}, is analogous to a hyperspectral image because it provides multiple information layers beyond the three channels of a standard color image. The \gls{PMix} framework assigns each projection to a specific channel of the input layer which is subsequently processed via a pointwise convolution operation using a $1 \times 1$ kernel. Formally, the input tensor $T_{in}$ with dimensions $p \times n \times m$ is constructed by stacking $p$ projections $\{M_1, M_2, \dots, M_p\}$ of identical dimensions $n \times m$ such that $T_{in_{k,i,j}} = M_{k_{i,j}}$. This tensor is then transformed into a mixed representation $T_{mix_{q \times n \times m}}$ as follows:
\begin{equation}
    %T_{mix_{k,i,j}} = \mathcal{A}\left(\sum\limits_{l=1}^{p}T_{in_{l,i,j}} \cdot w_{(k,i,j);l}\right),
    T_{mix_{k,i,j}} = \mathcal{A}\left(\sum_{l=1}^{p} T_{in_{l,i,j}} \cdot w_{k,l} + b_k\right),
\end{equation}
where $w_{(k,i,j);l} \in \mathbb{R}$ denotes the weight applied to the connection between the output tensor cell $T_{mix_{k,i,j}}$ and the input tensor cell $T_{in_{l,i,j}}$. The term $\mathcal{A}: \mathbb{R} \to \mathbb{R}$ represents an activation function, such as ReLU, sigmoid, or Softmax. This relationship can be expressed in terms of the input projections as follows:
\begin{equation}
    \label{eq:mix}
    %T_{mix_{k,i,j}} = \mathcal{A}\left(\sum\limits_{l=1}^{p}M_{l_{i,j}} \cdot w_{(k,i,j);l}\right).
    T_{mix_{k,i,j}} = \mathcal{A}\left(\sum_{l=1}^{p} M_{l,i,j} \cdot w_{k,l} + b_k\right)
\end{equation}
For each spatial coordinate $(i,j)$, the summation integrates the $p$ projections by aggregating the values $M_{l,i,j}$ according to the learnable weights $w_{k,l}$.
Subsequently, the activation function $\mathcal{A}$ is applied to the result to produce the final tensor value $T_{mix_{k,i,j}}$.
This integration framework is illustrated in Figure~\ref{fig:input_layer} within the context of models pre-trained on three-channel datasets.
Furthermore, this process may incorporate a resizing step to ensure compatibility with model input requirements because pointwise convolution preserves the original spatial dimensions of the projections.


Based on the \gls{PMix} projection method, this work proposes a novel \gls{SQA} framework as illustrated in Figure~\ref{fig:method}. The process begins by transforming the signal into four distinct projections using the aforementioned \gls{GAF}, \gls{MTF}, and \gls{RP} algorithms. These projections are subsequently integrated into an aggregated tensor by assigning each to a specific channel of a newly defined input layer. This multi-channel layer serves as the input for a computer vision model initialized with weights pre-trained on the ImageNet dataset~\cite{ImageNet}. Finally, the model performs binary classification to assess the signal quality, categorizing the input as either acceptable or unacceptable for clinical use.










\section{Experimental Setup} \label{sec:setup}


Signal quality assessment is formulated in this study as a supervised classification task where a model learns to map input signals $X$ to their corresponding quality labels $y$.
These labels represent binary categories identifying signals as either acceptable or unacceptable for clinical analysis.
To train the predictive models and evaluate their performance on heartbeat time series, the \gls{BUTPPG}~\cite{butppg} dataset was utilized.
Given that this repository currently constitutes the only publicly available dataset for this specific domain, it serves as the primary benchmark for the proposed methodology while providing a foundation for future studies involving novel datasets.


The \glsxtrlong{BUTPPG} is a publicly available database produced by the Department of Biomedical Engineering at Brno University of Technology. It contains samples of \gls{PPG} signals, their quality labels, and heart rate estimations.
The \gls{PPG} signals were acquired via smartphone-based photoplethysmography, leveraging the device's camera and \gls{LED} source to detect subcutaneous volumetric changes.
Specifically, the researchers recorded the subject's index finger while it covered the camera lens and its \gls{LED} light. For each video frame, they measured the average intensity of the red channel across all image pixels, resulting in a time series of averages. Finally, the signal was inverted. %The Figure \ref{fig:butppg_samples} shows examples of the results of such a sequence of procedures.  

The data acquisition process involved 48 \gls{PPG} recordings collected from 12 subjects with each participant providing four distinct measurements.
These recordings were obtained under two specific conditions including a static seated position and an ambulatory walking state.
The static condition typically yielded high-quality signals whereas the ambulatory state was prone to motion artifacts and lower quality recordings.
Because the walking condition was performed only once per subject, approximately 25\% of the dataset is categorized as low-quality.
Consequently, the dataset exhibits a class imbalance that was addressed through specific mitigation techniques during the experimental phase..


To establish signal quality labels, five experts estimated heart rates from the \gls{PPG} signals using custom software.
These estimations were validated against a gold standard derived from concurrently recorded \gls{ECG} signals that were manually synchronized during acquisition.
An estimation was considered accurate if the absolute deviation from the \gls{ECG} reference was 5 \gls{BPM} or less.
A \gls{PPG} signal was categorized as high quality if at least three of the five experts achieved this accuracy threshold.
Consequently, these labels serve as a proxy for the interpretability of the signal and the feasibility of manual heart rate detection.




\subsection{Dataset split}


The experimental evaluation utilized a \gls{LOSO} cross-validation strategy to maximize the utility of the limited \gls{BUTPPG} dataset. 
Given that \gls{BUTPPG} contains only 12 subjects, the data was partitioned into $K=12$ folds where each fold reserved a single subject for testing while the remaining 11 subjects were used for training.
This subject-level partitioning is essential to prevent data leakage because the inclusion of signals from the same subject in both training and testing sets would introduce significant bias and artificially inflate performance results.
By adopting this approach, every sample is utilized as a test case across the $K$ iterations while maintaining strict subject independence.
Furthermore, the training partition of each fold was subdivided to create a validation set comprising three subjects for hyperparameter optimization and early stopping.
The results presented in this papers correspond to the mean ($\mu$) accuracy of these multiple folds along with its standard deviation ($\sigma$).


\subsection{Compared techniques}

To evaluate the proposed projection-based framework and identify specific cases of superior performance, it was necessary to involve a large number of machine learning models.
Firstly, this work compared the projection-based framework with other time series classification approaches using the Aeon Toolkit~\cite{aeon2024}, with the models listed in Table~\ref{tab:non_cv_list}.
Furthermore, the proposed method was combined with a wide variety of classification \gls{CV} models, utilizing the PyTorch library~\cite{pytorch}, which supports a diverse range of neural network architectures.
These architectures vary from simple convolutional networks to vision transformers.
Table~\ref{tab:cv_list} lists all the \gls{CV} models involved in our experiments, which are briefly described in the following subsections.


\begin{table}[t!]
    \centering
    \caption{Tested \gls{SOTA} models that \textit{are not} based on computer vision.}
    \adjustbox{max width=\columnwidth}{
    \begin{tabular}{llc}
        \toprule    
        Classification         & Model                 & Reference             \\
         \midrule    
         Convolution-Based    & Arsenal                & \cite{HIVECOTEV2}        \\
                     & Rocket Classifier            & \cite{RocketClassifier}    \\
         Deep Learning        & Zhao’s CNN Classifier            & \cite{CNNClassifier}        \\
                     & Wang's FCN Classifier            & \cite{FCNClassifier-MLPClassifier}\\
                     & Wang's MLP Classifier            & \cite{FCNClassifier-MLPClassifier}\\
                     & Inception Time Classifier        & \cite{Inception1}\cite{Inception2}\\
                     & Individual Inception Classifier    & \cite{Inception1}\cite{Inception2}\\
                     & LITE Time Classifier            & \cite{LITETimeClassifier}    \\
         Dictionary-Based    & BOSS Ensemble                & \cite{BOSSEnsemble}        \\
                     & Contractable BOSS            & \cite{ContractableBOSS}    \\
                     & Individual BOSS            & \cite{BOSSEnsemble}        \\
                     & Individual TDE            & \cite{TDE}            \\
                     & MUSE                    & \cite{MUSE}            \\
                     & TemporalDictionaryEnsemble        & \cite{TDE}            \\
                     & WEASEL                & \cite{WEASEL}            \\
                     & WEASEL V2                & \cite{WEASELV2}        \\
                     & REDCOMETS                & \cite{REDCOMETS-1}\cite{REDCOMETS-2}\\
         Distance-Based        & Elastic Ensemble            & \cite{ElasticEnsemble}    \\
                     & K-Neighbors Time Series Classifier    & ---                \\
                     & Shape DTW                & \cite{ShapeDTW}        \\
         Feature-Based        & Catch-22 Classifier            & \cite{Catch22Classifier}    \\
                     & Summary Classifier            & ---                \\
                     & TS Fresh Classifier            & \cite{TSFreshClassifier}      \\
         Inverval-Based        & Interval Forest Classifier    & \cite{CanonicalIntervalForestClassifier}\\
                     & DrCIFClassifier            & \cite{HIVECOTEV2}        \\
             & Random Interval Spectral Ensemble Classifier & \cite{RandomIntervalSpectralEnsembleClassifier}\\
                     & Supervised Time Series Forest        & \cite{SupervisedTimeSeriesForest}\\
                     & Time Series Forest Classifier        & \cite{TimeSeriesForestClassifier}\\
                     & Random Interval Classifier        & ---                \\
         Shapelet-Based        & Shapelet Transform Classifier        & \cite{ShapeletTransformClassifier-1}\cite{ShapeletTransformClassifier-2}\\
                     & RDST Classifier            & \cite{RDSTClassifier-1}\cite{RDSTClassifier-2}\\
         Ordinal Classification    & Individual Ordinal TDE        & \cite{OrdinalTDE}        \\
                     & Ordinal TDE                & \cite{OrdinalTDE}        \\
         Other            & Continuous Interval Tree        & \cite{ContinuousIntervalTree}    \\
                     & Rotation Forest Classifier        & \cite{RotationForestClassifier}\\
        \bottomrule
    \end{tabular}
    }
    \label{tab:non_cv_list}
\end{table}



\begin{table}[t]
    \centering
    \caption{Neural architectures considered as computer vision classifier.}
    \adjustbox{max width=\columnwidth}{
    \begin{tabular}{llcc}
        \toprule    
        Classification         & Model         & Reference             \\
         \midrule    
        Transformer            & Vision Transformer    & \cite{VisionTransformer}    \\
                       & MaxViT        & \cite{MaxViT}            \\
                       & Swin Transformer    & \cite{SwinTransformer}    \\
                       & Swin Transformer V2    & \cite{SwinTransformerV2}    \\
        Residual Net           & ResNet        & \cite{ResNet}            \\
                     & ResNeXt        & \cite{ResNeXt}        \\
                     & WideResNeXt        & \cite{WideResNet}        \\
        Extreme Net           & DenseNet        & \cite{DenseNet}        \\
                     & VGG            & \cite{VGG}            \\
                    & SqueezeNet        & \cite{SqueezeNet}        \\
        Mobile-Oriented        & MNASNet        & \cite{MNASNet}        \\
                    & MobileNet V2        & \cite{MobileNetV2}        \\
                    & MobileNet V3        & \cite{MobileNetV3}        \\
        Efficiency-Oriented    & EfficientNet        & \cite{EfficientNet}        \\
                    & EfficientNet V2    & \cite{EfficientNetV2}        \\
                    & ShuffleNet V2        & \cite{ShuffleNetV2}        \\
        Diverse              & AlexNet        & \cite{AlexNet}        \\
                    & ConvNeXt        & \cite{ConvNeXt}        \\
                     & RegNet        & \cite{RegNet}            \\
        \bottomrule
    \end{tabular}
    }
    \label{tab:cv_list}
\end{table}



\subsubsection{Transformers}

The evaluation encompassed four transformer architectures including \gls{ViT}, \gls{MaxViT}, \gls{SwinT}, and \gls{SwinTV2}.
The \gls{ViT} model processes visual input as a sequence of linear embeddings derived from fixed-size image patches obtained by partitioning the original image into a grid~\cite{VisionTransformer}.
Subsequent architectures refine this approach by modifying attention mechanisms to improve feature extraction.
For instance, \gls{MaxViT} employs blocks that alternate between grid-based and block-based self-attention to capture dependencies at both high and low granularities~\cite{MaxViT}.
Similarly, the \gls{SwinT} architecture utilizes a hierarchical structure that merges patches across layers and implements shifted window self-attention to facilitate connectivity between adjacent windows~\cite{SwinTransformer}.
Finally, \gls{SwinTV2} introduces architectural refinements to enhance training stability and scaling capacity compared to the original version~\cite{SwinTransformerV2}.

\subsubsection{Residual nets}

ResNet introduced residual connections which consist of links between non-adjacent layers that bypass intermediate processing stages to mitigate the vanishing gradient problem~\cite{ResNet}.
In this paper, we evaluated two significant architectural variations including Wide ResNet and ResNeXt.
Wide ResNet enhances the original framework by increasing the number of channels per block to provide an alternative to increasing network depth~\cite{WideResNet}.
In contrast, ResNeXt employs a multipath approach that aggregates parallel transformations through an additive operation~\cite{ResNeXt}.
Rather than focusing solely on width and depth, ResNeXt introduces cardinality as an additional enhancement dimension .

\subsubsection{Mobile Nets}

Mobile-oriented models are defined in this study as neural networks specifically engineered to operate within stringent hardware constraints.
The evaluation encompasses three primary architectures including MNASNet~\cite{MNASNet}, MobileNet V2~\cite{MobileNetV2}, and MobileNet V3~\cite{MobileNetV3}.
MobileNet V2 optimizes memory efficiency and predictive accuracy through the implementation of inverted residual blocks~\cite{MobileNetV2}.
These blocks utilize thin bottleneck layers for skip connections while expanding the channel dimensions internally, which effectively reduces the total parameter count.

In contrast, MNASNet utilizes a reinforcement learning approach to select optimal architectural blocks that fit a predefined skeleton, thereby maximizing performance on physical mobile hardware~\cite{MNASNet}.
Finally, MobileNet V3 integrates these structural advancements and incorporates the NetAdapt~\cite{NetAdapt} algorithm into the automated search process to further refine the balance between latency and accuracy~\cite{MobileNetV3}.

\subsubsection{Extreme Nets}

We categorize as extreme nets the neural models that prioritize the maximization of specific design parameters including layer depth, model compression, or advanced residual connectivity.
These architectures represent the frontiers of model scaling and efficiency by pushing the theoretical limits of network design to improve feature extraction capabilities.
This category includes VGG~\cite{VGG}, DenseNet~\cite{DenseNet}, and SqueezeNet~\cite{SqueezeNet}. VGG utilizes $3 \times 3$ filters to facilitate deeper architectures by increasing the total number of layers~\cite{VGG}.
DenseNet employs skip connections between all pairs of architectural blocks which positions each layer closer to both the input and the output to enhance performance~\cite{DenseNet}.
SqueezeNet minimizes memory usage through model compression and the introduction of a specialized architectural module that reduces channel density before applying large convolution filters~\cite{SqueezeNet}.
This strategy significantly reduces the parameter count compared to convolutions applied to layers with a large number of channels~\cite{SqueezeNet}.

\subsubsection{Efficient Nets}

\hyphenation{Shuffle-Net}

This paper categorizes efficiency-oriented networks as architectures engineered for optimal resource utilization to maximize predictive performance while minimizing parameter counts.
Notable examples include ShuffleNetV2~\cite{ShuffleNetV2}, EfficientNet~\cite{EfficientNet}, and EfficientNetV2~\cite{EfficientNetV2}.
ShuffleNet V2 enhances the original architecture by utilizing the channel shuffle operator to facilitate information exchange across feature maps.

It improves upon its predecessor by incorporating a channel split operation within each block to eliminate the overhead associated with grouped convolutions.
This design ensures high computational efficiency by maintaining a balanced channel width and minimizing element-wise operations.
Furthermore, the EfficientNet series utilizes compound scaling to uniformly scale depth, width, and resolution, thereby achieving state-of-the-art accuracy with significantly reduced \glspl{FLOP}.

EfficientNet optimizes model performance through a compound scaling method that proportionally increases network depth, width, and resolution~\cite{EfficientNet}.
This approach establishes a highly efficient baseline architecture that remains effective across various model scales while preserving structural integrity.

EfficientNetV2 enhances EfficientNet by incorporating non-proportional scaling and leveraging neural architecture search to optimize training speed and parameter efficiency~\cite{EfficientNetV2}.
Furthermore, EfficientNetV2 introduces a progressive learning to gradually increase both the input resolution and regularization during the training process~\cite{EfficientNetV2}.
This technique ensures higher accuracy while significantly reducing the computational overhead required for convergence.

\subsubsection{Diverse}

The remaining models not included in the previously mentioned were grouped in this category. It includes AlexNet, ConvNeXt, and RegNet. 
Introduced in 2012, AlexNet was one of the earliest deep learning models designed to be trained across multiple GPUs, which accelerated the training process and utilized dropout to mitigate overfitting~\cite{AlexNet}.
In contrast, ConvNeXt, a modern model from 2022, integrates various convolutional techniques from recent years, such as patchified convolutions, inverted bottlenecks, and grouped convolutions, with the goal of advancing traditional convolutional networks~\cite{ConvNeXt}.
Furthermore, RegNet shifts the focus from individual network design to the creation of network families defined by linear parameter spaces which facilitates efficient architectural search within these populations~\cite{RegNet}.
The inclusion of these diverse models ensures a comprehensive evaluation of the \gls{PMix} framework across both historical and state-of-the-art architectural paradigms.



\subsection{Defining the hyperparameters}

However, defining the models alone is insufficient, as the selection of their hyperparameters is also required. Hyperparameters are parameters related to the learning process, rather to the model itself. For the Aeon models, the default hyperparameters provided by the library were used for convenience reasons, even though they are not the optimal ones. For the computational vision models, while most hyperparameters were set to their defaults, our experiments employed hyperparameter search for the learning rate, used by the optimization algorithm to search for better hyperparameters than the defaults provided by the PyTorch library. The Optuna library~\cite{optuna} conducted this search by heuristically exploring the parameter space dynamically defined in the user code. Optuna prunes the search-space tree using various methods, and in our experiments, the median pruning method was applied. In this case, the guiding metric for the heuristic search was the accuracy score, defined as the ratio of correct predictions to the total number of samples. It was chosen since maximizing that ratio is desired, as the more correct predictions, the better. The accuracy was measured on a validation dataset of size equal to 2 subjects, created through a simple random split. This functionality allowed us to find a near-optimal combination of parameters without exhaustively testing all possible cases, using the model's validation dataset score as a heuristic.

\subsection{Training strategy}

Given the aforementioned models, dataset, and its divisions, it was necessary to establish the training method for adjusting the models' parameters straightforwardly.
Experiment involved feeding the models by loading the signals data, applying random oversampling before transforming them, as the dataset was unbalanced. After performing the projection transform, our experiment loaded pre-trained model weights provided by PyTorch, which were originally trained on the ImageNet~\cite{ImageNet} dataset.
Transfer learning was employed by utilizing pre-trained ImageNet weights; this leverages the model's existing capacity for low-level feature extraction (e.g., edges and textures) relevant to 2D signal projections.
Following that, we fitted the PyTorch models using the Adam optimization algorithm~\cite{Adam} to minimize the cross-entropy loss function. A reason to use that algorithm is that it surpassed some of the other options present in the PyTorch library when tested in several datasets \cite{Adam}. The implementation of the training strategy performed this optimization cycle with a number of epochs determined by a median-deviation-based early stopping technique, through the assumption that a low dispersion on the last epochs indicates a convergence to a local-optimal in the search space. The formula below gives the score of the $n$-th epoch:
\begin{equation}
    S_{ES}(n) = \operatorname*{median}_{i \in \{0, \dots, 9\}} \left( \left| l_{n-i} - \operatorname*{median}_{j \in \{0, \dots, 9\}} (l_{n-j}) \right| \right)
    %S_{ES}(n) = \text{median} \left( \left| l_{n-i} - \text{median}_{j \in \{0, \dots, 9\}} (l_{n-j}) \right| \right)_{i=0}^{9}
    %S_{ES}(n) = med([|l_{n-i} - med([l_{n-i}]_{i=0}^9)|]_{i=0}^{9}),
\end{equation}
\noindent where $l_k$ is the loss value (i.e., cross-entropy loss) of the $k$-th epoch, ${med}$ is the median and $[f(i)]_{i=0}^p$ is the sequence generated by $f(i)$ when varying $i$ from $0$ to $p$. In other words, the formula calculates the median of the absolute deviations of the medians of the last 10 loss values using the central value. If $S_{ES}(n) \leq 0.1$, the training stops in the $n$-th epoch. With that established, it remains to determine the metrics to be measured for smoother readability.

\subsection{Performance measurements}

Being established the training procedure, it is needed to choose metrics to evaluate the efficacy of the solution after the training of the model. For these experiments, we can categorize the metrics into two groups: prediction metrics, which measure the quality of the model's signal quality assessments, and benchmarking metrics, which measure resource usage and the model speed. As the prediction metrics, our experiments used the Cohen kappa score, the F1-score, and the precision, considering that they are capable of estimating the quality of binary classification through different perspectives. All of them can be evaluated using confusion matrix values, presented in Table~\ref{tab:experimentos:confusion_matrix}. The Cohen kappa score~\cite{CohenKappa}, in binary classification tasks, measures the agreement between the obtained accuracy $acc_o$ and the expected accuracy $acc_e$. The following equations define those accuracies and the Cohen kappa score:
\begin{equation}
acc_o = \frac{TP+TN}{N},
\end{equation}
and 
\begin{equation}
    acc_{e} = \frac{ (TP+FP)(TP+FN) + (TN+FP)(TN+FN) }{N^2} 
    %acc_e  = \left(\frac{TP+FP}{N} \cdot \frac{TP+FN}{N}\right) + \left(\frac{TN+FP}{N} \cdot \frac{TN+FN}{N}\right),
\end{equation}
and
\begin{equation} \label{eq:Cohen kappa}
\text{Cohen Kappa}  = \frac{acc_o - acc_e}{1 - acc_e}, 
\end{equation}  
where $N=TP+TN+FP+FN$ is the total number of samples. For the purpose of aligning this metric with others, we can rescale that metric from $[-1,1]$ to $[0,1]$:
\begin{equation}
 \text{Cohen's~} \kappa = \frac{\text{Cohen Kappa} +1}{2}.
\end{equation}  
In sequence, the precision is a metric that measures the ratio of hits in the set of positive predictions. In our context, a higher precision implies that the predictor avoided mistakenly labeling ``bad'' signals as ``good'', which is desirable in applications where we do not want to show to the user measurements based on unreliable signals. From the precision and from the recall, the ratio of hits in the set of all existing positives, we can obtain the F1-Score. Precisely, the F1-Score is the harmonic mean between those two metrics. In other words, a high F1-Score indicates a good balance between precision and recall scores. In our application, it measures the same as the precision plus the recall, which would measure the amount of ``good'' signals that would feed the application. This is an desirable quality when we want to provide constant feedback to the user. The following equations define those metrics:
\begin{equation} \label{eq:Precision}
Precision = \frac{TP}{TP+FP},
\end{equation}
\begin{equation} \label{eq:Recall}
Recall = \frac{TP}{TP+FN},
\end{equation}
and
\begin{equation} \label{eq:F1-Score}
F1 = \frac{2 \cdot TP}{2 \cdot TP + FP + FN}.
\end{equation}
Therefore, the Cohen kappa score provides an overall sense of accuracy, the F1-Score suggests the model's usability level, and precision indicates the predictor's reliability.

\begin{table}[h!]
    \centering
    \caption[Binary classification confusion matrix]{Binary classification confusion matrix, where each cell resulting from the intersection between the $i$-th line and the $j$-th colum correspond to the amount of data which was predicted as the $i$-th line label and had the $j$-th column label as the true value.}
    \adjustbox{max width=\columnwidth}{
    \begin{tabular}{c|cc}
        \toprule
        \diagbox{Predicted label}{True label} 
             & Positive  & Negative\\
        \midrule
        Positive & \Gls{TP} & \Gls{FP}\\
        Negative & \Gls{FN} & \Gls{TN}\\
        \bottomrule
    \end{tabular}
    }
    \label{tab:experimentos:confusion_matrix}
\end{table}

Regarding the benchmarking metrics, our experiment measured the memory usage of the model in bytes and the inference time (including the 1D-to-2D projection time for projection-based models) in seconds. Memory usage is crucial because practical applications for heart rate estimation often impose hardware constraints that limit allowable memory usage. Additionally, inference time is important for achieving near-instantaneous evaluations, which enhances the application's responsiveness.

\subsection{Overall schema}


\begin{figure*}[t!]
    \centering
    \includegraphics[width=0.8\textwidth]{framework.png}
    \caption[The framework of the experiment.]{The framework of the experiment. Red dotted arrows indicates data flow that sources from the \acrlong{BUTPPG} dataset, while the full black lines, labeled with an verb, represent a relationship ``A do B'', where the arrow starts on A and end on B. Notice that the figure presents the training-testing cycle for only one of the twelve folds.}
    \label{fig:framework}
\end{figure*}


Figure~\ref{fig:framework} illustrates the experiment framework applied to each combination of \acrlong{CV} model and projection algorithm. One notable difference from the framework used for non-\gls{CV} models is that the 1D-to-2D conversion acts as a boundary between the dataset and the other components. So the experiment for non-\gls{CV} models is represented using a similar schema by omitting the conversion block. The experiment began with hyperparameter selection, involving the splitting of the \gls{BUTPPG} dataset through a simple division method to subsequently select the optimal learning rate for the \gls{CV} models. With the best learning rates chosen, all models, including non-\gls{CV} models, will be evaluated using the \gls{LOSO} strategy. For each fold, our experiments subjected the model to a training procedure that iterates through epochs of training and validation until early stopping is triggered. The model is then tested to produce the metrics for that fold.




\subsection{Implementation details}

The dataset sourcing procedure was carried out using the PyTorch multithreading data feeding solution, dataloader. This was configured to load batches of size 32 for all \gls{CV} models to make the comparison more uniform, since that variable can change their performance. Prior to loading the batches, the training dataset was balanced using the Imbalanced Learn library~\cite{ImbalancedLearn2017} and its random oversampling method, since it is a open source implementation of an algorithm that equalizes the proportion of labels in the learning process, avoiding an label unbalance that our experiment design hypothesizes that it could overfit the model to a specific label, which is undesirable. The batches were then transformed from 1D signals into 2D images using the projection algorithms of the PyTS library~\cite{PyTS}, which allows the reproducibility of such transformations for being open source. Although the signals are now 2D, their width and height might not be compatible with the original network's input dimensions, especially considering pre-trained weights. To address this issue, the PyTorch resize transform was applied to adjust the width and height. Additionally, a new convolutional layer corresponding to the \gls{PMix} method was incorporated.

The \gls{CV} models were trained using a single NVIDIA\texttrademark RTX 3090 TI. For training, our implementation used the Pytorch implementation of the Adam optimization algorithm~\cite{Adam}, which uses the gradients evaluated by the Pytorch autograd engine~\cite{pytorch}. The loss class (which, in our case, is the torch.nn.CrossEntropyLoss, used for being an open source implementation of the cross entropy loss function) backpropagates the gradients based on the model forward pass errors. For the models testing, our implementation used the Sklearn's metrics~\cite{Sklearn}, since they are open source. For model memory measurement, our implementation counted the summation of the size of each parameter and buffer tensors in the \gls{CV} models, while for the non-\gls{CV} models, our implementation used the \texttt{asizeof} function of the Pympler library~\cite{Pympler}. Finally, we describe the inference time measurement, for which our implementation extracted 500 measurement samples. For the non-\gls{CV} models, our implementation used the \texttt{time} method of the Python's time module, from its standard library, to measure two time instants: the moment right before the model testing predictions, when the model is already trained; and the moment right after those predictions. Our implementation evaluates the time interval between those instants to estimate the inference time of the non-\gls{CV} model. For the \gls{CV} models, our implementation marked the time instants by using CUDA events interface provided by Pytorch, while, before measuring, performing 500 iterations to warm-up the \gls{GPU}.




\section{Results} \label{sec:results}

The results were analyzed considering the prediction performance, i.e., evaluating how effectively different machine learning models, including both vision- and non-vision-based approaches, classify signal samples as either reliable or unreliable. Moreover, following the extensive analysis presented in the subsequent subsections, the top-performing models were also evaluated with respect to memory consumption and inference time.
Prediction metrics such as Cohen's $\kappa$, F1-Score, and Precision are shown in the format $\mu \pm \sigma$, where $\mu$ and $\sigma$ represent the mean and standard deviation of the scores across \gls{LOSO} folds.
Given the large number of models tested in this research, the analysis was organized into subsections. In these subsections, the results are presented using a color-coding scheme where red denotes values at or below the first quartile, green highlights results at or above the third quartile, and blue represents values within the intermediate range.
The experimental analysis is categorized by the \gls{CV} model families listed in Table~\ref{tab:cv_list}, specifically: Transformers, Residual Nets, Mobile-Oriented, Extreme Nets, Efficiency-Oriented, and Diverse. Within each category, the optimal combinations of model variants and projection methods are identified. These results are then compared against top-performing non-\gls{CV} models selected from the Aeon toolkit~\cite{aeon2024}. Finally, the overall superior configurations are determined, and the relative performance of the projection methods is evaluated.


\subsection{Analysis by computer vision model family}
 
%This analysis covers each \gls{CV} model family listed in Table~\ref{tab:cv_list}.
 
\subsubsection{Vision Transformers}

One metric table was generated for each type of transformer.
% Vision Transformer
Table \ref{tab:Averages_of_VisionTransformer} presents the \gls{ViT} scores, with variants categorized as Base (B), Large (L), or Huge (H) in parameter size and patch sizes of 14, 16, or 32. The table shows that the \gls{PMix} and \gls{RP} projection methods achieved the best scores across all metrics. In most cases, \gls{PMix} was equal to or better than \gls{RP}, except for the \mbox{H 14} variant, where \gls{RP} was superior. Among the combinations of variants and projections, \gls{RP} and \gls{PMix} with \mbox{B 16} and \mbox{L 16}, as well as \gls{PMix} with \mbox{B 32} and \mbox{L 32}, yielded the best scores.
% MaxViT
Table \ref{tab:Averages_of_Maxvit} shows the \gls{MaxViT} scores.  For this model, the \gls{PMix} method achieved the highest scores for the Cohen Kappa and precision metrics, while the \gls{RP} surpassed it for the F1-Score, despite \gls{PMix} having the smallest dispersion for that metric.

% Swin Transformer
Table \ref{tab:Averages_of_SwinTransformer} exhibits the \gls{SwinT} scores, with variants categorized as Base (B), Small (S), or Tiny (T) based on parameter count. The \gls{RP} method achieved the best scores for the B and S variants, while the \gls{PMix} method resulted in better scores for the T variant. Specifically, the \gls{PMix} method with the T variant attained the highest Cohen Kappa and precision scores, but ranked second for the F1-Score, which was surpassed by the \gls{RP} method with the S variant.
% Swin Transformer V2
Table \ref{tab:Averages_of_SwinTransformerV2} displays the \gls{SwinTV2} scores, with variants categorized as Base (B), Small (S), or Tiny (T). The \gls{PMix} method achieved better scores for the B and S variants, while the \gls{RP} method performed better for the T variant, despite \gls{RP} having the largest dispersion for the F1-Score in this case. Specifically, the \gls{PMix} method with the S variant resulted in the highest Cohen Kappa and F1 scores, and the second-best precision, where the \gls{RP} method with the T variant was superior.

% Inter-Family Comparison
% When considering all Tables \ref{tab:Averages_of_VisionTransformer}, \ref{tab:Averages_of_Maxvit}, \ref{tab:Averages_of_SwinTransformer}, and \ref{tab:Averages_of_SwinTransformerV2}, the \gls{RP} and \gls{PMix} methods with \mbox{\gls{ViT} B 16} and \mbox{\gls{ViT} L 16}, as well as \gls{PMix} with \mbox{\gls{ViT} B 32} and \mbox{\gls{ViT} L 32}, and the \gls{SwinTV2} S with \gls{PMix}, generally achieved better scores. The benchmarking metrics for these combinations are summarized next. Table~\ref{tab:Memory_of_Transformers} shows that the \gls{SwinT} V2 S variant uses considerably less memory than the \gls{ViT} variants. Therefore, the \gls{SwinT} V2 S with \gls{PMix} can achieve high scores while utilizing less memory. However, Figure~\ref{fig:Time_of_Transformers} indicates that the \gls{SwinT} V2 S variant has a slower inference speed compared to the \gls{ViT} variants. Among the \gls{ViT} variants, the \mbox{B 32} variant was the fastest, suggesting that the combination of \gls{PMix} with \gls{ViT} B 32 can produce high scores with lower inference time. Therefore, we select the following methods for this section:
% \begin{itemize}
%     \item \gls{SwinT} V2 S with \gls{PMix};
%     \item and \gls{ViT} B 32 with \gls{PMix}. 
% \end{itemize}


\begin{table}[t!]
    \centering
    \caption{Prediction results of the \textit{ViT} model variants ($\mu \pm \sigma$).}
    \label{tab:Averages_of_VisionTransformer}
    \adjustbox{max width=\columnwidth,center}{
    \begin{tabular}{lllll}
    \toprule
    Model & Projection & Cohen's $\kappa$ & F1 Score & Precision \\
    \midrule
    ViT: B 16 & GAF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.562} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.155} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.833} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.090} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.771} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.167} \\
    & MTF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.518} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.040} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.771} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.163} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.773} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.175} \\
    & RP & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.917}} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.163} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.955}} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.083} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.944}} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.130} \\
    & \purpole{PMix} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.917}} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.163} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.955}} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.083} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.944}} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.130} \\
    ViT: B 32 & GAF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.583} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.163} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.844} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.074}} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.785} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.148} \\
    & MTF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.515} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.207} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.790} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.167} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.729} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.155} \\
    & RP & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.883} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.184} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.913} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.154} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.944}} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.130} \\
    & \purpole{PMix} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.917}} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.163} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.955}} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.083} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.944}} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.130} \\
    ViT: H 14 & GAF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.500} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.000}} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.837} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.090} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.729} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.129}} \\
    & MTF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.477} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.075} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.799} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.154} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.708} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.144} \\
    & RP & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.875} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.199} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.943} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.086} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.924} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.140} \\
    & \purpole{PMix} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.833} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.222} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.931} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.087} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.903} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.146} \\
    ViT: L 16 & GAF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.667} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.246} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.873} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.117} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.812} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.188} \\
    & MTF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.594} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.254} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.851} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.118} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.736} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.284} \\
    & RP & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.917}} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.163} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.955}} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.083} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.944}} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.130} \\
    & \purpole{PMix} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.917}} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.163} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.955}} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.083} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.944}} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.130} \\
    ViT: L 32 & GAF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.674} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.257} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.868} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.119} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.819} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.173} \\
    & MTF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.612} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.196} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.828} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.141} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.811} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.167} \\
    & RP & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.875} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.199} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.943} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.086} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.924} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.140} \\
    & \purpole{PMix} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.917}} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.163} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.955}} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.083} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.944}} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.130} \\
    \bottomrule
    \end{tabular}
    }
\end{table}



\begin{table}[t!]
    \centering
    \caption{Prediction results of the \textit{MaxViT} model variants ($\mu \pm \sigma$).}
    \label{tab:Averages_of_Maxvit}
    \adjustbox{max width=\columnwidth,center}{
        \begin{tabular}{lllll}
        \toprule
        Model & Projection & Cohen's $\kappa$ & F1 Score & Precision \\
        \midrule
        MaxViT & GAF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.653} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.261} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.857} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.132} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.806} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.192} \\
        & MTF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.544} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.190} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.706} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.186} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.788} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.222} \\
        & RP & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.854} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.225} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.932}} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.111} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.910} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.172} \\
        & \purpole{PMix} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.875}} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.169}} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.921} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.098}} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.944}} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.130}} \\
        \bottomrule
\end{tabular}
    }
\end{table}



\begin{table}[t!]
    \centering
    \caption{Prediction results of the \textit{SwinTransformer} variants ($\mu \pm \sigma$).}
    \label{tab:Averages_of_SwinTransformer}
    \adjustbox{max width=\columnwidth,center}{
\begin{tabular}{lllll}
\toprule
Model & Projection & Cohen's $\kappa$ & F1 Score & Precision \\
\midrule
SwinT: B & GAF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.625} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.226} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.861} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.110} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.792} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.179} \\
 & MTF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.500} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.000}} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.837} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.090} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.729} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.129}} \\
 & RP & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.883} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.184} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.913} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.154} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.944}} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.130} \\
 & \purpole{PMix} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.500} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.000}} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.837} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.090} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.729} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.129} \\
SwinT: S & GAF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.696} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.236} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.838} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.160} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.854} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.198} \\
 & MTF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.568} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.226} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.820} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.181} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.750} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.194} \\
 & RP & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.875} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.199} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.943}} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.086}} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.924} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.140} \\
 & \purpole{PMix} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.792} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.234} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.919} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.087} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.882} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.148} \\
SwinT: T & GAF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.571} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.216} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.765} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.187} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.771} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.198} \\
 & MTF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.514} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.166} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.806} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.110} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.736} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.154} \\
 & RP & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.727} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.261} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.897} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.127} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.833} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.195} \\
 & \purpole{PMix} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.896}} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.167} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.938} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.093} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.944}} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.130} \\
\bottomrule
\end{tabular}
    }
\end{table}




\begin{table}[t!]
    \centering
    \caption{Prediction results of the \textit{SwinTransformerV2} variants ($\mu \pm \sigma$).}
    \label{tab:Averages_of_SwinTransformerV2}
    \adjustbox{max width=\columnwidth,center}{
\begin{tabular}{lllll}
\toprule
Model & Projection & Cohen's $\kappa$ & F1 Score & Precision \\
\midrule
SwinTV2: B & GAF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.500} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.000}} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.837} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.090} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.729} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.129} \\
 & MTF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.568} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.162} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.860} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.085} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.764} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.132} \\
 & RP & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.833} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.222} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.931} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.087} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.931} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.127} \\
 & \purpole{PMix} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.896} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.167} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.938} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.093} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.944} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.130} \\
SwinTV2: S & GAF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.611} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.239} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.829} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.134} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.785} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.183} \\
 & MTF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.500} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.000}} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.837} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.090} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.729} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.129} \\
 & RP & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.833} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.195} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.910} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.097} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.924} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.140} \\
 & \purpole{PMix} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.917}} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.163} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.955}} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.083}} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.944} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.130} \\
SwinTV2: T & GAF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.674} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.257} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.868} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.119} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.819} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.173} \\
 & MTF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.500} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.000}} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.837} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.090} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.729} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.129} \\
 & RP & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.842} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.210} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.901} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.152} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.951}} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.115}} \\
 & \purpole{PMix} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.500} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.000}} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.837} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.090} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.729} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.129} \\
\bottomrule
\end{tabular}
    }
\end{table}



\subsubsection{Residual Nets}

The experiments produced three score tables.
% ResNet
Table~\ref{tab:Averages_of_ResNet} presents the ResNet scores for variants with 18, 34, 50, 101, and 152 layers. Among these, the \gls{PMix} and \gls{RP} methods outperformed the other projection methods. Specifically, the \gls{PMix} method achieved the best scores when combined with the 50 and 101-layer variants.
% ResNeXt
Table~\ref{tab:Averages_of_ResNeXt} displays the ResNeXt scores for variants with 50 or 101 layers, cardinality of 32 or 64, and bottleneck width of 4 or 8. Among these, the \gls{PMix} and \gls{RP} methods achieved the best scores. Notably, the \gls{RP} method with the \mbox{ResNeXt 101 $32\times 8d$} variant achieved the highest scores.
% Wide ResNet
Table \ref{tab:Averages_of_WideResNet} lists the Wide ResNet scores for variants with 50 or 101 layers and a widening factor of 2. The \gls{PMix} and \gls{RP} methods consistently performed better across all metrics. Notably, the \gls{PMix} method with the Wide \mbox{ResNet 101-2} variant achieved the best scores for Cohen kappa and F1-Score, and the second-best score for precision.
% Inter-Family Comparison
Observing Tables~\ref{tab:Averages_of_ResNet}, \ref{tab:Averages_of_ResNeXt}, and \ref{tab:Averages_of_WideResNet} together reveals that the \mbox{Wide ResNet 101-2} with \gls{PMix} was the top-performing combination in terms of scoring.
%However, this combination had the highest memory usage, according to Table~\ref{tab:Memory_of_Residual Nets}, and was the fourth slowest in inference time, as seen in Figure~\ref{fig:Time_of_ResNet based}. An alternative with nearly the second-best scores but significantly lower memory usage and inference time is the \mbox{ResNet 50} with \gls{PMix}. Thus, the two methods below were chosen for this section:
% \begin{itemize}
%     \item ResNet 50 with \gls{PMix}; 
%     \item and Wide ResNet 101-2 with \gls{PMix}. 
% \end{itemize}




\begin{table}[t!]
    \centering
    \caption{Prediction results of the \textit{ResNet} model variants ($\mu \pm \sigma$).}
    \label{tab:Averages_of_ResNet}
    \adjustbox{max width=\columnwidth,center}{
\begin{tabular}{lllll}
\toprule
Model & Projection & Cohen's $\kappa$ & F1 Score & Precision \\
\midrule
ResNet: 101 & GAF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.558} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.223} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.848} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.106} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.708} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.279} \\
 & MTF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.500} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.000}} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.825} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.074}} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.729} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.129} \\
 & RP & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.667} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.244} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.851} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.147} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.867} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.185} \\
 & \purpole{PMix} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.917}} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.163} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.955}} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.083} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.944}} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.130} \\
ResNet: 152 & GAF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.609} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.266} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.874} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.123} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.729} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.291} \\
 & MTF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.557} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.168} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.787} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.135} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.785} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.183} \\
 & RP & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.792} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.234} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.925} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.089} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.894} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.149} \\
 & \purpole{PMix} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.875} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.199} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.913} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.154} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.931} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.166} \\
ResNet: 18 & GAF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.661} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.256} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.807} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.172} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.861} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.182} \\
 & MTF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.547} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.188} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.799} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.148} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.771} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.155} \\
 & RP & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.854} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.198} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.926} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.093} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.924} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.140} \\
 & \purpole{PMix} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.771} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.249} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.908} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.109} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.868} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.176} \\
ResNet: 34 & GAF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.599} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.210} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.799} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.148} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.799} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.165} \\
 & MTF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.500} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.000}} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.833} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.098} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.725} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.142} \\
 & RP & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.896} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.167} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.938} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.093} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.944}} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.130} \\
 & \purpole{PMix} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.854} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.225} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.932} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.111} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.931} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.127}} \\
ResNet: 50 & GAF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.510} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.254} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.772} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.178} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.681} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.293} \\
 & MTF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.470} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.067} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.806} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.110} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.715} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.130} \\
 & RP & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.818} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.226} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.931} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.087} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.882} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.148} \\
 & \purpole{PMix} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.917}} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.163} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.955}} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.083} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.944}} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.130} \\
\bottomrule
\end{tabular}
    }
\end{table}




\begin{table}[t!]
    \centering
    \caption{Prediction results of the \textit{ResNeXt} model variants ($\mu \pm \sigma$).}
    \label{tab:Averages_of_ResNeXt}
    \adjustbox{max width=\columnwidth,center}{
\begin{tabular}{lllll}
\toprule
Model & Projection & Cohen's $\kappa$ & F1 Score & Precision \\
\midrule
ResNeXt: 101; 32x8d & GAF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.729} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.271} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.853} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.179} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.847} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.204} \\
 & MTF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.568} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.162} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.844} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.102} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.771} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.167} \\
 & RP & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.875}} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.199} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.943}} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.086} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.924}} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.140} \\
 & \purpole{PMix} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.758} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.230} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.877} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.145} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.882} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.148} \\
ResNeXt: 101; 64x4d & GAF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.479} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.188} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.752} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.159} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.708} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.169} \\
 & MTF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.511} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.198} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.580} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.217} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.806} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.257} \\
 & RP & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.758} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.204} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.856} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.149} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.917} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.144} \\
 & \purpole{PMix} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.833} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.222} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.915} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.115} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.903} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.146} \\
ResNeXt: 50; 32x4d & GAF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.542} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.144}} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.794} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.161} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.750} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.158} \\
 & MTF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.568} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.162} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.860} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.085}} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.764} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.132}} \\
 & RP & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.750} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.282} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.870} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.183} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.847} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.204} \\
 & \purpole{PMix} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.792} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.234} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.919} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.087} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.882} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.148} \\
\bottomrule
\end{tabular}
    }
\end{table}





\begin{table}[t!]
    \centering
    \caption{Prediction results of the \textit{WideResNet} model variants ($\mu \pm \sigma$).}
    \label{tab:Averages_of_WideResNet}
    \adjustbox{max width=\columnwidth,center}{
\begin{tabular}{lllll}
\toprule
Model & Projection & Cohen's $\kappa$ & F1 Score & Precision \\
\midrule
WiResNet: 101-2 & GAF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.625} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.226} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.826} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.158} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.803} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.172} \\
 & MTF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.508} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.110} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.702} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.189} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.750} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.194} \\
 & RP & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.842} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.210} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.905} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.159} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.970}} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.101}} \\
 & \purpole{PMix} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.955}} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.101}} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.967}} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.078}} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.944} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.130} \\
WiResNet: 50-2 & GAF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.486} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.117} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.737} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.154} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.713} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.196} \\
 & MTF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.550} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.145} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.786} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.142} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.773} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.175} \\
 & RP & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.896} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.167} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.938} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.093} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.944} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.130} \\
 & \purpole{PMix} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.875} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.199} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.943} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.086} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.924} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.140} \\
\bottomrule
\end{tabular}
    }
\end{table}






\subsubsection{Mobile Nets}

Three metric tables were generated for mobile-oriented family of \gls{CV} models.
%MNASNet
Table~\ref{tab:Averages_of_MNASNet} records the scores obtained by the MNASNet variants, which can have depth multipliers of 0.5, 0.75, 1.0, or 1.3, affecting the number of channels. Notably, the combination of \mbox{MNASNet 1.0} with \gls{PMix} achieved the best scores across all metrics.
%MobileNet V2
Table~\ref{tab:Averages_of_MobileNetV2} presents the scores for MobileNet V2. The \gls{RP} projection achieved the best Cohen kappa and precision scores, while \gls{PMix} obtained the highest F1-Score. However, \gls{RP} demonstrated greater consistency, with lower variability in results compared to the standard deviations of \gls{PMix}.
%MobileNet V3 
Table~\ref{tab:Averages_of_MobileNetV3} lists the MobileNet V3 variants, which include Small and Large configurations in terms of resource usage. Notably, \gls{PMix} with the Large variant achieved the best Cohen kappa and precision scores, while \gls{RP} with the Small variant excelled in the F1-Score metric.
% Inter-Family Comparison
% From the Tables \ref{tab:Averages_of_MNASNet}, \ref{tab:Averages_of_MobileNetV2} and \ref{tab:Averages_of_MobileNetV3}, the combination of \mbox{MNASNet 1.0} with \gls{PMix} emerges as the overall best case. This combination demonstrates a competent inference time when comparing to the other models in the category, as shown in Figure~\ref{fig:Time_of_Mobile nets}, but its memory consumption was not among the best models in the category, according to Table~\ref{tab:Memory_of_Mobile-Oriented}. Nonetheless, we elect only one method as the best models of this section:
% \begin{itemize}
%     \item MNASNet 1.0 with \gls{PMix}.
% \end{itemize}


\begin{table}[t!]
    \centering
    \caption{Prediction results of the \textit{MNASNet} model variants ($\mu \pm \sigma$).}
    \label{tab:Averages_of_MNASNet}
    \adjustbox{max width=\columnwidth,center}{
\begin{tabular}{lllll}
\toprule
Model & Projection & Cohen's $\kappa$ & F1 Score & Precision \\
\midrule
MNASNet: 0.5 & GAF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.513} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.211} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.812} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.167} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.552} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.367} \\
 & MTF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.480} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.133} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.798} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.136} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.681} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.263} \\
 & RP & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.619} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.260} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.787} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.222} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.843} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.197} \\
 & \purpole{PMix} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.691} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.220} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.866} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.147} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.848} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.148} \\
MNASNet: 0.75 & GAF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.500} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.000}} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.830} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.072} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.750} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.144} \\
 & MTF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.524} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.097} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.689} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.142} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.771} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.212} \\
 & RP & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.854} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.225} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.932} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.111} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.910} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.172} \\
 & \purpole{PMix} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.674} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.298} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.796} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.225} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.811} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.230} \\
MNASNet: 1.0 & GAF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.588} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.213} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.698} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.235} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.861} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.220} \\
 & MTF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.527} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.185} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.839} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.236} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.750} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.433} \\
 & RP & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.521} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.072} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.830} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.064}} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.750} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.125} \\
 & \purpole{PMix} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.917}} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.163} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.955}} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.083} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.944}} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.130} \\
MNASNet: 1.3 & GAF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.583} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.163} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.842} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.078} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.765} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.139} \\
 & MTF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.530} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.164} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.833} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.114} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.743} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.153} \\
 & RP & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.523} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.075} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.848} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.073} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.743} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.109}} \\
 & \purpole{PMix} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.604} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.249} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.884} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.107} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.750} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.312} \\
\bottomrule
\end{tabular}
    }
\end{table}





\begin{table}[t!]
    \centering
    \caption{Prediction results of the \textit{MobileNetV2} variants ($\mu \pm \sigma$).}
    \label{tab:Averages_of_MobileNetV2}
    \adjustbox{max width=\columnwidth,center}{
\begin{tabular}{lllll}
\toprule
Model & Projection & Cohen's $\kappa$ & F1 Score & Precision \\
\midrule
MobileNet V2 & GAF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.565} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.214} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.776} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.164} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.788} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.294} \\
 & MTF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.485} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.200} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.773} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.201} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.708} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.193} \\
 & RP & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.875}} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.199}} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.927} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.116} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.924}} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.140}} \\
 & \purpole{PMix} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.854} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.249} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.951}} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.086}} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.889} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.296} \\
\bottomrule
\end{tabular}
    }
\end{table}



\begin{table}[t!]
    \centering
    \caption{Prediction results of the \textit{MobileNetV3} variants ($\mu \pm \sigma$).}
    \label{tab:Averages_of_MobileNetV3}
    \adjustbox{max width=\columnwidth,center}{
\begin{tabular}{lllll}
\toprule
Model & Projection & Cohen's $\kappa$ & F1 Score & Precision \\
\midrule
MobileNet V3: Large & GAF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.507} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.140} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.758} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.146} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.765} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.178} \\
 & MTF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.561} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.227} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.777} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.185} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.806} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.195} \\
 & RP & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.683} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.272} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.838} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.191} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.818} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.318} \\
 & \purpole{PMix} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.792}} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.234} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.908} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.109} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.910}} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.135}} \\
MobileNet V3: Small & GAF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.473} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.090}} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.807} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.153} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.639} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.283} \\
 & MTF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.474} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.091} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.731} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.165} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.697} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.150} \\
 & RP & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.727} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.236} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.912}} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.087}} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.848} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.148} \\
 & \purpole{PMix} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.667} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.246} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.822} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.174} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.833} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.207} \\
\bottomrule
\end{tabular}
    }
\end{table}







\subsubsection{Extreme Nets}

Three metric tables were constructed, each corresponding to a model within the \gls{CV} family.
% Dense Net
Table \ref{tab:Averages_of_DenseNet} presents the DenseNet results, where the variants include depths of 121, 161, 169, or 201 layers. For the 169 and 201 layer variants, the \gls{PMix} method achieved superior performance, whereas the \gls{RP} method was the best for the 161 layer variant. For the 121 layer variant, the \gls{PMix} method obtained the highest Cohen kappa score, while the \gls{RP} method excelled in the F1-Score and achieved perfect precision. Overall, the DenseNet 161 with \gls{RP}, DenseNet 201 with \gls{PMix}, and DenseNet 121 with \gls{RP} achieved the best scores in terms of Cohen kappa, F1-Score, and precision metrics, respectively. Notably, the DenseNet 161 with \gls{RP} demonstrated a good balance across metrics, attaining the best Cohen kappa score and the second-best F1 and precision scores.
% SqueezeNet
Table~\ref{tab:Averages_of_SqueezeNet} exhibits the SqueezeNet results for versions 1.0 and 1.1. The optimized version 1.1 achieved the highest scores when paired with the \gls{PMix} method, attaining the best Cohen kappa and F1 scores. When combined with the \gls{RP} method, the optimized version 1.1 achieved the best precision score. Both combinations demonstrated generally strong performance across all metrics.
% VGG
Table \ref{tab:Averages_of_VGG} details the VGG scores across variants with 11, 13, 16, or 19 layers, with or without Batch Normalization (BN). The \gls{RP} and \gls{PMix} methods achieved the best scores for all variants, though some cases exhibited higher dispersion. Notably, the combination of \mbox{VGG 16} with \gls{RP} excelled in Cohen kappa and precision metrics, while \mbox{VGG 16 BN} with \gls{PMix} achieved the highest F1-Score. However, the \mbox{VGG 16} with \gls{RP} combination showed considerable dispersion in the F1-Score metric, making \mbox{VGG 16 BN} with \gls{PMix} a more reliable choice.
% Inter-Family Comparison
% the combinations \mbox{SqueezeNet 1.1} with \gls{PMix} and \mbox{VGG 16 BN} with \gls{PMix} stand out. Specifically, \mbox{SqueezeNet 1.1} with \gls{PMix} achieved the best Cohen kappa, while \mbox{VGG 16 BN} with \gls{PMix} attained the highest F1-score among all Extreme Nets \gls{CV} family models. The Figure~\ref{fig:Time_of_Extreme nets} illustrates that \mbox{SqueezeNet 1.1} with \gls{PMix} outperforms most other variants in terms of inference speed. Additionally, Table~\ref{tab:Memory_of_Extreme Models} shows that this combination also ranks as the smallest in memory consumption. Thence, we choose two methods as representative of this section:
% \begin{itemize}
%     \item VGG 16 BN with \gls{PMix};
%     \item and SqueezeNet 1.1 with \gls{PMix}.
% \end{itemize}



\begin{table}[t!]
    \centering
    \caption{Prediction results of the \textit{DenseNet} model variants ($\mu \pm \sigma$).}
    \label{tab:Averages_of_DenseNet}
    \adjustbox{max width=\columnwidth,center}{
\begin{tabular}{lllll}
\toprule
Model & Projection & Cohen's $\kappa$ & F1 Score & Precision \\
\midrule
DenseNet: 121 & GAF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.621} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.248} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.795} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.190} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.799} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.196} \\
 & MTF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.500} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.000}} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.837} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.090} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.729} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.129} \\
 & RP & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.771} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.225} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.917} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.099} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{1.000}} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.000}} \\
 & \purpole{PMix} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.862} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.212} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.902} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.167} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.931} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.166} \\
DenseNet: 161 & GAF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.557} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.168} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.724} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.191} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.788} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.191} \\
 & MTF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.676} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.239} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.818} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.167} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.847} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.204} \\
 & RP & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.896}} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.167} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.938} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.093} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.944} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.130} \\
 & \purpole{PMix} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.750} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.238} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.907} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.085} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.861} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.148} \\
DenseNet: 169 & GAF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.480} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.103} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.700} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.211} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.767} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.188} \\
 & MTF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.653} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.261} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.857} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.132} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.806} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.192} \\
 & RP & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.636} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.275} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.848} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.133} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.799} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.153} \\
 & \purpole{PMix} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.833} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.222} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.938} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.088} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.917} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.144} \\
DenseNet: 201 & GAF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.600} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.256} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.861} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.116} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.729} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.291} \\
 & MTF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.558} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.223} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.854} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.058}} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.701} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.351} \\
 & RP & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.683} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.183} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.773} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.179} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.889} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.175} \\
 & \purpole{PMix} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.875} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.199} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.943}} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.086} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.924} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.140} \\
\bottomrule
\end{tabular}
    }
\end{table}


\begin{table}[t!]
    \centering
    \caption{Prediction results of the \textit{SqueezeNet} model variants ($\mu \pm \sigma$).}
    \label{tab:Averages_of_SqueezeNet}
    \adjustbox{max width=\columnwidth,center}{
\begin{tabular}{lllll}
\toprule
Model & Projection & Cohen's $\kappa$ & F1 Score & Precision \\
\midrule
SqueezeNet: 1.0 & GAF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.591} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.231} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.804} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.192} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.771} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.198} \\
 & MTF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.586} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.194} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.742} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.197} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.812} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.217} \\
 & RP & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.787} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.206} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.816} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.194} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.958} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.144} \\
 & \purpole{PMix} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.729} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.271} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.838} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.210} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.856} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.211} \\
SqueezeNet: 1.1 & GAF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.500} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.000}} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.819} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.080}} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.700} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.105} \\
 & MTF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.450} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.112} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.794} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.161} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.646} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.249} \\
 & RP & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.904} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.181} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.914} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.168} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.972}} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.096}} \\
 & \purpole{PMix} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.917}} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.163} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.955}} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.083} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.944} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.130} \\
\bottomrule
\end{tabular}
    }
\end{table}


\begin{table}[t!]
    \centering
    \caption{Prediction results of the \textit{VGG} model variants ($\mu \pm \sigma$).}
    \label{tab:Averages_of_VGG}
    \adjustbox{max width=\columnwidth,center}{
\begin{tabular}{lllll}
\toprule
Model & Projection & Cohen's $\kappa$ & F1 Score & Precision \\
\midrule
VGG: 11 & GAF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.659} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.257} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.840} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.182} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.811} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.201} \\
 & MTF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.500} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.174} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.790} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.116} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.729} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.155} \\
 & RP & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.829} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.192} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.855} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.188} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.944} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.130} \\
 & \purpole{PMix} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.833} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.222} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.931} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.087} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.903} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.146} \\
VGG: 11 BN & GAF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.562} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.155} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.848} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.073} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.764} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.132} \\
 & MTF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.545} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.151} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.849} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.101} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.750} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.151} \\
 & RP & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.875} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.169} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.921} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.098} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.944} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.130} \\
 & \purpole{PMix} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.854} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.198} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.926} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.093} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.924} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.140} \\
VGG: 13 & GAF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.667} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.244} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.863} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.121} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.819} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.173} \\
 & MTF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.500} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.000}} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.837} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.090} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.729} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.129} \\
 & RP & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.896} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.198} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.944} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.110} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.931} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.166} \\
 & \purpole{PMix} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.875} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.199} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.943} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.086} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.924} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.140} \\
VGG: 13 BN & GAF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.500} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.000}} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.837} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.090} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.729} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.129} \\
 & MTF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.530} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.164} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.833} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.114} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.743} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.153} \\
 & RP & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.833} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.246} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.921} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.131} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.896} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.198} \\
 & \purpole{PMix} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.873} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.189} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.913} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.154} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.924} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.140} \\
VGG: 16 & GAF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.583} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.163} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.860} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.052}} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.780} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.113} \\
 & MTF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.500} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.000}} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.837} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.090} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.729} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.129} \\
 & RP & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.904}} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.181} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.930} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.151} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.972}} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.096}} \\
 & \purpole{PMix} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.875} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.199} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.943} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.086} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.924} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.140} \\
VGG: 16 BN & GAF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.541} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.196} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.861} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.090} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.701} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.257} \\
 & MTF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.569} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.177} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.828} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.090} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.778} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.152} \\
 & RP & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.625} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.199} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.856} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.087} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.799} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.125} \\
 & \purpole{PMix} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.896} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.198} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.960}} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.075} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.951} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.115} \\
VGG: 19 & GAF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.568} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.117} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.855} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.052} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.778} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.109} \\
 & MTF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.479} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.078} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.776} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.139} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.736} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.154} \\
 & RP & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.854} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.225} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.932} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.111} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.910} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.172} \\
 & \purpole{PMix} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.688} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.217} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.879} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.077} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.840} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.144} \\
VGG: 19 BN & GAF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.549} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.199} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.790} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.152} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.757} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.172} \\
 & MTF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.553} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.262} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.764} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.211} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.743} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.215} \\
 & RP & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.875} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.199} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.927} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.116} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.931} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.166} \\
 & \purpole{PMix} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.708} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.257} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.885} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.123} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.833} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.195} \\
\bottomrule
\end{tabular}
    }
\end{table}






\subsubsection{Efficiency Nets}

Three score tables were constructed for the Efficiency-Oriented \gls{CV} family.
% EfficientNet
Table~\ref{tab:Averages_of_EfficientNet} lists the results for EfficientNet variants ranging from B0, the smallest, to B4, the largest, in terms of parameter scaling. The \gls{PMix} projection achieved the highest scores for variants B0, B1, and B2. For the B3 variant, the \gls{MTF} method excelled in the F1-score, while the \gls{RP} method performed better for the other metrics. Overall, the combination of \mbox{EfficientNet B1} with \gls{PMix} emerged as the top performer.
% EfficientNetV2
Table~\ref{tab:Averages_of_EfficientNetV2} presents the scores for EfficientNet V2, with the \gls{PMix} projection outperforming all other methods.
% ShuffleNet V2
Table~\ref{tab:Averages_of_ShuffleNetV2} displays the metrics for ShuffleNet V2 variants, which include multipliers of $\times 0.5$, $\times 1.0$, $\times 1.5$, and $\times 2.0$ on the number of channels in each architectural block. Across all variants, the \gls{PMix} projection method outperformed all others. Specifically, the best scores for ShuffleNet V2 were achieved with the $\times 0.5$ and $\times 1.0$ variants combined with the \gls{PMix} method.
% Inter-Family Comparison
% When analyzing the results from Tables  \ref{tab:Averages_of_EfficientNet}, \ref{tab:Averages_of_EfficientNetV2}, and \ref{tab:Averages_of_ShuffleNetV2}, it is evident that the usage of \mbox{EfficientNet V2}, \mbox{ShuffleNet V2 $\times 0.5$}, and \mbox{ShuffleNet V2 $\times 1.0$}  with \gls{PMix} achieved high scores across all metrics, including the best Cohen kappa and F1 scores, as well as the second-best precision. Among these, the \mbox{ShuffleNet V2 $\times 0.5$} with \gls{PMix} was the most efficient in terms of memory usage, as shown in Table~\ref{tab:Memory_of_Efficiency-Oriented}, while being one of the fastest in inference, as visible in the Figure \ref{fig:Time_of_Efficiency Oriented}. Thus, only the following method was selected for this section:
% \begin{itemize}
% 	\item ShuffleNet V2$\times0.5$ with \gls{PMix}.
% \end{itemize}






\begin{table}[t!]
    \centering
    \caption{Prediction results of the \textit{EfficientNet} model variants ($\mu \pm \sigma$).}
    \label{tab:Averages_of_EfficientNet}
    \adjustbox{max width=\columnwidth,center}{
\begin{tabular}{lllll}
\toprule
Model & Projection & Cohen's $\kappa$ & F1 Score & Precision \\
\midrule
EfficientNet: B0 & GAF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.569} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.177} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.828} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.090} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.778} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.152} \\
 & MTF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.507} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.206} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.806} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.155} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.694} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.257} \\
 & RP & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.736} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.199} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.856} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.142} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.882} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.148} \\
 & \purpole{PMix} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.841} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.231} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.916} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.134} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.896} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.198} \\
EfficientNet: B1 & GAF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.517} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.247} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.755} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.178} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.688} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.278} \\
 & MTF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.503} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.131} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.735} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.186} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.757} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.172} \\
 & RP & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.694} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.294} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.841} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.196} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.856} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.211} \\
 & \purpole{PMix} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.875}} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.199} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.943}} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.086} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.924}} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.140}} \\
EfficientNet: B2 & GAF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.436} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.161} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.729} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.168} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.546} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.344} \\
 & MTF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.473} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.117}} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.671} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.228} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.750} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.217} \\
 & RP & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.682} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.276} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.858} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.179} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.806} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.192} \\
 & \purpole{PMix} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.854} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.198} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.926} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.093} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.924}} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.140}} \\
EfficientNet: B3 & GAF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.583} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.163} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.841} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.082}} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.792} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.163} \\
 & MTF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.579} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.229} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.863} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.116} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.719} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.339} \\
 & RP & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.696} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.210} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.817} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.151} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.868} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.176} \\
 & \purpole{PMix} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.604} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.225} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.788} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.181} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.792} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.209} \\
\bottomrule
\end{tabular}
    }
\end{table}




\begin{table}[t!]
    \centering
    \caption{Prediction results of the \textit{EfficientNetV2} variants ($\mu \pm \sigma$).}
    \label{tab:Averages_of_EfficientNetV2}
    \adjustbox{max width=\columnwidth,center}{
\begin{tabular}{lllll}
\toprule
Model & Projection & Cohen's $\kappa$ & F1 Score & Precision \\
\midrule
EfficientNet V2 & GAF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.600} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.200} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.826} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.167} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.800} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.197} \\
 & MTF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.545} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.151}} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.849} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.101} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.750} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.151} \\
 & RP & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.708} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.234} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.895} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.080}} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.840} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.144} \\
 & \purpole{PMix} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.917}} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.163} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.955}} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.083} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.944}} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.130}} \\
\bottomrule
\end{tabular}

    }
\end{table}



\begin{table}[t!]
    \centering
    \caption{Prediction results of the \textit{ShuffleNetV2} model variants ($\mu \pm \sigma$).}
    \label{tab:Averages_of_ShuffleNetV2}
    \adjustbox{max width=\columnwidth,center}{
\begin{tabular}{lllll}
\toprule
Model & Projection & Cohen's $\kappa$ & F1 Score & Precision \\
\midrule
ShuffleNet V2: x0.5 & GAF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.523} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.208} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.784} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.199} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.736} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.210} \\
 & MTF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.473} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.090} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.851} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.090} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.667} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.280} \\
 & RP & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.821} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.231} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.876} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.190} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.910} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.172} \\
 & \purpole{PMix} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.917}} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.163} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.955}} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.083}} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.944} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.130} \\
ShuffleNet V2: x1.0 & GAF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.504} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.194} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.744} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.180} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.688} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.285} \\
 & MTF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.591} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.202} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.862} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.122} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.775} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.184} \\
 & RP & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.727} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.236} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.932} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.095} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.885} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.160} \\
 & \purpole{PMix} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.917}} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.163} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.955}} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.083}} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.944} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.130} \\
ShuffleNet V2: x1.5 & GAF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.500} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.000}} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.837} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.090} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.729} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.129} \\
 & MTF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.489} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.156} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.772} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.122} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.659} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.248} \\
 & RP & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.592} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.220} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.792} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.207} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.767} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.301} \\
 & \purpole{PMix} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.800} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.198} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.868} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.148} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.951}} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.115}} \\
ShuffleNet V2: x2.0 & GAF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.625} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.226} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.861} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.110} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.792} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.179} \\
 & MTF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.527} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.199} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.700} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.230} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.778} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.234} \\
 & RP & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.480} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.235} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.789} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.189} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.629} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.358} \\
 & \purpole{PMix} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.729} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.249} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.896} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.106} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.847} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.173} \\
\bottomrule
\end{tabular}

    }
\end{table}






\subsubsection{Further architectures}

Three score tables were generated for the remaining computer vision models.
% AlexNet
The Table \ref{tab:Averages_of_AlexNet} contains the scores of AlexNet. Notably, the \gls{PMix} projection earned the best scores for all metrics in that table.
% ConvNeXt
Table~\ref{tab:Averages_of_ConvNeXt} presents the results for the ConvNeXt model, with variants including Tiny, Small, Base, and Large in terms of parameter size. Among these variants, the \gls{RP} and \gls{PMix} methods achieved the best scores overall, though some instances, such as \gls{RP} with the Tiny variant, exhibited higher dispersion, particularly for the Cohen kappa score. Specifically, the \gls{PMix} method with the \mbox{ConvNeXt Tiny} variant achieved the highest F1-score, while the \gls{PMix} method with the \mbox{ConvNeXt Small} variant obtained the best Cohen kappa and precision scores, and also secured the second best F1-score.
% RegNet 
Table~\ref{tab:Averages_of_RegNet} exhibits the results for RegNet variants, categorized into RegNetX and RegNetY design spaces~\cite{RegNet}, with varying float operations per second rates such as 400 Mega Flops (MF) or 16 Giga Flops (GF). Among these variants, several achieved scores above the third quartile across all metrics. For the X space, notable cases include \gls{RP} with the 400 MF and 800 MF variants, and \gls{PMix} with the 800 MF, 3.2 GF, 8 GF, and 16 GF variants. For the Y space, noteworthy cases are \gls{RP} with the 400 MF, 1.6 GF, 16 GF, and 32 GF variants, and \gls{PMix} with the 800 MF, 3.2 GF, and 16 GF variants. Among these high-scoring variants, the \gls{PMix} method with the \mbox{RegNet X 3.2 GF}, \mbox{RegNet X 800 MF}, \mbox{RegNet Y 400 MF}, and \mbox{RegNet Y 800 MF} variants achieved the best Cohen kappa and F1 scores, and the third best precision score. 
%Of these top-performing combinations, the \mbox{RegNet Y 400 MF} with \gls{PMix} had the lowest memory usage, as shown in Table~\ref{tab:Memory_of_Diverse}, while the \mbox{RegNet X 800 MF} with \gls{PMix} had the fastest inferences of the model variants, as seen in Figure \ref{fig:Time_of_Diverse}.
% Inter-Family Comparison
When evaluating the top-performing models from each type within the Diverse \gls{CV} family, the \mbox{RegNet Y 400 MF} with \gls{RP}, and the \mbox{RegNet X 800 MF} and AlexNet with \gls{PMix} achieved the highest scores.
%Notably, the \mbox{RegNet Y 400 MF} with \gls{RP} exhibited the lowest memory usage, as shown in Table~\ref{tab:Memory_of_Diverse}, while AlexNet had the fastest inference times across all projections, as illustrated in Figure~\ref{fig:Time_of_Diverse}. Hence, two methods were chosen for this section:
% \begin{itemize}
%     \item AlexNet with \gls{PMix};
%     \item and RegNet Y 400 MF with \gls{RP}.
% \end{itemize}



\begin{table}[t!]
    \centering
    \caption{Prediction results of the \textit{AlexNet} model variants ($\mu \pm \sigma$).}
    \label{tab:Averages_of_AlexNet}
    \adjustbox{max width=\columnwidth,center}{

\begin{tabular}{lllll}
\toprule
Model & Projection & Cohen's $\kappa$ & F1 Score & Precision \\
\midrule
AlexNet & GAF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.545} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.151}} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.849} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.101} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.750} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.151} \\
 & MTF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.598} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.247} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.827} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.174} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.773} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.163} \\
 & RP & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.704} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.204} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.819} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.168} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.910} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.135} \\
 & \purpole{PMix} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.917}} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.163} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.955}} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.083}} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.944}} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.130}} \\
\bottomrule
\end{tabular}

    }
\end{table}





\begin{table}[t!]
    \centering
    \caption{Prediction results of the \textit{ConvNeXt} model variants ($\mu \pm \sigma$).}
    \label{tab:Averages_of_ConvNeXt}
    \adjustbox{max width=\columnwidth,center}{

\begin{tabular}{lllll}
\toprule
Model & Projection & Cohen's $\kappa$ & F1 Score & Precision \\
\midrule
ConvNeXt: Base & GAF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.536} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.157} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.792} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.137} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.764} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.170} \\
 & MTF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.473} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.144} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.789} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.159} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.667} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.268} \\
 & RP & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.883} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.184} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.913} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.154} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.944}} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.130}} \\
 & \purpole{PMix} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.854} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.198} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.926} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.093} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.924} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.140} \\
ConvNeXt: Large & GAF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.611} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.239} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.845} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.124} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.785} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.183} \\
 & MTF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.545} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.151} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.849} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.101} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.750} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.151} \\
 & RP & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.862} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.184} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.896} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.154} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.944}} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.130}} \\
 & \purpole{PMix} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.862} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.184} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.896} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.154} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.944}} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.130}} \\
ConvNeXt: Small & GAF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.708} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.257} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.885} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.123} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.833} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.195} \\
 & MTF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.611} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.239} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.845} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.124} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.785} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.183} \\
 & RP & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.854} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.198} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.926} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.093} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.924} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.140} \\
 & \purpole{PMix} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.896}} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.167} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.938} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.093} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.944}} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.130}} \\
ConvNeXt: Tiny & GAF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.688} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.241} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.884} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.101} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.826} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.168} \\
 & MTF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.523} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.075}} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.833} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.090} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.750} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.151} \\
 & RP & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.778} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.257} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.903} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.113} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.875} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.157} \\
 & \purpole{PMix} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.875} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.199} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.951}} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.086}} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.939} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.135} \\
\bottomrule
\end{tabular}

    }
\end{table}



\begin{table}[t!]
    \centering
    \caption{Prediction results of the \textit{RegNet} model variants ($\mu \pm \sigma$).}
    \label{tab:Averages_of_RegNet}
    \adjustbox{max width=\columnwidth,center}{

\begin{tabular}{lllll}
\toprule
Model & Projection & Cohen's $\kappa$ & F1 Score & Precision \\
\midrule
RegNet: X; 16 GF & GAF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.668} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.226} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.837} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.167} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.841} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.202} \\
 & MTF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.542} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.226} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.771} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.154} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.736} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.303} \\
 & RP & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.729} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.198} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.838} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.142} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.902} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.178} \\
 & \purpole{PMix} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.875} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.199} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.943} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.086} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.924} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.140} \\
RegNet: X; 1.6 GF & GAF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.515} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.174} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.817} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.123} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.736} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.154} \\
 & MTF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.553} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.176} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.829} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.114} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.764} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.170} \\
 & RP & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.768} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.233} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.865} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.195} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.955} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.101} \\
 & \purpole{PMix} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.854} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.225} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.918} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.151} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.910} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.172} \\
RegNet: X; 32 GF & GAF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.508} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.095} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.830} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.094} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.735} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.117} \\
 & MTF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.527} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.185} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.812} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.157} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.705} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.292} \\
 & RP & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.862} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.184} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.896} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.154} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.944} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.130} \\
 & \purpole{PMix} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.896} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.198} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.930} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.151} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.931} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.166} \\
RegNet: X; 3.2 GF & GAF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.461} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.095} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.810} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.088} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.657} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.278} \\
 & MTF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.550} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.098} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.772} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.122} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.800} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.197} \\
 & RP & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.896} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.198} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.914} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.168} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.931} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.166} \\
 & \purpole{PMix} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.917}} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.163} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.955}} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.083} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.944} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.130} \\
RegNet: X; 400 MF & GAF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.523} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.075} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.831} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.104} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.778} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.150} \\
 & MTF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.479} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.113} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.773} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.095} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.729} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.155} \\
 & RP & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.896} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.167} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.938} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.093} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.944} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.130} \\
 & \purpole{PMix} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.550} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.098} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.791} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.119} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.792} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.163} \\
RegNet: X; 800 MF & GAF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.594} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.278} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.857} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.145} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.720} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.306} \\
 & MTF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.402} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.117} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.656} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.238} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.667} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.173} \\
 & RP & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.875} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.199} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.943} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.086} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.951} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.115} \\
 & \purpole{PMix} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.917}} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.163} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.955}} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.083} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.944} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.130} \\
RegNet: X; 8 GF & GAF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.545} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.151} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.849} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.101} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.750} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.151} \\
 & MTF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.530} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.164} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.812} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.157} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.742} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.169} \\
 & RP & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.854} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.198} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.932} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.095} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.970}} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.101}} \\
 & \purpole{PMix} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.875} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.199} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.951} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.086} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.939} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.135} \\
RegNet: Y; 16 GF & GAF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.612} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.196} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.811} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.149} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.818} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.197} \\
 & MTF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.477} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.118} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.778} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.117} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.727} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.163} \\
 & RP & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.896} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.167} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.938} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.093} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.944} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.130} \\
 & \purpole{PMix} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.875} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.199} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.943} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.086} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.924} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.140} \\
RegNet: Y; 1.6 GF & GAF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.636} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.259} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.846} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.173} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.799} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.217} \\
 & MTF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.500} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.000}} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.837} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.090} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.729} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.129} \\
 & RP & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.875} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.199} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.943} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.086} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.924} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.140} \\
 & \purpole{PMix} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.795} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.218} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.914} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.092} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.882} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.148} \\
RegNet: Y; 32 GF & GAF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.583} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.222} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.822} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.158} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.764} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.170} \\
 & MTF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.568} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.226} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.823} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.173} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.750} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.185} \\
 & RP & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.875} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.199} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.943} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.086} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.924} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.140} \\
 & \purpole{PMix} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.667} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.222} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.883} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.074} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.819} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.137} \\
RegNet: Y; 3.2 GF & GAF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.712} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.280} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.881} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.143} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.826} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.199} \\
 & MTF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.547} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.246} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.753} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.206} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.758} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.212} \\
 & RP & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.826} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.234} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.910} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.119} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.896} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.155} \\
 & \purpole{PMix} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.875} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.199} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.943} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.086} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.924} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.140} \\
RegNet: Y; 400 MF & GAF & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.590} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.260} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.823} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.173} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.771} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.211} \\
 & MTF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.475} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.112} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.690} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.193} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.729} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.198} \\
 & RP & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.917}} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.163} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.955}} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.083} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.944} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.130} \\
 & \purpole{PMix} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.773} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.236} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.919} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.087} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.861} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.148} \\
RegNet: Y; 800 MF & GAF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.521} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.072} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.832} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.061}} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.742} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.121} \\
 & MTF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.486} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.191} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.660} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.240} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.713} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.196} \\
 & RP & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.792} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.257} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.902} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.121} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.868} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.296} \\
 & \purpole{PMix} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.917}} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.163} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.955}} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.083} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.944} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.130} \\
RegNet: Y; 8 GF & GAF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.508} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.029} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.790} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.123} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.750} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.158} \\
 & MTF & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.482} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.166} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.738} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.158} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.648} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.303} \\
 & RP & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.875} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.199} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.927} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.116} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.924} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.140} \\
 & \purpole{PMix} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.771} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.249} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.908} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.109} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.868} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.176} \\
\bottomrule
\end{tabular}

    }
\end{table}






\subsection{Non-computer vision models comparison}


Table~\ref{tab:Averages_of_Non-CV} presents the scores for temporal series models that are not based on \gls{CV} techniques. These models include Individual \mbox{Ordinal TDE}, Random Interval Classifier, \gls{RISEC}, \mbox{TS Fresh} Classifier, \gls{TDE}, and \mbox{WEASEL V2} achieved high scores across all metrics. Among these, \gls{RISEC} and \gls{TDE} surpassed the other models in every score metric. 
Specifically, \gls{RISEC} demonstrated faster inference while \gls{TDE} had lower memory consumption. So, we elect the two methods below as the best models of this section.

%Specifically, \gls{RISEC} demonstrated faster inference, as shown in Figure \ref{fig:Time_of_Non CV},while \gls{TDE} had lower memory consumption, according to Table~\ref{tab:Memory_of_Non-CV}. So, we elect the two methods below as the best models of this section:
% \begin{itemize}
%     \item \gls{RISEC};
%     \item and \gls{TDE}.
% \end{itemize}





\begin{table}[t!]
    \centering
    \caption{Prediction results of the \textit{Non-CV} model variants ($\mu \pm \sigma$).}
    \label{tab:Averages_of_Non-CV}
    \adjustbox{max width=\columnwidth,center}{

\begin{tabular}{llll}
\toprule
Model & Cohen's $\kappa$ & F1 Score & Precision \\
\midrule
Arsenal & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.639} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.252} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.804} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.140} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.819} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.204} \\
BOSS Ensemble & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.688} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.241} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.884} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.101} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.826} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.168} \\
Zhao's CNN Classifier & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.875} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.199} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.951} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.086} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.939} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.135} \\
Interval Forest Classifier & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.862} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.184} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.896} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.154} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.944} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.130} \\
Catch 22 Classifier & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.896} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.167} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.938} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.093} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.944} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.130} \\
Continuous Interval Tree & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.632} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.240} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.856} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.112} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.799} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.165} \\
Contractable BOSS & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.792} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.234} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.919} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.087} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.882} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.148} \\
DrCIF Classifier & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.904} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.181} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.930} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.151} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.972}} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.096}} \\
Elastic Ensemble & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.812} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.188} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.893} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.097} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.924} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.140} \\
Wang's FCN Classifier & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.842} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.210} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.901} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.152} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.924} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.140} \\
Inception Time Classifier & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.799} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.242} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.898} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.116} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.896} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.155} \\
Individual BOSS & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.875} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.169} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.921} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.098} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.944} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.130} \\
Individual Inception Classifier & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.694} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.228} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.858} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.111} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.875} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.163} \\
Individual Ordinal TDE & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.917} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.163} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.955} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.083} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.944} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.130} \\
Individual TDE & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.862} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.184} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.896} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.154} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.944} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.130} \\
K-Neighbors Time Series Classifier & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.875} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.199} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.927} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.116} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.931} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.166} \\
LITE Time Classifier & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.771} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.249} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.908} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.109} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.868} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.176} \\
Wang's MLP Classifier & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.485} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.050}} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.821} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.102} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.722} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.130} \\
MUSE & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.875} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.199} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.943} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.086} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.924} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.140} \\
Ordinal TDE & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.896} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.167} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.938} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.093} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.944} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.130} \\
RDST Classifier & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.633} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.196} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.842} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.125} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.819} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.137} \\
REDCOMETS & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.508} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.095} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.817} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.101} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.743} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.153} \\
Random Interval Classifier & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.917} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.163} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.955} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.083} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.944} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.130} \\
RISEC & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.938}} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.155} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.971}} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.068} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.972}} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.096}} \\
Rocket Classifier & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.729} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.225} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.859} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.122} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.868} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.176} \\
Rotation Forest Classifier & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.854} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.225} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.932} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.111} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.910} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.172} \\
Shape DTW & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.729} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.225} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.875} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.106} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.868} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.176} \\
Shapelet Transform Classifier & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.625} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.199} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.873} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.067}} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.803} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.131} \\
Summary Classifier & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.883} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.184} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.913} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.154} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.944} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.130} \\
Supervised Time Series Forest & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.862} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.184} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.896} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.154} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.972}} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.096}} \\
TS Fresh Classifier & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.917} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.163} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.955} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.083} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.944} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.130} \\
TDE & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.938}} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.155} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.971}} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.068} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.972}} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.096}} \\
Time Series Forest Classifier & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.896} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.167} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.938} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.093} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.944} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.130} \\
WEASEL & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.875} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.199} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.943} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.086} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.924} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.140} \\
WEASEL V2 & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.917} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.163} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.955} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.083} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.944} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.130} \\
\bottomrule
\end{tabular}

    }
\end{table}



\subsection{Comparison of the top-performing models}


The optimal combinations of models and projections identified in the preceding analyses are summarized in Table~\ref{tab:Averages_of_best models}.
The top-performing models include the \gls{TDE}, the \gls{RISEC}, and the \mbox{Wide ResNet 100-2} with \gls{PMix}.
While the \mbox{Wide ResNet} achieved the highest Cohen's $\kappa$ score, it is notable that this model was the second largest in terms of memory usage, as indicated in Table~\ref{tab:Memory_of_best models}.
Additionally, it did not achieve the highest F1-Score or precision and was the second slowest in terms of inference speed, as shown in Figure~\ref{fig:Time_of_Best Models}.
In contrast, the \gls{TDE} and \gls{RISEC} models excelled in usability and security metrics, including F1-Score and precision.
They also demonstrated superior performance in terms of inference speed and memory efficiency.
% Conversely, the \gls{TDE} and \gls{RISEC} models demonstrated superior performance in terms of F1-score, precision, and computational efficiency.
% While the \gls{CV} approach utilizing \mbox{Wide ResNet} and \gls{PMix} achieved marginal gains in classification consistency, the non-\gls{CV} approaches represented by \gls{TDE} and \gls{RISEC} provide a more optimized balance of resource consumption and latency.
% These characteristics make non-\gls{CV} methods a more viable selection for real-time applications or environments with limited computational overhead.




\begin{table}[t!]
    \centering
    \caption{Prediction results of the \textit{top-12 best} models ($\mu \pm \sigma$).}
    \label{tab:Averages_of_best models}
    \adjustbox{max width=\columnwidth,center}{

\begin{tabular}{lllll}
\toprule
Model & Projection & Cohen's $\kappa$ & F1 Score & Precision \\
\midrule
AlexNet & \purpole{PMix} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.917} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.163} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.955} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.083} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.944} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.130} \\
MNASNet: 1.0 & \purpole{PMix} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.917} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.163} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.955} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.083} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.944} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.130} \\
RISEC & Not projected & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.938} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.155} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.971}} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.068}} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.972}} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.096}} \\
RegNet: Y; 400 MF & RP & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.917} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.163} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.955} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.083} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.944} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.130} \\
ResNet: 50 & \purpole{PMix} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.917} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.163} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.955} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.083} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.944} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.130} \\
ShuffleNet V2: x0.5 & \purpole{PMix} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.917} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.163} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.955} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.083} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.944} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.130} \\
SqueezeNet: 1.1 & \purpole{PMix} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.917} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.163} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.955} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.083} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.944} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.130} \\
SwinTV2: S & \purpole{PMix} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.917} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.163} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.955} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.083} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.944} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.130} \\
TDE & Not projected & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.938} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.155} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.971}} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.068}} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.972}} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.096}} \\
VGG: 16 BN & \purpole{PMix} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.896} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.198} & \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.960} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.075} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.951} $\pm$ \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.115} \\
ViT: B 32 & \purpole{PMix} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.917} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.163} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.955} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.083} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.944} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.130} \\
WiResNet: 101-2 & \purpole{PMix} & \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.955}} $\pm$ \textbf{\textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.101}} & \textcolor[rgb]{0.0000000000,0.7000000000,0.0}{0.967} $\pm$ \textcolor[rgb]{0.3000000000,0.3000000000,0.5}{0.078} & \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.944} $\pm$ \textcolor[rgb]{1.0000000000,0.2000000000,0.2}{0.130} \\
\bottomrule
\end{tabular}


    }
\end{table}



\begin{table}[t!]
    \centering
    \caption{Memory size (in MB) of the \textit{top-12 best} models.}

    \adjustbox{max width=\columnwidth,center}{
    \begin{tabular}{lr}
        \toprule
        Neural Network & \begin{tabular}{c} Size (MB)\end{tabular} \\
        \midrule
        TDE & 0.586264 \\
        RISEC & 1.171312 \\
        ShuffleNet V2: x0.5 & 1.376760 \\
        SqueezeNet: 1.1 & 2.894136 \\
        MNASNet: 1.0 & 12.420792 \\
        RegNet: Y; 400 MF & 15.617376 \\
        \bottomrule
    \end{tabular}
    \begin{tabular}{lr}
        \toprule
        Neural Network & \begin{tabular}{c} Size (MB)\end{tabular} \\
        \midrule
        ResNet: 50 & 94.049840 \\
        SwinTV2: S & 195.880352 \\
        AlexNet & 228.048184 \\
        ViT: B 32 & 349.827128 \\
        WiResNet: 101-2 & 499.369720 \\
        VGG: 16 BN & 537.109104 \\
        \bottomrule
    \end{tabular}
    }

    \label{tab:Memory_of_best models}
\end{table}



\begin{figure}[ht!]
    \includegraphics[width=\columnwidth, trim={17em 0 0 0}, clip]{benchmark_of_best models.pdf}
    \caption{Inference time (in ms) of best achieved models.}
    \label{fig:Time_of_Best Models}
\end{figure}










\section{Discussion and Limitations}
\label{sec:Limitations}


While the results are promising, few limitations must be acknowledged regarding the scope of the evaluation.
The study relied exclusively on the \gls{BUTPPG} dataset, which currently represents the only publicly available dataset labeled for \gls{SQA} task.
Consequently, the performance of the proposed \gls{CV} framework may vary across external datasets that utilize different acquisition protocols, sensor specifications, and signal lengths.
Furthermore, the absence of confirmed cardiac arrhythmia cases in the \gls{BUTPPG} population limits the clinical generalizability of the findings to more diverse medical conditions.
The relatively small sample size also resulted in a constrained testing environment, which may not fully capture the statistical variability found in real-world data.
From a deep learning perspective, the limited data volume restricts the ability of high-capacity models to optimize their extensive parameter sets effectively.
Therefore, future research should focus on the development of novel datasets to provide a more robust benchmark for the proposed methodology.


% A further limitation is that this study did not evaluate every available architecture or library. For instance, several models within the PyTorch and Aeon ecosystems, such as GoogLeNet~\cite{GoogLeNet} and the Hydra Classifier~\cite{HydraClassifier}, remained outside the current scope. Similarly, architectures from other frameworks, including Xception~\cite{Xception} from the Keras library~\cite{Keras}, were not tested. Furthermore, the evaluation did not encompass all model variants, such as EfficientNet B7, nor did it optimize the hyperparameters of the projection methods, such as the dimensionality of the \gls{RP}. Future work incorporating a broader range of architectures and hyperparameter optimization techniques like Optuna could provide more exhaustive insights.


Several implementation-level limitations provide opportunities for further optimization.
Although random oversampling was utilized to address class imbalance, specialized time series augmentation techniques could be explored to simultaneously balance and expand the training distribution~\cite{TimeSeriesAugmentation}.
Additionally, the application of resizing transforms to adapt projection images to model input requirements may have suppressed fine-grained spatial relationships within the encoding matrices.
This potential loss of information suggests that the current performance of the \gls{CV} architectures represents a lower bound rather than their maximum theoretical capacity.
While early stopping was employed to mitigate overfitting, future research should include a comprehensive sensitivity analysis to evaluate how this mechanism influences the convergence of high-complexity models.



% Lastly, benchmarking metrics were measured using the Python standard API, which may be limited by the interpreter. Additionally, our measurements did not control the environment where measured the inference time. This could imply that competed with the experimental measurements. Therefore, improvements at the implementation level could include applying time series augmentation techniques, resizing images without distortion by using integer multipliers and padding, researching and optimizing early stopping methods, and conducting measurements in a more controlled environment using low-level interfaces.






\section{Conclusions}
\label{sec:Limitations}



This study evaluated a signal quality assessment framework for \gls{PPG} signals using 1D-to-2D projections and computer vision architectures.
The results demonstrate that the proposed \gls{PMix} fusion strategy provides a more comprehensive spatial encoding of signal morphology than individual techniques, consistently appearing among the top-performing configurations.
While the combination of \gls{PMix} and Wide ResNet achieved superior Cohen's $\kappa$ scores compared to baseline time series classifiers, conventional 1D models maintained higher F1-scores and precision scores with significantly lower computational overhead.

The findings suggest that while projection-based methods are highly accurate, their memory requirements currently favor remote healthcare environments over direct deployment on resource-constrained wearable devices.
A primary limitation of this work remains the exclusive reliance on the \gls{BUTPPG} dataset, which is currently the only publicly available resource for this task.
The small sample size and lack of diverse clinical conditions, such as cardiac arrhythmias, restrict the generalizability of the results.

Future research will focus on the development of novel datasets to facilitate robust cross-dataset validation and more extensive benchmarking against specialized algorithms. 
dditionally, implementation refinements involving optimized augmentation and low-level profiling will be explored to further enhance the efficiency of the proposed framework.



% This work presented a study on \gls{SQA} for \gls{PPG} signals, mainly following an 1D-to-2D-projection approach in combination with \gls{CV} techniques. The investigated projection-based approach involved transforming 1D signals onto 2D images using the \gls{RP}, \gls{GAF}, and \gls{MTF} methods. In addition to these methods, we proposed a mixed approach combining them. The results indicate that the \gls{RP} and \gls{PMix} projection methods outperformed the \gls{GAF} and \gls{MTF} methods, with \gls{RP} and \gls{PMix} yielding similar outcomes. Although the set of machine learning models was extensive, the \gls{BUTPPG} dataset was small and unbalanced, limiting the conclusiveness of the results. Consequently, the experiment should be replicated on a larger dataset, either by using data augmentation techniques to balance and expand the BUTPPG dataset or by utilizing a different dataset with more samples.

% The experiments provided insights of the importance of the proposed \gls{PMix} approach. One key finding is that the \gls{PMix} method appeared more frequently among the best-performing results compared to the other projection methods. Specifically, as depicted in Table~\ref{tab:Averages_of_best models}, all but one top-performing approaches used the \gls{PMix} method.
% These results demonstrate that the proposed \gls{PMix} fusion strategy effectively mitigates the limitations of individual projection techniques by providing a more comprehensive spatial encoding of the \gls{PPG} morphology.
% Our experiments also demonstrate the overall effectiveness of projection methods. Notably, in the best-performing models listed in Table \ref{tab:Averages_of_best models}, the \gls{PMix} method combined with Wide ResNet outperformed the baseline time series classification models in terms of the Cohen Kappa score.
% This indicates that a projection-based approach can be highly accurate for both binary \gls{SQI} classes.
% While this highlights the viability of the projection-based approach alongside other time series classifiers, the conventional time series classifiers achieved higher F1 and Precision scores, suggesting they performed better for the positive \gls{SQI} class. An additional drawback is that combining projection-based methods with \gls{CV} models is computationally more expensive and requires more memory than using 1D classifiers. Nevertheless, the projection-based approach proved to be effective for \gls{SQA}, fulfilling our original objective described in Section~\ref{sec:problem}.


% The results reveal that the proposed method is a promising tool for real-life applications, as presented in Section~\ref{sec_intro}.
% This technique allows \gls{AI} engineers to trade memory and computational cost for improved accuracy. By combining multiple projection methods, the approach increases image size and incurs 1D-to-2D conversion costs for each projection.
% For that reason, even though the \gls{CV} models incorporated into the proposed method have sufficiently low latency to support a responsive application, they may not be advisable for wearable devices, such as smartwatches, due to memory constraints.
% It is necessary to process the signal on a remote device with greater memory capacity, such as a server in a remote healthcare environment.
% Therefore, this method is suitable for remote healthcare applications.


% Several opportunities for improvement exist, some of which are discussed in Section~\ref{sec:Limitations}. For instance, this study utilized the only currently available public dataset, which is constrained by its size, variety, and recording length. Future work should involve the development of novel datasets to enable more extensive experiments and cross-dataset validation.
% Beyond expanding the model selection, it is essential to benchmark the proposed method against specialized \gls{SQA} techniques. This would provide a more robust assessment of the method's comparative performance. Finally, the implementation could be refined through optimized pre-processing techniques, advanced training strategies, and a more robust experimental setup.


\section*{Declaration of AI-assisted technologies}

During the preparation of this work the authors used ChatGPT\texttrademark and Grammarly\texttrademark to review English usage and grammatical correction. After using these tools, the authors reviewed and edited the content as needed and take full responsibility for the content of the publication.


\bibliographystyle{elsarticle-num}
% \bibliography{bibliografia}


\begin{thebibliography}{100}
\expandafter\ifx\csname url\endcsname\relax
  \def\url#1{\texttt{#1}}\fi
\expandafter\ifx\csname urlprefix\endcsname\relax\def\urlprefix{URL }\fi
\expandafter\ifx\csname href\endcsname\relax
  \def\href#1#2{#2} \def\path#1{#1}\fi

\bibitem{atheromas}
T.~Thenappan, J.~A. Raza, A.~Movahed,
  \href{https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1540-8175.2007.00568.x}{Review:
  Aortic atheromas: Current concepts and controversies—a review of the
  literature}, Echocardiography 25~(2) (2008) 198--207.
\newblock \href
  {http://arxiv.org/abs/https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1540-8175.2007.00568.x}
  {\path{arXiv:https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1540-8175.2007.00568.x}},
  \href {https://doi.org/https://doi.org/10.1111/j.1540-8175.2007.00568.x}
  {\path{doi:https://doi.org/10.1111/j.1540-8175.2007.00568.x}}.
\newline\urlprefix\url{https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1540-8175.2007.00568.x}

\bibitem{cardiac-amyloidosis}
C.~S. Kwok, W.~E. Moody, \href{https://doi.org/10.1177/17539447231216318}{The
  importance of pathways to facilitate early diagnosis and treatment of
  patients with cardiac amyloidosis}, Therapeutic Advances in Cardiovascular
  Disease 17 (2023) 17539447231216318, pMID: 38099406.
\newblock \href
  {http://arxiv.org/abs/https://doi.org/10.1177/17539447231216318}
  {\path{arXiv:https://doi.org/10.1177/17539447231216318}}, \href
  {https://doi.org/10.1177/17539447231216318}
  {\path{doi:10.1177/17539447231216318}}.
\newline\urlprefix\url{https://doi.org/10.1177/17539447231216318}

\bibitem{van2024smart}
E.~{van Weenen}, Smart wearables in healthcare, in: Dimensions of Intelligent
  Analytics for Smart Digital Health Solutions, Chapman and Hall/CRC, 2024, pp.
  23--61.

\bibitem{aouedi2024survey}
O.~Aouedi, T.~H. Vu, A.~Sacco, D.~C. Nguyen, K.~Piamrat, G.~Marchetto, Q.~V.
  Pham, A survey on intelligent internet of things: applications, security,
  privacy, and future directions, IEEE Communications Surveys \& Tutorials
  (2024).

\bibitem{ECG-diagnosis}
K.~Nikus, O.~Pahlm, G.~Wagner, Y.~Birnbaum, J.~Cinca, P.~Clemmensen, M.~Eskola,
  M.~Fiol, D.~Goldwasser, A.~Gorgels, S.~Sclarovsky, S.~Stern, H.~Wellens,
  W.~Zareba, A.~B. {de Luna},
  \href{https://www.sciencedirect.com/science/article/pii/S0022073609002829}{Electrocardiographic
  classification of acute coronary syndromes: a review by a committee of the
  international society for holter and non-invasive electrocardiology}, Journal
  of Electrocardiology 43~(2) (2010) 91--103.
\newblock \href
  {https://doi.org/https://doi.org/10.1016/j.jelectrocard.2009.07.009}
  {\path{doi:https://doi.org/10.1016/j.jelectrocard.2009.07.009}}.
\newline\urlprefix\url{https://www.sciencedirect.com/science/article/pii/S0022073609002829}

\bibitem{ppg-1}
F.~Scardulla, G.~Cosoli, S.~Spinsante, A.~Poli, G.~Iadarola, R.~Pernice,
  A.~Busacca, S.~Pasta, L.~Scalise, L.~D'Acquisto,
  \href{https://www.sciencedirect.com/science/article/pii/S0263224123007145}{Photoplethysmograhic
  sensors, potential and limitations: Is it time for regulation? a
  comprehensive review}, Measurement 218 (2023) 113150.
\newblock \href
  {https://doi.org/https://doi.org/10.1016/j.measurement.2023.113150}
  {\path{doi:https://doi.org/10.1016/j.measurement.2023.113150}}.
\newline\urlprefix\url{https://www.sciencedirect.com/science/article/pii/S0263224123007145}

\bibitem{butppg}
A.~Nemcova, E.~Vargova, R.~Smisek, L.~Marsanova, L.~Smital, M.~Vitek,
  \href{https://onlinelibrary.wiley.com/doi/abs/10.1155/2021/3453007}{Brno
  university of technology smartphone ppg database (but ppg): Annotated dataset
  for ppg quality assessment and heart rate estimation}, BioMed Research
  International 2021~(1) (2021) 3453007.
\newblock \href
  {http://arxiv.org/abs/https://onlinelibrary.wiley.com/doi/pdf/10.1155/2021/3453007}
  {\path{arXiv:https://onlinelibrary.wiley.com/doi/pdf/10.1155/2021/3453007}},
  \href {https://doi.org/https://doi.org/10.1155/2021/3453007}
  {\path{doi:https://doi.org/10.1155/2021/3453007}}.
\newline\urlprefix\url{https://onlinelibrary.wiley.com/doi/abs/10.1155/2021/3453007}

\bibitem{origins-1}
S.~O. Rice, Mathematical analysis of random noise, The Bell System Technical
  Journal 23~(3) (1944) 282--332.
\newblock \href {https://doi.org/10.1002/j.1538-7305.1944.tb00874.x}
  {\path{doi:10.1002/j.1538-7305.1944.tb00874.x}}.

\bibitem{origins-2}
C.~E. Shannon, A mathematical theory of communication, The Bell System
  Technical Journal 27~(3) (1948) 379--423.
\newblock \href {https://doi.org/10.1002/j.1538-7305.1948.tb01338.x}
  {\path{doi:10.1002/j.1538-7305.1948.tb01338.x}}.

\bibitem{origins-3}
R.~H. Stehle, A double-sideband shortwave-broadcast signal-quality estimation
  algorithm, IEEE Transactions on Broadcasting 34~(2) (1988) 263--282.
\newblock \href {https://doi.org/10.1109/11.1443} {\path{doi:10.1109/11.1443}}.

\bibitem{origins-4}
A.~Bayya, M.~Vis, Objective measures for speech quality assessment in wireless
  communications, in: 1996 IEEE International Conference on Acoustics, Speech,
  and Signal Processing Conference Proceedings, Vol.~1, 1996, pp. 495--498 vol.
  1.
\newblock \href {https://doi.org/10.1109/ICASSP.1996.541141}
  {\path{doi:10.1109/ICASSP.1996.541141}}.

\bibitem{2000s-1}
{Wang, J. Y.}, A new method for evaluating ecg signal quality for multi-lead
  arrhythmia analysis, in: Computers in Cardiology, 2002, pp. 85--88.
\newblock \href {https://doi.org/10.1109/CIC.2002.1166713}
  {\path{doi:10.1109/CIC.2002.1166713}}.

\bibitem{2000s-2}
Q.~Li, R.~G. Mark, G.~D. Clifford,
  \href{https://dx.doi.org/10.1088/0967-3334/29/1/002}{Robust heart rate
  estimation from multiple asynchronous noisy sources using signal quality
  indices and a kalman filter}, Physiological Measurement 29~(1) (2007) 15.
\newblock \href {https://doi.org/10.1088/0967-3334/29/1/002}
  {\path{doi:10.1088/0967-3334/29/1/002}}.
\newline\urlprefix\url{https://dx.doi.org/10.1088/0967-3334/29/1/002}

\bibitem{2000s-3}
A.~V. Deshmane, False arrhythmia alarm suppression using ecg, abp, and
  photoplethysmogram, Master's thesis, Massachusetts Institute of Technology
  (2009).

\bibitem{hjorth-parameters}
B.~Hjorth,
  \href{https://www.sciencedirect.com/science/article/pii/0013469470901434}{Eeg
  analysis based on time domain properties}, Electroencephalography and
  Clinical Neurophysiology 29~(3) (1970) 306--310.
\newblock \href {https://doi.org/https://doi.org/10.1016/0013-4694(70)90143-4}
  {\path{doi:https://doi.org/10.1016/0013-4694(70)90143-4}}.
\newline\urlprefix\url{https://www.sciencedirect.com/science/article/pii/0013469470901434}

\bibitem{2000s-4}
P.~Zhang, J.~Liu, X.~Wu, X.~Liu, Q.~Gao, A novel feature extraction method for
  signal quality assessment of arterial blood pressure for monitoring cerebral
  autoregulation, in: 2010 4th International Conference on Bioinformatics and
  Biomedical Engineering, 2010, pp. 1--4.
\newblock \href {https://doi.org/10.1109/ICBBE.2010.5515739}
  {\path{doi:10.1109/ICBBE.2010.5515739}}.

\bibitem{ecg-1}
S.~K. Berkaya, A.~K. Uysal, E.~S. Gunal, S.~Ergin, S.~Gunal, M.~B. Gulmezoglu,
  \href{https://www.sciencedirect.com/science/article/pii/S1746809418300636}{A
  survey on ecg analysis}, Biomedical Signal Processing and Control 43 (2018)
  216--235.
\newblock \href {https://doi.org/https://doi.org/10.1016/j.bspc.2018.03.003}
  {\path{doi:https://doi.org/10.1016/j.bspc.2018.03.003}}.
\newline\urlprefix\url{https://www.sciencedirect.com/science/article/pii/S1746809418300636}

\bibitem{ecg-2}
H.~Naseri, M.~R. Homaeinezhad,
  \href{https://doi.org/10.1080/10255842.2013.875163}{Electrocardiogram signal
  quality assessment using an artificially reconstructed target lead}, Computer
  Methods in Biomechanics and Biomedical Engineering 18~(10) (2015) 1126--1141,
  pMID: 24460414.
\newblock \href
  {http://arxiv.org/abs/https://doi.org/10.1080/10255842.2013.875163}
  {\path{arXiv:https://doi.org/10.1080/10255842.2013.875163}}, \href
  {https://doi.org/10.1080/10255842.2013.875163}
  {\path{doi:10.1080/10255842.2013.875163}}.
\newline\urlprefix\url{https://doi.org/10.1080/10255842.2013.875163}

\bibitem{ecg-3}
C.~Orphanidou, I.~Drobnjak, Quality assessment of ambulatory ecg using wavelet
  entropy of the hrv signal, IEEE Journal of Biomedical and Health Informatics
  21~(5) (2017) 1216--1223.
\newblock \href {https://doi.org/10.1109/JBHI.2016.2615316}
  {\path{doi:10.1109/JBHI.2016.2615316}}.

\bibitem{ecg-4}
Y.~Shahriari, R.~Fidler, M.~M. Pelter, Y.~Bai, A.~Villaroman, X.~Hu,
  Electrocardiogram signal quality assessment based on structural image
  similarity metric, IEEE Transactions on Biomedical Engineering 65~(4) (2018)
  745--753.
\newblock \href {https://doi.org/10.1109/TBME.2017.2717876}
  {\path{doi:10.1109/TBME.2017.2717876}}.

\bibitem{ecg-5}
J.~Moeyersons, E.~Smets, J.~Morales, A.~Villa, W.~{De Raedt}, D.~Testelmans,
  B.~Buyse, C.~{Van Hoof}, R.~Willems, S.~{Van Huffel}, C.~Varon,
  \href{https://www.sciencedirect.com/science/article/pii/S0169260719312817}{Artefact
  detection and quality assessment of ambulatory ecg signals}, Computer Methods
  and Programs in Biomedicine 182 (2019) 105050.
\newblock \href {https://doi.org/https://doi.org/10.1016/j.cmpb.2019.105050}
  {\path{doi:https://doi.org/10.1016/j.cmpb.2019.105050}}.
\newline\urlprefix\url{https://www.sciencedirect.com/science/article/pii/S0169260719312817}

\bibitem{ecg-6}
A.~Huerta, A.~Martinez-Rodrigo, V.~Bertomeu-Gonzalez, O.~Ayo-Martin, J.~J.
  Rieta, R.~Alcaraz,
  \href{https://www.sciencedirect.com/science/article/pii/S1746809423013538}{Single-lead
  electrocardiogram quality assessment in the context of paroxysmal atrial
  fibrillation through phase space plots}, Biomedical Signal Processing and
  Control 91 (2024) 105920.
\newblock \href {https://doi.org/https://doi.org/10.1016/j.bspc.2023.105920}
  {\path{doi:https://doi.org/10.1016/j.bspc.2023.105920}}.
\newline\urlprefix\url{https://www.sciencedirect.com/science/article/pii/S1746809423013538}

\bibitem{ppg-2}
Q.~Li, G.~D. Clifford,
  \href{https://dx.doi.org/10.1088/0967-3334/33/9/1491}{Dynamic time warping
  and machine learning for signal quality assessment of pulsatile signals},
  Physiological Measurement 33~(9) (2012) 1491.
\newblock \href {https://doi.org/10.1088/0967-3334/33/9/1491}
  {\path{doi:10.1088/0967-3334/33/9/1491}}.
\newline\urlprefix\url{https://dx.doi.org/10.1088/0967-3334/33/9/1491}

\bibitem{ppg-3}
G.~B. Papini, P.~Fonseca, X.~L. Aubert, S.~Overeem, J.~W.~M. Bergmans,
  R.~Vullings, Photoplethysmography beat detection and pulse morphology quality
  assessment for signal reliability estimation, in: 2017 39th Annual
  International Conference of the IEEE Engineering in Medicine and Biology
  Society (EMBC), 2017, pp. 117--120.
\newblock \href {https://doi.org/10.1109/EMBC.2017.8036776}
  {\path{doi:10.1109/EMBC.2017.8036776}}.

\bibitem{such2007motion}
O.~Such, Motion tolerance in wearable sensors-the challenge of motion artifact,
  in: 2007 29th Annual International Conference of the IEEE Engineering in
  Medicine and Biology Society, IEEE, 2007, pp. 1542--1545.

\bibitem{nabavi2020robust}
S.~Nabavi, S.~Bhadra, A robust fusion method for motion artifacts reduction in
  photoplethysmography signal, IEEE Transactions on Instrumentation and
  Measurement 69~(12) (2020) 9599--9608.

\bibitem{tuauctan2015characterization}
A.~M. T{\u{a}}u{\c{t}}an, A.~Young, E.~Wentink, F.~Wieringa, Characterization
  and reduction of motion artifacts in photoplethysmographic signals from a
  wrist-worn device, in: 2015 37th Annual International Conference of the IEEE
  Engineering in Medicine and Biology Society (EMBC), IEEE, 2015, pp.
  6146--6149.

\bibitem{zhang2019motion}
Y.~Zhang, S.~Song, R.~Vullings, D.~Biswas, N.~Sim{\~o}es-Capela,
  N.~Van~Helleputte, C.~Van~Hoof, W.~Groenendaal, Motion artifact reduction for
  wrist-worn photoplethysmograph sensors based on different wavelengths,
  Sensors 19~(3) (2019) 673.

\bibitem{ram2011novel}
M.~R. Ram, K.~V. Madhav, E.~H. Krishna, N.~R. Komalla, K.~A. Reddy, A novel
  approach for motion artifact reduction in ppg signals based on as-lms
  adaptive filter, IEEE Transactions on Instrumentation and Measurement 61~(5)
  (2011) 1445--1457.

\bibitem{raghuram2016use}
M.~Raghuram, K.~Sivani, K.~A. Reddy, Use of complex emd generated noise
  reference for adaptive reduction of motion artifacts from ppg signals, in:
  2016 international conference on electrical, electronics, and optimization
  techniques (ICEEOT), IEEE, 2016, pp. 1816--1820.

\bibitem{janiesch2021machine}
C.~Janiesch, P.~Zschech, K.~Heinrich, Machine learning and deep learning,
  Electronic Markets 31~(3) (2021) 685--695.

\bibitem{ppg-sqa-1}
F.~Mohagheghian, D.~Han, A.~Peitzsch, N.~Nishita, E.~Ding, E.~L. Dickson,
  D.~DiMezza, E.~M. Otabil, K.~Noorishirazi, J.~Scott, D.~Lessard, Z.~Wang,
  C.~Whitcomb, K.~V. Tran, T.~P. Fitzgibbons, D.~D. McManus, K.~H. Chon,
  Optimized signal quality assessment for photoplethysmogram signals using
  feature selection, IEEE Transactions on Biomedical Engineering 69~(9) (2022)
  2982--2993.
\newblock \href {https://doi.org/10.1109/TBME.2022.3158582}
  {\path{doi:10.1109/TBME.2022.3158582}}.

\bibitem{ppg-sqa-2}
A.~Tiwari, G.~Gray, P.~Bondi, A.~Mahnam, T.~H. Falk,
  \href{https://www.mdpi.com/1424-8220/23/12/5606}{Automated multi-wavelength
  quality assessment of photoplethysmography signals using modulation spectrum
  shape features}, Sensors 23~(12) (2023).
\newblock \href {https://doi.org/10.3390/s23125606}
  {\path{doi:10.3390/s23125606}}.
\newline\urlprefix\url{https://www.mdpi.com/1424-8220/23/12/5606}

\bibitem{ppg-sqa-3}
J.~A. Miranda, C.~López-Ongil, J.~Andreu-Perez, Personalised and adjustable
  interval type-2 fuzzy-based ppg quality assessment for the edge, in: 2023
  IEEE International Conference on Fuzzy Systems (FUZZ), 2023, pp. 1--5.
\newblock \href {https://doi.org/10.1109/FUZZ52849.2023.10309733}
  {\path{doi:10.1109/FUZZ52849.2023.10309733}}.

\bibitem{ppg-sqa-4}
M.~S. Roy, R.~Gupta, K.~D. Sharma, Photoplethysmogram signal quality evaluation
  by unsupervised learning approach, in: 2020 IEEE Applied Signal Processing
  Conference (ASPCON), 2020, pp. 6--10.
\newblock \href {https://doi.org/10.1109/ASPCON49795.2020.9276733}
  {\path{doi:10.1109/ASPCON49795.2020.9276733}}.

\bibitem{ppg-sqa-5}
A.~Mahmoudzadeh, I.~Azimi, A.~M. Rahmani, P.~Liljeberg,
  \href{https://www.sciencedirect.com/science/article/pii/S1877050921006499}{Lightweight
  photoplethysmography quality assessment for real-time iot-based health
  monitoring using unsupervised anomaly detection}, Procedia Computer Science
  184 (2021) 140--147, the 12th International Conference on Ambient Systems,
  Networks and Technologies (ANT) / The 4th International Conference on
  Emerging Data and Industry 4.0 (EDI40) / Affiliated Workshops.
\newblock \href {https://doi.org/https://doi.org/10.1016/j.procs.2021.03.025}
  {\path{doi:https://doi.org/10.1016/j.procs.2021.03.025}}.
\newline\urlprefix\url{https://www.sciencedirect.com/science/article/pii/S1877050921006499}

\bibitem{ppg-sqa-6}
M.~Feli, I.~Azimi, A.~Anzanpour, A.~M. Rahmani, P.~Liljeberg,
  \href{https://www.sciencedirect.com/science/article/pii/S2352648323000181}{An
  energy-efficient semi-supervised approach for on-device photoplethysmogram
  signal quality assessment}, Smart Health 28 (2023) 100390.
\newblock \href {https://doi.org/https://doi.org/10.1016/j.smhl.2023.100390}
  {\path{doi:https://doi.org/10.1016/j.smhl.2023.100390}}.
\newline\urlprefix\url{https://www.sciencedirect.com/science/article/pii/S2352648323000181}

\bibitem{arrhythmia-1}
C.~Antzelevitch, A.~Burashnikov, Overview of basic mechanisms of cardiac
  arrhythmia, Cardiac electrophysiology clinics 3~(1) (2011) 23--45.

\bibitem{arrhythmia-2}
T.~Pereira, K.~Gadhoumi, M.~Ma, R.~Colorado, K.~J. Keenan, K.~Meisel, X.~Hu,
  Robust assessment of photoplethysmogram signal quality in the presence of
  atrial fibrillation, in: 2018 Computing in Cardiology Conference (CinC),
  Vol.~45, 2018, pp. 1--4.
\newblock \href {https://doi.org/10.22489/CinC.2018.254}
  {\path{doi:10.22489/CinC.2018.254}}.

\bibitem{arrhythmia-3}
T.~Pereira, K.~Gadhoumi, M.~Ma, X.~Liu, R.~Xiao, R.~A. Colorado, K.~J. Keenan,
  K.~Meisel, X.~Hu, A supervised approach to robust photoplethysmography
  quality assessment, IEEE Journal of Biomedical and Health Informatics 24~(3)
  (2020) 649--657.
\newblock \href {https://doi.org/10.1109/JBHI.2019.2909065}
  {\path{doi:10.1109/JBHI.2019.2909065}}.

\bibitem{arrhythmia-4}
T.~Pereira, C.~Ding, K.~Gadhoumi, N.~Tran, R.~A. Colorado, K.~Meisel, X.~Hu,
  \href{https://dx.doi.org/10.1088/1361-6579/ab5b84}{Deep learning approaches
  for plethysmography signal quality assessment in the presence of atrial
  fibrillation}, Physiological Measurement 40~(12) (2019) 125002.
\newblock \href {https://doi.org/10.1088/1361-6579/ab5b84}
  {\path{doi:10.1088/1361-6579/ab5b84}}.
\newline\urlprefix\url{https://dx.doi.org/10.1088/1361-6579/ab5b84}

\bibitem{gaf-mtf-1}
Z.~Wang, T.~Oates, Encoding time series as images for visual inspection and
  classification using tiled convolutional neural networks, in: Workshops at
  the twenty-ninth AAAI conference on artificial intelligence, 2015.

\bibitem{rp-1}
J.~P. Eckmann, S.~O. Kamphorst, D.~Ruelle, Recurrence plots of dynamical
  systems, World Scientific Series on Nonlinear Science Series A 16 (1995)
  441--446.

\bibitem{imaging-6}
J.~Liu, S.~Hu, Y.~Wang, Q.~Hu, D.~Wang, C.~Yang, A lightweight hybrid model
  using multiscale markov transition field for real-time quality assessment of
  photoplethysmography signals, IEEE Journal of Biomedical and Health
  Informatics 28~(2) (2024) 1078--1088.
\newblock \href {https://doi.org/10.1109/JBHI.2023.3331975}
  {\path{doi:10.1109/JBHI.2023.3331975}}.

\bibitem{STFT}
K.~Gr{\"o}chenig, Foundations of time-frequency analysis, Springer Science \&
  Business Media, 2013.

\bibitem{imaging-1}
J.~Chen, K.~Sun, Y.~Sun, X.~Li, Signal quality assessment of ppg signals using
  stft time-frequency spectra and deep learning approaches, in: 2021 43rd
  Annual International Conference of the IEEE Engineering in Medicine \&
  Biology Society (EMBC), 2021, pp. 1153--1156.
\newblock \href {https://doi.org/10.1109/EMBC46164.2021.9630758}
  {\path{doi:10.1109/EMBC46164.2021.9630758}}.

\bibitem{deep-learning-1}
E.~K. Naeini, I.~Azimi, A.~M. Rahmani, P.~Liljeberg, N.~Dutt,
  \href{https://www.sciencedirect.com/science/article/pii/S1877050919305368}{A
  real-time ppg quality assessment approach for healthcare internet-of-things},
  Procedia Computer Science 151 (2019) 551--558, the 10th International
  Conference on Ambient Systems, Networks and Technologies (ANT 2019) / The 2nd
  International Conference on Emerging Data and Industry 4.0 (EDI40 2019) /
  Affiliated Workshops.
\newblock \href {https://doi.org/https://doi.org/10.1016/j.procs.2019.04.074}
  {\path{doi:https://doi.org/10.1016/j.procs.2019.04.074}}.
\newline\urlprefix\url{https://www.sciencedirect.com/science/article/pii/S1877050919305368}

\bibitem{deep-learning-2}
S.~Zanelli, M.~A. El~Yacoubi, M.~Hallab, M.~Ammi, Transfer learning of
  cnn-based signal quality assessment from clinical to non-clinical ppg
  signals, in: 2021 43rd Annual International Conference of the IEEE
  Engineering in Medicine \& Biology Society (EMBC), 2021, pp. 902--905.
\newblock \href {https://doi.org/10.1109/EMBC46164.2021.9629640}
  {\path{doi:10.1109/EMBC46164.2021.9629640}}.

\bibitem{deep-learning-3}
G.~D. Lucaf{\'o}, P.~Freitas, R.~Lima, G.~da~Luz, R.~Bispo, P.~Rodrigues,
  F.~Cabello, O.~Penatti, Signal quality assessment of photoplethysmogram
  signals using hybrid rule-and learning-based models, Journal of Health
  Informatics 15~(Especial) (2023).

\bibitem{deep-learning-4}
H.~Gao, C.~Zhang, S.~Pei, X.~Wu,
  \href{https://opg.optica.org/boe/abstract.cfm?URI=boe-14-3-1119}{Lstm-based
  real-time signal quality assessment for blood volume pulse analysis}, Biomed.
  Opt. Express 14~(3) (2023) 1119--1136.
\newblock \href {https://doi.org/10.1364/BOE.477143}
  {\path{doi:10.1364/BOE.477143}}.
\newline\urlprefix\url{https://opg.optica.org/boe/abstract.cfm?URI=boe-14-3-1119}

\bibitem{deep-learning-5}
M.~S. Roy, B.~Roy, R.~Gupta, K.~D. Sharma, On-device reliability assessment and
  prediction of missing photoplethysmographic data using deep neural networks,
  IEEE Transactions on Biomedical Circuits and Systems 14~(6) (2020)
  1323--1332.
\newblock \href {https://doi.org/10.1109/TBCAS.2020.3028935}
  {\path{doi:10.1109/TBCAS.2020.3028935}}.

\bibitem{deep-learning-6}
E.~K. Naeini, F.~Sarhaddi, I.~Azimi, P.~Liljeberg, N.~Dutt, A.~M. Rahmani,
  \href{https://doi.org/10.1145/3616019}{A deep learning–based ppg quality
  assessment approach for heart rate and heart rate variability}, ACM Trans.
  Comput. Healthcare 4~(4) (nov 2023).
\newblock \href {https://doi.org/10.1145/3616019} {\path{doi:10.1145/3616019}}.
\newline\urlprefix\url{https://doi.org/10.1145/3616019}

\bibitem{vitaldb-dataset}
H.~C. Lee, C.~W. Jung,
  \href{https://www.doi.org/10.1038/s41598-018-20062-4}{Vital recorder—a free
  research tool for automatic recording of high-resolution time-synchronised
  physiological data from multiple anaesthesia devices}, Scientific reports
  8~(1) (2018) 1527.
\newblock \href {https://doi.org/10.1038/s41598-018-20062-4}
  {\path{doi:10.1038/s41598-018-20062-4}}.
\newline\urlprefix\url{https://www.doi.org/10.1038/s41598-018-20062-4}

\bibitem{imaging-2}
T.~Chatterjee, A.~Ghosh, S.~Sarkar, Signal quality assessment of
  photoplethysmogram signals using quantum pattern recognition technique and
  lightweight cnn module, in: 2022 44th Annual International Conference of the
  IEEE Engineering in Medicine \& Biology Society (EMBC), 2022, pp. 3382--3386.
\newblock \href {https://doi.org/10.1109/EMBC48229.2022.9871494}
  {\path{doi:10.1109/EMBC48229.2022.9871494}}.

\bibitem{queensland-dataset}
D.~Liu, M.~G{\"o}rges, S.~A. Jenkins,
  \href{https://www.doi.org/10.1213/ANE.0b013e318241f7c0}{University of
  queensland vital signs dataset: Development of an accessible repository of
  anesthesia patient monitoring data for research}, Anesthesia \& Analgesia
  114~(3) (2012) 584--589.
\newblock \href {https://doi.org/10.1213/ANE.0b013e318241f7c0}
  {\path{doi:10.1213/ANE.0b013e318241f7c0}}.
\newline\urlprefix\url{https://www.doi.org/10.1213/ANE.0b013e318241f7c0}

\bibitem{imaging-3}
D.~Roh, H.~Shin, \href{https://www.mdpi.com/1424-8220/21/6/2188}{Recurrence
  plot and machine learning for signal quality assessment of photoplethysmogram
  in mobile environment}, Sensors 21~(6) (2021).
\newblock \href {https://doi.org/10.3390/s21062188}
  {\path{doi:10.3390/s21062188}}.
\newline\urlprefix\url{https://www.mdpi.com/1424-8220/21/6/2188}

\bibitem{imaging-4}
P.~G. Freitas, R.~G. De~Lima, G.~D. Lucafo, O.~A.~B. Penatti,
  Photoplethysmogram signal quality assessment via 1d-to-2d projections and
  vision transformers, in: 2023 15th International Conference on Quality of
  Multimedia Experience (QoMEX), 2023, pp. 165--170.
\newblock \href {https://doi.org/10.1109/QoMEX58391.2023.10178569}
  {\path{doi:10.1109/QoMEX58391.2023.10178569}}.

\bibitem{imaging-5}
P.~G. Freitas, R.~G. De~Lima, G.~D. Lucafo, O.~A.~B. Penatti, Assessing the
  quality of photoplethysmograms via gramian angular fields and vision
  transformer, in: 2023 31st European Signal Processing Conference (EUSIPCO),
  2023, pp. 1035--1039.
\newblock \href {https://doi.org/10.23919/EUSIPCO58844.2023.10290014}
  {\path{doi:10.23919/EUSIPCO58844.2023.10290014}}.

\bibitem{rp-2}
N.~Marwan, A historical review of recurrence plots, The European Physical
  Journal Special Topics 164~(1) (2008) 3--12.

\bibitem{rp-3}
L.~C.~S. Afonso, G.~H. Rosa, C.~R. Pereira, S.~A.~T. Weber, C.~Hook, V.~H.~C.
  Albuquerque, J.~P. Papa,
  \href{https://www.sciencedirect.com/science/article/pii/S0167739X18322507}{A
  recurrence plot-based approach for parkinson’s disease identification},
  Future Generation Computer Systems 94 (2019) 282--292.
\newblock \href {https://doi.org/https://doi.org/10.1016/j.future.2018.11.054}
  {\path{doi:https://doi.org/10.1016/j.future.2018.11.054}}.
\newline\urlprefix\url{https://www.sciencedirect.com/science/article/pii/S0167739X18322507}

\bibitem{rp-4}
A.~Shankar, H.~K. Khaing, S.~Dandapat, S.~Barma,
  \href{https://www.sciencedirect.com/science/article/pii/S1746809421004511}{Analysis
  of epileptic seizures based on eeg using recurrence plot images and deep
  learning}, Biomedical Signal Processing and Control 69 (2021) 102854.
\newblock \href {https://doi.org/https://doi.org/10.1016/j.bspc.2021.102854}
  {\path{doi:https://doi.org/10.1016/j.bspc.2021.102854}}.
\newline\urlprefix\url{https://www.sciencedirect.com/science/article/pii/S1746809421004511}

\bibitem{rp-5}
Z.~Zhao, Y.~Zhang, Z.~Comert, Y.~Deng,
  \href{https://www.frontiersin.org/journals/physiology/articles/10.3389/fphys.2019.00255}{Computer-aided
  diagnosis system of fetal hypoxia incorporating recurrence plot with
  convolutional neural network}, Frontiers in Physiology 10 (2019).
\newblock \href {https://doi.org/10.3389/fphys.2019.00255}
  {\path{doi:10.3389/fphys.2019.00255}}.
\newline\urlprefix\url{https://www.frontiersin.org/journals/physiology/articles/10.3389/fphys.2019.00255}

\bibitem{rp-6}
X.~Li, T.~Zhou, S.~Qiu,
  \href{https://www.frontiersin.org/journals/aging-neuroscience/articles/10.3389/fnagi.2022.888577}{Alzheimer's
  disease analysis algorithm based on no-threshold recurrence plot convolution
  network}, Frontiers in Aging Neuroscience 14 (2022).
\newblock \href {https://doi.org/10.3389/fnagi.2022.888577}
  {\path{doi:10.3389/fnagi.2022.888577}}.
\newline\urlprefix\url{https://www.frontiersin.org/journals/aging-neuroscience/articles/10.3389/fnagi.2022.888577}

\bibitem{mtf-1}
A.~S. L.~O. Campanharo, M.~I. Sirer, R.~D. Malmgren, F.~M. Ramos, L.~A.~N.
  Amaral, \href{https://doi.org/10.1371/journal.pone.0023378}{Duality between
  time series and networks}, PLOS ONE 6~(8) (2011) 1--13.
\newblock \href {https://doi.org/10.1371/journal.pone.0023378}
  {\path{doi:10.1371/journal.pone.0023378}}.
\newline\urlprefix\url{https://doi.org/10.1371/journal.pone.0023378}

\bibitem{ImageNet}
J.~Deng, W.~Dong, R.~Socher, L.~J. Li, K.~Li, L.~Fei-Fei, Imagenet: A
  large-scale hierarchical image database, in: 2009 IEEE Conference on Computer
  Vision and Pattern Recognition, 2009, pp. 248--255.
\newblock \href {https://doi.org/10.1109/CVPR.2009.5206848}
  {\path{doi:10.1109/CVPR.2009.5206848}}.

\bibitem{aeon2024}
M.~Middlehurst, A.~Ismail-Fawaz, A.~Guillaume, C.~Holder, D.~Guijo-Rubio,
  G.~Bulatova, L.~Tsaprounis, L.~Mentel, M.~Walter, P.~Sch\"{a}fer, A.~Bagnall,
  Aeon: a python toolkit for learning from time series, J. Mach. Learn. Res.
  25~(1) (Jan. 2024).

\bibitem{pytorch}
A.~Paszke, S.~Gross, F.~Massa, A.~Lerer, J.~Bradbury, G.~Chanan, T.~Killeen,
  Z.~Lin, N.~Gimelshein, L.~Antiga, A.~Desmaison, A.~K\"{o}pf, E.~Yang,
  Z.~DeVito, M.~Raison, A.~Tejani, S.~Chilamkurthy, B.~Steiner, L.~Fang,
  J.~Bai, S.~Chintala, PyTorch: An Imperative Style, High-Performance Deep
  Learning Library, Curran Associates Inc., Red Hook, NY, USA, 2019.

\bibitem{HIVECOTEV2}
M.~Middlehurst, J.~Large, M.~Flynn, J.~Lines, A.~Bostrom, A.~Bagnall,
  \href{https://doi.org/10.1007/s10994-021-06057-9}{Hive-cote 2.0: a new meta
  ensemble for time series classification}, Mach. Learn. 110~(11–12) (2021)
  3211–3243.
\newblock \href {https://doi.org/10.1007/s10994-021-06057-9}
  {\path{doi:10.1007/s10994-021-06057-9}}.
\newline\urlprefix\url{https://doi.org/10.1007/s10994-021-06057-9}

\bibitem{RocketClassifier}
A.~Dempster, F.~Petitjean, G.~I. Webb,
  \href{https://doi.org/10.1007/s10618-020-00701-z}{{ROCKET:} exceptionally
  fast and accurate time series classification using random convolutional
  kernels}, Data Min. Knowl. Discov. 34~(5) (2020) 1454--1495.
\newblock \href {https://doi.org/10.1007/S10618-020-00701-Z}
  {\path{doi:10.1007/S10618-020-00701-Z}}.
\newline\urlprefix\url{https://doi.org/10.1007/s10618-020-00701-z}

\bibitem{CNNClassifier}
B.~Zhao, H.~Lu, S.~Chen, J.~Liu, D.~Wu, Convolutional neural networks for time
  series classification, Journal of Systems Engineering and Electronics 28~(1)
  (2017) 162--169.
\newblock \href {https://doi.org/10.21629/JSEE.2017.01.18}
  {\path{doi:10.21629/JSEE.2017.01.18}}.

\bibitem{FCNClassifier-MLPClassifier}
Z.~Wang, W.~Yan, T.~Oates,
  \href{https://doi.org/10.1109/IJCNN.2017.7966039}{Time series classification
  from scratch with deep neural networks: {A} strong baseline}, in: 2017
  International Joint Conference on Neural Networks, {IJCNN} 2017, Anchorage,
  AK, USA, May 14-19, 2017, {IEEE}, 2017, pp. 1578--1585.
\newblock \href {https://doi.org/10.1109/IJCNN.2017.7966039}
  {\path{doi:10.1109/IJCNN.2017.7966039}}.
\newline\urlprefix\url{https://doi.org/10.1109/IJCNN.2017.7966039}

\bibitem{Inception1}
H.~Ismai-Fawaz, B.~Lucas, G.~Forestier, C.~Pelletier, D.~F. Schmidt, J.~Weber,
  G.~I. Webb, L.~Idoumghar, P.~A. Muller, F.~Petitjean,
  \href{https://doi.org/10.1007/s10618-020-00710-y}{Inceptiontime: Finding
  alexnet for time series classification}, Data Min. Knowl. Discov. 34~(6)
  (2020) 1936–1962.
\newblock \href {https://doi.org/10.1007/s10618-020-00710-y}
  {\path{doi:10.1007/s10618-020-00710-y}}.
\newline\urlprefix\url{https://doi.org/10.1007/s10618-020-00710-y}

\bibitem{Inception2}
A.~Ismail-Fawaz, M.~Devanne, J.~Weber, G.~Forestier, Deep learning for time
  series classification using new hand-crafted convolution filters, in: 2022
  IEEE International Conference on Big Data (Big Data), 2022, pp. 972--981.
\newblock \href {https://doi.org/10.1109/BigData55660.2022.10020496}
  {\path{doi:10.1109/BigData55660.2022.10020496}}.

\bibitem{LITETimeClassifier}
A.~Ismail-Fawaz, M.~Devanne, S.~Berretti, J.~Weber, G.~Forestier, Lite: Light
  inception with boosting techniques for time series classification, in: 2023
  IEEE 10th International Conference on Data Science and Advanced Analytics
  (DSAA), 2023, pp. 1--10.
\newblock \href {https://doi.org/10.1109/DSAA60987.2023.10302569}
  {\path{doi:10.1109/DSAA60987.2023.10302569}}.

\bibitem{BOSSEnsemble}
P.~Sch{\"{a}}fer, \href{https://doi.org/10.1007/s10618-014-0377-7}{The {BOSS}
  is concerned with time series classification in the presence of noise}, Data
  Min. Knowl. Discov. 29~(6) (2015) 1505--1530.
\newblock \href {https://doi.org/10.1007/S10618-014-0377-7}
  {\path{doi:10.1007/S10618-014-0377-7}}.
\newline\urlprefix\url{https://doi.org/10.1007/s10618-014-0377-7}

\bibitem{ContractableBOSS}
M.~Middlehurst, W.~Vickers, A.~Bagnall, Scalable dictionary classifiers for
  time series classification, in: H.~Yin, D.~Camacho, P.~Tino, A.~J.
  Tall{\'o}n-Ballesteros, R.~Menezes, R.~Allmendinger (Eds.), Intelligent Data
  Engineering and Automated Learning -- IDEAL 2019, Springer International
  Publishing, Cham, 2019, pp. 11--19.

\bibitem{TDE}
M.~Middlehurst, J.~Large, G.~Cawley, A.~Bagnall,
  \href{https://doi.org/10.1007/978-3-030-67658-2_38}{The temporal dictionary
  ensemble (tde) classifier for time series classification}, in: Machine
  Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD
  2020, Ghent, Belgium, September 14–18, 2020, Proceedings, Part I,
  Springer-Verlag, Berlin, Heidelberg, 2020, p. 660–676.
\newblock \href {https://doi.org/10.1007/978-3-030-67658-2_38}
  {\path{doi:10.1007/978-3-030-67658-2_38}}.
\newline\urlprefix\url{https://doi.org/10.1007/978-3-030-67658-2_38}

\bibitem{MUSE}
P.~Sch{\"{a}}fer, U.~Leser, \href{http://arxiv.org/abs/1711.11343}{Multivariate
  time series classification with {WEASEL+MUSE}}, CoRR abs/1711.11343 (2017).
\newblock \href {http://arxiv.org/abs/1711.11343} {\path{arXiv:1711.11343}}.
\newline\urlprefix\url{http://arxiv.org/abs/1711.11343}

\bibitem{WEASEL}
P.~Sch\"{a}fer, U.~Leser, \href{https://doi.org/10.1145/3132847.3132980}{Fast
  and accurate time series classification with weasel}, in: Proceedings of the
  2017 ACM on Conference on Information and Knowledge Management, CIKM '17,
  Association for Computing Machinery, New York, NY, USA, 2017, p. 637–646.
\newblock \href {https://doi.org/10.1145/3132847.3132980}
  {\path{doi:10.1145/3132847.3132980}}.
\newline\urlprefix\url{https://doi.org/10.1145/3132847.3132980}

\bibitem{WEASELV2}
P.~Sch{\"{a}}fer, U.~Leser,
  \href{https://doi.org/10.1007/s10994-023-06395-w}{{WEASEL} 2.0: a random
  dilated dictionary transform for fast, accurate and memory constrained time
  series classification}, Mach. Learn. 112~(12) (2023) 4763--4788.
\newblock \href {https://doi.org/10.1007/S10994-023-06395-W}
  {\path{doi:10.1007/S10994-023-06395-W}}.
\newline\urlprefix\url{https://doi.org/10.1007/s10994-023-06395-w}

\bibitem{REDCOMETS-1}
L.~A. Bennett, Z.~S. Abdallah,
  \href{https://doi.org/10.1007/978-3-031-49896-1\_6}{{RED} comets: An ensemble
  classifier for symbolically represented multivariate time series}, in:
  G.~Ifrim, R.~Tavenard, A.~J. Bagnall, P.~Sch{\"{a}}fer, S.~Malinowski,
  T.~Guyet, V.~Lemaire (Eds.), Advanced Analytics and Learning on Temporal Data
  - 8th {ECML} {PKDD} Workshop, {AALTD} 2023, Turin, Italy, September 18-22,
  2023, Revised Selected Papers, Vol. 14343 of Lecture Notes in Computer
  Science, Springer, 2023, pp. 76--91.
\newblock \href {https://doi.org/10.1007/978-3-031-49896-1\_6}
  {\path{doi:10.1007/978-3-031-49896-1\_6}}.
\newline\urlprefix\url{https://doi.org/10.1007/978-3-031-49896-1\_6}

\bibitem{REDCOMETS-2}
Z.~S. Abdallah, M.~M. Gaber,
  \href{https://doi.org/10.1007/s10994-020-05887-3}{Co-eye: a multi-resolution
  ensemble classifier for symbolically approximated time series}, Mach. Learn.
  109~(11) (2020) 2029--2061.
\newblock \href {https://doi.org/10.1007/S10994-020-05887-3}
  {\path{doi:10.1007/S10994-020-05887-3}}.
\newline\urlprefix\url{https://doi.org/10.1007/s10994-020-05887-3}

\bibitem{ElasticEnsemble}
J.~Lines, A.~J. Bagnall, \href{https://doi.org/10.1007/s10618-014-0361-2}{Time
  series classification with ensembles of elastic distance measures}, Data Min.
  Knowl. Discov. 29~(3) (2015) 565--592.
\newblock \href {https://doi.org/10.1007/S10618-014-0361-2}
  {\path{doi:10.1007/S10618-014-0361-2}}.
\newline\urlprefix\url{https://doi.org/10.1007/s10618-014-0361-2}

\bibitem{ShapeDTW}
J.~Zhao, L.~Itti,
  \href{https://www.sciencedirect.com/science/article/pii/S0031320317303710}{shapedtw:
  Shape dynamic time warping}, Pattern Recognition 74 (2018) 171--184.
\newblock \href {https://doi.org/https://doi.org/10.1016/j.patcog.2017.09.020}
  {\path{doi:https://doi.org/10.1016/j.patcog.2017.09.020}}.
\newline\urlprefix\url{https://www.sciencedirect.com/science/article/pii/S0031320317303710}

\bibitem{Catch22Classifier}
C.~H. Lubba, S.~S. Sethi, P.~Knaute, S.~R. Schultz, B.~D. Fulcher, N.~S. Jones,
  \href{https://doi.org/10.1007/s10618-019-00647-x}{catch22: Canonical
  time-series characteristics - selected through highly comparative time-series
  analysis}, Data Min. Knowl. Discov. 33~(6) (2019) 1821--1852.
\newblock \href {https://doi.org/10.1007/S10618-019-00647-X}
  {\path{doi:10.1007/S10618-019-00647-X}}.
\newline\urlprefix\url{https://doi.org/10.1007/s10618-019-00647-x}

\bibitem{TSFreshClassifier}
M.~Christ, N.~Braun, J.~Neuffer, A.~W. Kempa-Liehr,
  \href{https://www.sciencedirect.com/science/article/pii/S0925231218304843}{Time
  series feature extraction on basis of scalable hypothesis tests (tsfresh –
  a python package)}, Neurocomputing 307 (2018) 72--77.
\newblock \href {https://doi.org/https://doi.org/10.1016/j.neucom.2018.03.067}
  {\path{doi:https://doi.org/10.1016/j.neucom.2018.03.067}}.
\newline\urlprefix\url{https://www.sciencedirect.com/science/article/pii/S0925231218304843}

\bibitem{CanonicalIntervalForestClassifier}
M.~Middlehurst, J.~Large, A.~Bagnall, The canonical interval forest (cif)
  classifier for time series classification, in: 2020 IEEE International
  Conference on Big Data (Big Data), 2020, pp. 188--195.
\newblock \href {https://doi.org/10.1109/BigData50022.2020.9378424}
  {\path{doi:10.1109/BigData50022.2020.9378424}}.

\bibitem{RandomIntervalSpectralEnsembleClassifier}
J.~Lines, S.~Taylor, A.~Bagnall, \href{https://doi.org/10.1145/3182382}{Time
  series classification with hive-cote: The hierarchical vote collective of
  transformation-based ensembles}, ACM Trans. Knowl. Discov. Data 12~(5) (jul
  2018).
\newblock \href {https://doi.org/10.1145/3182382} {\path{doi:10.1145/3182382}}.
\newline\urlprefix\url{https://doi.org/10.1145/3182382}

\bibitem{SupervisedTimeSeriesForest}
N.~Cabello, E.~Naghizade, J.~Qi, L.~Kulik, Fast and accurate time series
  classification through supervised interval search, in: 2020 IEEE
  International Conference on Data Mining (ICDM), 2020, pp. 948--953.
\newblock \href {https://doi.org/10.1109/ICDM50108.2020.00107}
  {\path{doi:10.1109/ICDM50108.2020.00107}}.

\bibitem{TimeSeriesForestClassifier}
H.~Deng, G.~Runger, E.~Tuv, M.~Vladimir,
  \href{https://www.sciencedirect.com/science/article/pii/S0020025513001473}{A
  time series forest for classification and feature extraction}, Information
  Sciences 239 (2013) 142--153.
\newblock \href {https://doi.org/https://doi.org/10.1016/j.ins.2013.02.030}
  {\path{doi:https://doi.org/10.1016/j.ins.2013.02.030}}.
\newline\urlprefix\url{https://www.sciencedirect.com/science/article/pii/S0020025513001473}

\bibitem{ShapeletTransformClassifier-1}
J.~Hills, J.~Lines, E.~Baranauskas, J.~Mapp, A.~J. Bagnall,
  \href{https://doi.org/10.1007/s10618-013-0322-1}{Classification of time
  series by shapelet transformation}, Data Min. Knowl. Discov. 28~(4) (2014)
  851--881.
\newblock \href {https://doi.org/10.1007/S10618-013-0322-1}
  {\path{doi:10.1007/S10618-013-0322-1}}.
\newline\urlprefix\url{https://doi.org/10.1007/s10618-013-0322-1}

\bibitem{ShapeletTransformClassifier-2}
A.~Bostrom, A.~J. Bagnall,
  \href{https://doi.org/10.1007/978-3-662-55608-5\_2}{Binary shapelet transform
  for multiclass time series classification}, Trans. Large Scale Data Knowl.
  Centered Syst. 32 (2017) 24--46.
\newblock \href {https://doi.org/10.1007/978-3-662-55608-5\_2}
  {\path{doi:10.1007/978-3-662-55608-5\_2}}.
\newline\urlprefix\url{https://doi.org/10.1007/978-3-662-55608-5\_2}

\bibitem{RDSTClassifier-1}
A.~Guillaume, C.~Vrain, W.~Elloumi,
  \href{https://doi.org/10.1007/978-3-031-09037-0\_53}{Random dilated shapelet
  transform: {A} new approach for time series shapelets}, in: M.~A.
  El{-}Yacoubi, E.~Granger, P.~C. Yuen, U.~Pal, N.~Vincent (Eds.), Pattern
  Recognition and Artificial Intelligence - Third International Conference,
  {ICPRAI} 2022, Paris, France, June 1-3, 2022, Proceedings, Part {I}, Vol.
  13363 of Lecture Notes in Computer Science, Springer, 2022, pp. 653--664.
\newblock \href {https://doi.org/10.1007/978-3-031-09037-0\_53}
  {\path{doi:10.1007/978-3-031-09037-0\_53}}.
\newline\urlprefix\url{https://doi.org/10.1007/978-3-031-09037-0\_53}

\bibitem{RDSTClassifier-2}
A.~Guillaume, C.~Vrain, W.~Elloumi,
  \href{https://tel.archives-ouvertes.fr/tel-04368849}{Time series
  classification with shapelets: Application to predictive maintenance on event
  logs. (classification de s{\'{e}}ries temporelles avec les shapelets :
  application {\`{a}} la maintenance pr{\'{e}}dictive via journaux
  d'{\'{e}}v{\'{e}}nements)}, Ph.D. thesis, University of Orl{\'{e}}ans, France
  (2023).
\newline\urlprefix\url{https://tel.archives-ouvertes.fr/tel-04368849}

\bibitem{OrdinalTDE}
R.~Ayll\'{o}n-Gavil\'{a}n, D.~Guijo-Rubio, P.~A. Guti\'{e}rrez,
  C.~Herv\'{a}s-Mart\'{\i}nez, A dictionary-based approach to time series
  ordinal classification, in: Advances in Computational Intelligence: 17th
  International Work-Conference on Artificial Neural Networks, IWANN 2023,
  Ponta Delgada, Portugal, June 19–21, 2023, Proceedings, Part II,
  Springer-Verlag, Berlin, Heidelberg, 2023, p. 541–552.
\newblock \href {https://doi.org/10.1007/978-3-031-43078-7_44}
  {\path{doi:10.1007/978-3-031-43078-7_44}}.

\bibitem{ContinuousIntervalTree}
H.~Deng, G.~Runger, E.~Tuv, M.~Vladimir,
  \href{https://www.sciencedirect.com/science/article/pii/S0020025513001473}{A
  time series forest for classification and feature extraction}, Information
  Sciences 239 (2013) 142--153.
\newblock \href {https://doi.org/https://doi.org/10.1016/j.ins.2013.02.030}
  {\path{doi:https://doi.org/10.1016/j.ins.2013.02.030}}.
\newline\urlprefix\url{https://www.sciencedirect.com/science/article/pii/S0020025513001473}

\bibitem{RotationForestClassifier}
J.~J. Rodr{\'{\i}}guez, L.~I. Kuncheva, C.~J. Alonso,
  \href{https://doi.org/10.1109/TPAMI.2006.211}{Rotation forest: {A} new
  classifier ensemble method}, {IEEE} Trans. Pattern Anal. Mach. Intell.
  28~(10) (2006) 1619--1630.
\newblock \href {https://doi.org/10.1109/TPAMI.2006.211}
  {\path{doi:10.1109/TPAMI.2006.211}}.
\newline\urlprefix\url{https://doi.org/10.1109/TPAMI.2006.211}

\bibitem{VisionTransformer}
A.~Dosovitskiy, L.~Beyer, A.~Kolesnikov, D.~Weissenborn, X.~Zhai,
  T.~Unterthiner, M.~Dehghani, M.~Minderer, G.~Heigold, S.~Gelly, J.~Uszkoreit,
  N.~Houlsby, \href{https://openreview.net/forum?id=YicbFdNTTy}{An image is
  worth 16x16 words: Transformers for image recognition at scale}, in:
  International Conference on Learning Representations, 2021.
\newline\urlprefix\url{https://openreview.net/forum?id=YicbFdNTTy}

\bibitem{MaxViT}
Z.~Tu, H.~Talebi, H.~Zhang, F.~Yang, P.~Milanfar, A.~Bovik, Y.~Li, Maxvit:
  Multi-axis vision transformer, in: S.~Avidan, G.~Brostow, M.~Ciss{\'e}, G.~M.
  Farinella, T.~Hassner (Eds.), Computer Vision -- ECCV 2022, Springer Nature
  Switzerland, Cham, 2022, pp. 459--479.

\bibitem{SwinTransformer}
Z.~Liu, Y.~Lin, Y.~Cao, H.~Hu, Y.~Wei, Z.~Zhang, S.~Lin, B.~Guo, Swin
  transformer: Hierarchical vision transformer using shifted windows, in: 2021
  IEEE/CVF International Conference on Computer Vision (ICCV), 2021, pp.
  9992--10002.
\newblock \href {https://doi.org/10.1109/ICCV48922.2021.00986}
  {\path{doi:10.1109/ICCV48922.2021.00986}}.

\bibitem{SwinTransformerV2}
Z.~Liu, H.~Hu, Y.~Lin, Z.~Yao, Z.~Xie, Y.~Wei, J.~Ning, Y.~Cao, Z.~Zhang,
  L.~Dong, F.~Wei, B.~Guo, Swin transformer v2: Scaling up capacity and
  resolution, in: 2022 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR), 2022, pp. 11999--12009.
\newblock \href {https://doi.org/10.1109/CVPR52688.2022.01170}
  {\path{doi:10.1109/CVPR52688.2022.01170}}.

\bibitem{ResNet}
K.~He, X.~Zhang, S.~Ren, J.~Sun, Deep residual learning for image recognition,
  in: 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR),
  2016, pp. 770--778.
\newblock \href {https://doi.org/10.1109/CVPR.2016.90}
  {\path{doi:10.1109/CVPR.2016.90}}.

\bibitem{ResNeXt}
S.~Xie, R.~Girshick, P.~Dollár, Z.~Tu, K.~He, Aggregated residual
  transformations for deep neural networks, in: 2017 IEEE Conference on
  Computer Vision and Pattern Recognition (CVPR), 2017, pp. 5987--5995.
\newblock \href {https://doi.org/10.1109/CVPR.2017.634}
  {\path{doi:10.1109/CVPR.2017.634}}.

\bibitem{WideResNet}
S.~Zagoruyko, N.~Komodakis, \href{https://dx.doi.org/10.5244/C.30.87}{Wide
  residual networks}, in: E.~R.~H. Richard C.~Wilson, W.~A.~P. Smith (Eds.),
  Proceedings of the British Machine Vision Conference (BMVC), BMVA Press,
  2016, pp. 87.1--87.12.
\newblock \href {https://doi.org/10.5244/C.30.87} {\path{doi:10.5244/C.30.87}}.
\newline\urlprefix\url{https://dx.doi.org/10.5244/C.30.87}

\bibitem{DenseNet}
G.~Huang, Z.~Liu, L.~Van Der~Maaten, K.~Q. Weinberger, Densely connected
  convolutional networks, in: 2017 IEEE Conference on Computer Vision and
  Pattern Recognition (CVPR), 2017, pp. 2261--2269.
\newblock \href {https://doi.org/10.1109/CVPR.2017.243}
  {\path{doi:10.1109/CVPR.2017.243}}.

\bibitem{VGG}
K.~Simonyan, A.~Zisserman, \href{http://arxiv.org/abs/1409.1556}{Very deep
  convolutional networks for large-scale image recognition}, in: Y.~Bengio,
  Y.~LeCun (Eds.), 3rd International Conference on Learning Representations,
  {ICLR} 2015, San Diego, CA, USA, May 7-9, 2015, Conference Track Proceedings,
  2015.
\newline\urlprefix\url{http://arxiv.org/abs/1409.1556}

\bibitem{SqueezeNet}
F.~N. Iandola, S.~Han, M.~W. Moskewicz, K.~Ashraf, W.~J. Dally, K.~Keutzer,
  \href{https://openreview.net/forum?id=S1xh5sYgx}{Squeezenet: Alexnet-level
  accuracy with 50x fewer parameters and \ensuremath{<}0.5{MB} model size}
  (2017).
\newline\urlprefix\url{https://openreview.net/forum?id=S1xh5sYgx}

\bibitem{MNASNet}
M.~Tan, B.~Chen, R.~Pang, V.~Vasudevan, M.~Sandler, A.~Howard, Q.~V. Le,
  \href{https://doi.ieeecomputersociety.org/10.1109/CVPR.2019.00293}{Mnasnet:
  Platform-aware neural architecture search for mobile}, in: 2019 IEEE/CVF
  Conference on Computer Vision and Pattern Recognition (CVPR), IEEE Computer
  Society, Los Alamitos, CA, USA, 2019, pp. 2815--2823.
\newblock \href {https://doi.org/10.1109/CVPR.2019.00293}
  {\path{doi:10.1109/CVPR.2019.00293}}.
\newline\urlprefix\url{https://doi.ieeecomputersociety.org/10.1109/CVPR.2019.00293}

\bibitem{MobileNetV2}
M.~Sandler, A.~Howard, M.~Zhu, A.~Zhmoginov, L.~Chen,
  \href{https://doi.ieeecomputersociety.org/10.1109/CVPR.2018.00474}{Mobilenetv2:
  Inverted residuals and linear bottlenecks}, in: 2018 IEEE/CVF Conference on
  Computer Vision and Pattern Recognition (CVPR), IEEE Computer Society, Los
  Alamitos, CA, USA, 2018, pp. 4510--4520.
\newblock \href {https://doi.org/10.1109/CVPR.2018.00474}
  {\path{doi:10.1109/CVPR.2018.00474}}.
\newline\urlprefix\url{https://doi.ieeecomputersociety.org/10.1109/CVPR.2018.00474}

\bibitem{MobileNetV3}
A.~Howard, M.~Sandler, B.~Chen, W.~Wang, L.~C. Chen, M.~Tan, G.~Chu,
  V.~Vasudevan, Y.~Zhu, R.~Pang, H.~Adam, Q.~Le, Searching for mobilenetv3, in:
  2019 IEEE/CVF International Conference on Computer Vision (ICCV), 2019, pp.
  1314--1324.
\newblock \href {https://doi.org/10.1109/ICCV.2019.00140}
  {\path{doi:10.1109/ICCV.2019.00140}}.

\bibitem{EfficientNet}
M.~Tan, Q.~V. Le, Efficientnet: Rethinking model scaling for convolutional
  neural networks, in: K.~Chaudhuri, R.~Salakhutdinov (Eds.), Proceedings of
  the 36th International Conference on Machine Learning, {ICML} 2019, 9-15 June
  2019, Long Beach, California, {USA}, Vol.~97 of Proceedings of Machine
  Learning Research, {PMLR}, 2019, pp. 6105--6114.

\bibitem{EfficientNetV2}
M.~Tan, Q.~V. Le, Efficientnetv2: Smaller models and faster training, in:
  M.~Meila, T.~Zhang (Eds.), Proceedings of the 38th International Conference
  on Machine Learning, {ICML} 2021, 18-24 July 2021, Virtual Event, Vol. 139 of
  Proceedings of Machine Learning Research, {PMLR}, 2021, pp. 10096--10106.

\bibitem{ShuffleNetV2}
N.~Ma, X.~Zhang, H.~T. Zheng, J.~Sun, Shufflenet v2: Practical guidelines for
  efficient cnn architecture design, in: V.~Ferrari, M.~Hebert,
  C.~Sminchisescu, Y.~Weiss (Eds.), Computer Vision -- ECCV 2018, Springer
  International Publishing, Cham, 2018, pp. 122--138.

\bibitem{AlexNet}
A.~Krizhevsky, I.~Sutskever, G.~E. Hinton,
  \href{https://doi.org/10.1145/3065386}{Imagenet classification with deep
  convolutional neural networks}, Commun. ACM 60~(6) (2017) 84–90.
\newblock \href {https://doi.org/10.1145/3065386} {\path{doi:10.1145/3065386}}.
\newline\urlprefix\url{https://doi.org/10.1145/3065386}

\bibitem{ConvNeXt}
Z.~Liu, H.~Mao, C.~Y. Wu, C.~Feichtenhofer, T.~Darrell, S.~Xie, A convnet for
  the 2020s, in: 2022 IEEE/CVF Conference on Computer Vision and Pattern
  Recognition (CVPR), 2022, pp. 11966--11976.
\newblock \href {https://doi.org/10.1109/CVPR52688.2022.01167}
  {\path{doi:10.1109/CVPR52688.2022.01167}}.

\bibitem{RegNet}
I.~Radosavovic, R.~P. Kosaraju, R.~Girshick, K.~He, P.~Dollár, Designing
  network design spaces, in: 2020 {IEEE/CVF} Conference on Computer Vision and
  Pattern Recognition, {CVPR} 2020, Seattle, WA, USA, June 13-19, 2020, 2020,
  pp. 10425--10433.
\newblock \href {https://doi.org/10.1109/CVPR42600.2020.01044}
  {\path{doi:10.1109/CVPR42600.2020.01044}}.

\bibitem{NetAdapt}
T.~J. Yang, A.~G. Howard, B.~Chen, X.~Zhang, A.~Go, M.~Sandler, V.~Sze,
  H.~Adam, \href{https://doi.org/10.1007/978-3-030-01249-6\_18}{Netadapt:
  Platform-aware neural network adaptation for mobile applications}, in:
  V.~Ferrari, M.~Hebert, C.~Sminchisescu, Y.~Weiss (Eds.), Computer Vision -
  {ECCV} 2018 - 15th European Conference, Munich, Germany, September 8-14,
  2018, Proceedings, Part {X}, Vol. 11214 of Lecture Notes in Computer Science,
  Springer, 2018, pp. 289--304.
\newblock \href {https://doi.org/10.1007/978-3-030-01249-6\_18}
  {\path{doi:10.1007/978-3-030-01249-6\_18}}.
\newline\urlprefix\url{https://doi.org/10.1007/978-3-030-01249-6\_18}

\bibitem{optuna}
T.~Akiba, S.~Sano, T.~Yanase, T.~Ohta, M.~Koyama,
  \href{https://doi.org/10.1145/3292500.3330701}{Optuna: A next-generation
  hyperparameter optimization framework}, in: Proceedings of the 25th ACM
  SIGKDD International Conference on Knowledge Discovery \& Data Mining, KDD
  '19, Association for Computing Machinery, New York, NY, USA, 2019, p.
  2623–2631.
\newblock \href {https://doi.org/10.1145/3292500.3330701}
  {\path{doi:10.1145/3292500.3330701}}.
\newline\urlprefix\url{https://doi.org/10.1145/3292500.3330701}

\bibitem{Adam}
D.~P. Kingma, J.~Ba, \href{http://arxiv.org/abs/1412.6980}{Adam: {A} method for
  stochastic optimization}, in: Y.~Bengio, Y.~LeCun (Eds.), 3rd International
  Conference on Learning Representations, {ICLR} 2015, San Diego, CA, USA, May
  7-9, 2015, Conference Track Proceedings, 2015.
\newline\urlprefix\url{http://arxiv.org/abs/1412.6980}

\bibitem{CohenKappa}
J.~Cohen, \href{https://doi.org/10.1177/001316446002000104}{A coefficient of
  agreement for nominal scales}, Educational and Psychological Measurement
  20~(1) (1960) 37--46.
\newblock \href
  {http://arxiv.org/abs/https://doi.org/10.1177/001316446002000104}
  {\path{arXiv:https://doi.org/10.1177/001316446002000104}}, \href
  {https://doi.org/10.1177/001316446002000104}
  {\path{doi:10.1177/001316446002000104}}.
\newline\urlprefix\url{https://doi.org/10.1177/001316446002000104}

\bibitem{ImbalancedLearn2017}
G.~Lema{{\^i}}tre, F.~Nogueira, C.~K. Aridas,
  \href{http://jmlr.org/papers/v18/16-365}{Imbalanced-learn: A python toolbox
  to tackle the curse of imbalanced datasets in machine learning}, Journal of
  Machine Learning Research 18~(17) (2017) 1--5.
\newline\urlprefix\url{http://jmlr.org/papers/v18/16-365}

\bibitem{PyTS}
J.~Faouzi, H.~Janati, \href{http://jmlr.org/papers/v21/19-763.html}{pyts: A
  python package for time series classification}, Journal of Machine Learning
  Research 21~(46) (2020) 1--6.
\newline\urlprefix\url{http://jmlr.org/papers/v21/19-763.html}

\bibitem{Sklearn}
F.~Pedregosa, G.~Varoquaux, A.~Gramfort, V.~Michel, B.~Thirion, O.~Grisel,
  M.~Blondel, P.~Prettenhofer, R.~Weiss, V.~Dubourg, J.~Vanderplas, A.~Passos,
  D.~Cournapeau, M.~Brucher, M.~Perrot, E.~Duchesnay, Scikit-learn: Machine
  learning in {P}ython (2011).

\bibitem{Pympler}
R.~S. J.~Brouwers, L.~Haehne, Pympler: A python package to measure, monitor and
  analyze the memory behavior of python objects in a running python
  application, \url{https://github.com/pympler/pympler}, accessed: 2026-01-13
  (2023).

\bibitem{TimeSeriesAugmentation}
Q.~Wen, L.~Sun, F.~Yang, X.~Song, J.~Gao, X.~Wang, H.~Xu,
  \href{https://doi.org/10.24963/ijcai.2021/631}{Time series data augmentation
  for deep learning: {A} survey}, in: Z.~Zhou (Ed.), Proceedings of the
  Thirtieth International Joint Conference on Artificial Intelligence, {IJCAI}
  2021, Virtual Event / Montreal, Canada, 19-27 August 2021, ijcai.org, 2021,
  pp. 4653--4660.
\newblock \href {https://doi.org/10.24963/IJCAI.2021/631}
  {\path{doi:10.24963/IJCAI.2021/631}}.
\newline\urlprefix\url{https://doi.org/10.24963/ijcai.2021/631}

\end{thebibliography}




\end{document}

\endinput
%%
%% End of file `elsarticle-template-num.tex'.
